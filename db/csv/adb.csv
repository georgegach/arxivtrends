author_all,author_main,category_ids,category_primary,category_primary_id,comment,key,keywords,pages,pdf,published,success,summary,title,ui_comment,ui_subject,ui_submitted,updated,words
Ian Goodfellow,Ian Goodfellow,cs.LG,Learning,cs.LG,v2-v4 are all typo fixes. No substantive changes relative to v1,A:1701.00160,-,57,https://arxiv.org/pdf/1701.00160.pdf,2016-12-31T19:17:17Z,,"This report summarizes the tutorial presented by the author at NIPS 2016 on generative adversarial networks (GANs). The tutorial describes: (1) Why generative modeling is a topic worth studying, (2) how generative models work, and how GANs compare to other generative models, (3) the details of how GANs work, (4) research frontiers in GANs, and (5) state-of-the-art image models that combine GANs with other methods. Finally, the tutorial contains three exercises for readers to complete, and the solutions to these exercises.",NIPS 2016 Tutorial: Generative Adversarial Networks,Comment: v2-v4 are all typo fixes. No substantive changes relative to v1,Subject: Learning [cs.LG],"Updated in Apr 03, 2017",2017-04-03T21:57:48Z,-
"Dragos Strugar, Rasheed Hussain, Manuel Mazzara, Victor Rivera, JooYoung Lee, Ruslan Mustafin",Dragos Strugar et al.,cs.CY,Computers and Society,cs.CY,-,A:1804.08964,-,4,https://arxiv.org/pdf/1804.08964.pdf,2018-04-24T11:36:49Z,,"The proliferation of electric vehicles has spurred the research interest in technologies associated with it, for instance, batteries, and charging mechanisms. Moreover, the recent advancements in autonomous cars also encourage the enabling technologies to integrate and provide holistic applications. To this end, one key requirement for electric vehicles is to have an efficient, secure, and scalable infrastructure and framework for charging, billing, and auditing. However, the current manual charging systems for EVs may not be applicable to the autonomous cars that demand new, automatic, secure, efficient, and scalable billing and auditing mechanism. Owing to the distributed systems such as blockchain technology, in this paper, we propose a new charging and billing mechanism for electric vehicles that charge their batteries in a charging-on-the-move fashion. To meet the requirements of billing in electric vehicles, we leverage distributed ledger technology (DLT), a distributed peer-to-peer technology for micro-transactions. Our proof-of-concept implementation of the billing framework demonstrates the feasibility of such system in electric vehicles. It is also worth noting that the solution can easily be extended to the electric autonomous cars (EACs).",On M2M Micropayments : A Case Study of Electric Autonomous Vehicles,Comment: [ 4 pages. ],Subject: Computers and Society [cs.CY],"Published in Apr 24, 2018",2018-04-24T11:36:49Z,-
"Gaia Collaboration, C. Babusiaux, F. van Leeuwen, M. A. Barstow, C. Jordi, A. Vallenari, D. Bossini, A. Bressan, T. Cantat-Gaudin, M. van Leeuwen, A. G. A. Brown, T. Prusti, J. H. J. de Bruijne, C. A. L. Bailer-Jones, M. Biermann, D. W. Evans, L. Eyer, F. Jansen, S. A. Klioner, U. Lammers, L. Lindegren, X. Luri, F. Mignard, C. Panem, D. Pourbaix, S. Randich, P. Sartoretti, H. I. Siddiqui, C. Soubiran, N. A. Walton, F. Arenou, U. Bastian, M. Cropper, R. Drimmel, D. Katz, M. G. Lattanzi, J. Bakker, C. Cacciari, J. Castañeda, L. Chaoul, N. Cheek, F. DeAngeli, C. Fabricius, R. Guerra, B. Holl, E. Masana, R. Messineo, N. Mowlavi, K. Nienartowicz, P. Panuzzo, J. Portell, M. Riello, G. M. Seabroke, P. Tanga, F. Thévenin, G. Gracia-Abril, G. Comoretto, M. Garcia-Reinaldos, D. Teyssier, M. Altmann, R. Andrae, M. Audard, I. Bellas-Velidis, K. Benson, J. Berthier, R. Blomme, P. Burgess, G. Busso, B. Carry, A. Cellino, G. Clementini, M. Clotet, O. Creevey, M. Davidson, J. DeRidder, L. Delchambre, A. Dell'Oro, C. Ducourant, J. Fernández-Hernández, M. Fouesneau, Y. Frémat, L. Galluccio, M. García-Torres, J. González-Núñez, J. J. González-Vidal, E. Gosset, L. P. Guy, J. -L. Halbwachs, N. C. Hambly, D. L. Harrison, J. Hernández, D. Hestroffer, S. T. Hodgkin, A. Hutton, G. Jasniewicz, A. Jean-Antoine-Piccolo, S. Jordan, A. J. Korn, A. Krone-Martins, A. C. Lanzafame, T. Lebzelter, W. Löffler, M. Manteiga, P. M. Marrese, J. M. Martín-Fleitas, A. Moitinho, A. Mora, K. Muinonen, J. Osinde, E. Pancino, T. Pauwels, J. -M. Petit, A. Recio-Blanco, P. J. Richards, L. Rimoldini, A. C. Robin, L. M. Sarro, C. Siopis, M. Smith, A. Sozzetti, M. Süveges, J. Torra, W. vanReeven, U. Abbas, A. Abreu Aramburu, S. Accart, C. Aerts, G. Altavilla, M. A. Álvarez, R. Alvarez, J. Alves, R. I. Anderson, A. H. Andrei, E. Anglada Varela, E. Antiche, T. Antoja, B. Arcay, T. L. Astraatmadja, N. Bach, S. G. Baker, L. Balaguer-Núñez, P. Balm, C. Barache, C. Barata, D. Barbato, F. Barblan, P. S. Barklem, D. Barrado, M. Barros, S. Bartholomé Muñoz, J. -L. Bassilana, U. Becciani, M. Bellazzini, A. Berihuete, S. Bertone, L. Bianchi, O. Bienaymé, S. Blanco-Cuaresma, T. Boch, C. Boeche, A. Bombrun, R. Borrachero, S. Bouquillon, G. Bourda, A. Bragaglia, L. Bramante, M. A. Breddels, N. Brouillet, T. Brüsemeister, E. Brugaletta, B. Bucciarelli, A. Burlacu, D. Busonero, A. G. Butkevich, R. Buzzi, E. Caffau, R. Cancelliere, G. Cannizzaro, R. Carballo, T. Carlucci, J. M. Carrasco, L. Casamiquela, M. Castellani, A. Castro-Ginard, P. Charlot, L. Chemin, A. Chiavassa, G. Cocozza, G. Costigan, S. Cowell, F. Crifo, M. Crosta, C. Crowley, J. Cuypers, C. Dafonte, Y. Damerdji, A. Dapergolas, P. David, M. David, P. deLaverny, F. DeLuise, R. DeMarch, D. deMartino, R. deSouza, A. deTorres, J. Debosscher, E. delPozo, M. Delbo, A. Delgado, H. E. Delgado, S. Diakite, C. Diener, E. Distefano, C. Dolding, P. Drazinos, J. Durán, B. Edvardsson, H. Enke, K. Eriksson, P. Esquej, G. Eynard Bontemps, C. Fabre, M. Fabrizio, S. Faigler, A. J. Falcão, M. Farràs Casas, L. Federici, G. Fedorets, P. Fernique, F. Figueras, F. Filippi, K. Findeisen, A. Fonti, E. Fraile, M. Fraser, B. Frézouls, M. Gai, S. Galleti, D. Garabato, F. García-Sedano, A. Garofalo, N. Garralda, A. Gavel, P. Gavras, J. Gerssen, R. Geyer, P. Giacobbe, G. Gilmore, S. Girona, G. Giuffrida, F. Glass, M. Gomes, M. Granvik, A. Gueguen, A. Guerrier, J. Guiraud, R. Gutiérrez-Sánchez, R. Haigron, D. Hatzidimitriou, M. Hauser, M. Haywood, U. Heiter, A. Helmi, J. Heu, T. Hilger, D. Hobbs, W. Hofmann, G. Holland, H. E. Huckle, A. Hypki, V. Icardi, K. Janßen, G. JevardatdeFombelle, P. G. Jonker, Á. L. Juhász, F. Julbe, A. Karampelas, A. Kewley, J. Klar, A. Kochoska, R. Kohley, K. Kolenberg, M. Kontizas, E. Kontizas, S. E. Koposov, G. Kordopatis, Z. Kostrzewa-Rutkowska, P. Koubsky, S. Lambert, A. F. Lanza, Y. Lasne, J. -B. Lavigne, Y. LeFustec, C. LePoncin-Lafitte, Y. Lebreton, S. Leccia, N. Leclerc, I. Lecoeur-Taibi, H. Lenhardt, F. Leroux, S. Liao, E. Licata, H. E. P. Lindstrøm, T. A. Lister, E. Livanou, A. Lobel, M. López, S. Managau, R. G. Mann, G. Mantelet, O. Marchal, J. M. Marchant, M. Marconi, S. Marinoni, G. Marschalkó, D. J. Marshall, M. Martino, G. Marton, N. Mary, D. Massari, G. Matijevič, T. Mazeh, P. J. McMillan, S. Messina, D. Michalik, N. R. Millar, D. Molina, R. Molinaro, L. Molnár, P. Montegriffo, R. Mor, R. Morbidelli, T. Morel, D. Morris, A. F. Mulone, T. Muraveva, I. Musella, G. Nelemans, L. Nicastro, L. Noval, W. O'Mullane, C. Ordénovic, D. Ordóñez-Blanco, P. Osborne, C. Pagani, I. Pagano, F. Pailler, H. Palacin, L. Palaversa, A. Panahi, M. Pawlak, A. M. Piersimoni, F. -X. Pineau, E. Plachy, G. Plum, E. Poggio, E. Poujoulet, A. Prša, L. Pulone, E. Racero, S. Ragaini, N. Rambaux, M. Ramos-Lerate, S. Regibo, C. Reylé, F. Riclet, V. Ripepi, A. Riva, A. Rivard, G. Rixon, T. Roegiers, M. Roelens, M. Romero-Gómez, N. Rowell, F. Royer, L. Ruiz-Dern, G. Sadowski, T. Sagristà Sellés, J. Sahlmann, J. Salgado, E. Salguero, N. Sanna, T. Santana-Ros, M. Sarasso, H. Savietto, M. Schultheis, E. Sciacca, M. Segol, J. C. Segovia, D. Ségransan, I-C. Shih, L. Siltala, A. F. Silva, R. L. Smart, K. W. Smith, E. Solano, F. Solitro, R. Sordo, S. SoriaNieto, J. Souchay, A. Spagna, F. Spoto, U. Stampa, I. A. Steele, H. Steidelmüller, C. A. Stephenson, H. Stoev, F. F. Suess, J. Surdej, L. Szabados, E. Szegedi-Elek, D. Tapiador, F. Taris, G. Tauran, M. B. Taylor, R. Teixeira, D. Terrett, P. Teyssandier, W. Thuillot, A. Titarenko, F. TorraClotet, C. Turon, A. Ulla, E. Utrilla, S. Uzzi, M. Vaillant, G. Valentini, V. Valette, A. vanElteren, E. Van Hemelryck, M. Vaschetto, A. Vecchiato, J. Veljanoski, Y. Viala, D. Vicente, S. Vogt, C. vonEssen, H. Voss, V. Votruba, S. Voutsinas, G. Walmsley, M. Weiler, O. Wertz, T. Wevers, Ł. Wyrzykowski, A. Yoldas, M. Žerjal, H. Ziaeepour, J. Zorec, S. Zschocke, S. Zucker, C. Zurbach, T. Zwitter",Gaia Collaboration et al.,"astro-ph.SR, astro-ph.GA",Solar and Stellar Astrophysics,astro-ph.SR,Accepted for publication by A&A to be published in the Gaia Data Release 2 special issue,A:1804.09378,-,28,https://arxiv.org/pdf/1804.09378.pdf,2018-04-25T06:25:28Z,,"We highlight the power of the Gaia DR2 in studying many fine structures of the Hertzsprung-Russell diagram (HRD). Gaia allows us to present many different HRDs, depending in particular on stellar population selections. We do not aim here for completeness in terms of types of stars or stellar evolutionary aspects. Instead, we have chosen several illustrative examples. We describe some of the selections that can be made in Gaia DR2 to highlight the main structures of the Gaia HRDs. We select both field and cluster (open and globular) stars, compare the observations with previous classifications and with stellar evolutionary tracks, and we present variations of the Gaia HRD with age, metallicity, and kinematics. Late stages of stellar evolution such as hot subdwarfs, post-AGB stars, planetary nebulae, and white dwarfs are also analysed, as well as low-mass brown dwarf objects. The Gaia HRDs are unprecedented in both precision and coverage of the various Milky Way stellar populations and stellar evolutionary phases. Many fine structures of the HRDs are presented. The clear split of the white dwarf sequence into hydrogen and helium white dwarfs is presented for the first time in an HRD. The relation between kinematics and the HRD is nicely illustrated. Two different populations in a classical kinematic selection of the halo are unambiguously identified in the HRD. Membership and mean parameters for a selected list of open clusters are provided. They allow drawing very detailed cluster sequences, highlighting fine structures, and providing extremely precise empirical isochrones that will lead to more insight in stellar physics. Gaia DR2 demonstrates the potential of combining precise astrometry and photometry for large samples for studies in stellar evolution and stellar population and opens an entire new area for HRD-based studies.",Gaia Data Release 2: Observational Hertzsprung-Russell diagrams,Comment: Accepted for publication by A&A to be published in the Gaia Data Release 2 special issue,Subject: Solar and Stellar Astrophysics [astro-ph.SR],"Published in Apr 25, 2018",2018-04-25T06:25:28Z,-
"Shiyu Liang, Ruoyu Sun, Jason D. Lee, R. Srikant",Shiyu Liang et al.,"stat.ML, cs.LG",Machine Learning,stat.ML,-,A:1805.08671,-,36,https://arxiv.org/pdf/1805.08671.pdf,2018-05-22T15:44:35Z,,"One of the main difficulties in analyzing neural networks is the non-convexity of the loss function which may have many bad local minima. In this paper, we study the landscape of neural networks for binary classification tasks. Under mild assumptions, we prove that after adding one special neuron with a skip connection to the output, or one special neuron per layer, every local minimum is a global minimum.",Adding One Neuron Can Eliminate All Bad Local Minima,Comment: [ 36 pages. ],Subject: Machine Learning [stat.ML],"Published 3 days ago in May 22, 2018",2018-05-22T15:44:35Z,-
"Vanessa Volz, Jacob Schrum, Jialin Liu, Simon M. Lucas, Adam Smith, Sebastian Risi",Vanessa Volz et al.,"cs.AI, cs.NE",Artificial Intelligence,cs.AI,"8 pages, GECCO2018",A:1805.00728,"Generative Adversarial Network, Procedural Content Generation, Mario, CMA-ES, Game",8,https://arxiv.org/pdf/1805.00728.pdf,2018-05-02T10:59:36Z,,"Generative Adversarial Networks (GANs) are a machine learning approach capable of generating novel example outputs across a space of provided training examples. Procedural Content Generation (PCG) of levels for video games could benefit from such models, especially for games where there is a pre-existing corpus of levels to emulate. This paper trains a GAN to generate levels for Super Mario Bros using a level from the Video Game Level Corpus. The approach successfully generates a variety of levels similar to one in the original corpus, but is further improved by application of the Covariance Matrix Adaptation Evolution Strategy (CMA-ES). Specifically, various fitness functions are used to discover levels within the latent space of the GAN that maximize desired properties. Simple static properties are optimized, such as a given distribution of tile types. Additionally, the champion A* agent from the 2009 Mario AI competition is used to assess whether a level is playable, and how many jumping actions are required to beat it. These fitness functions allow for the discovery of levels that exist within the space of examples designed by experts, and also guide the search towards levels that fulfill one or more specified objectives.",Evolving Mario Levels in the Latent Space of a Deep Convolutional Generative Adversarial Network,"Comment: 8 pages, GECCO2018",Subject: Artificial Intelligence [cs.AI],"Published 24 days ago in May 02, 2018",2018-05-02T10:59:36Z,-
Nassim Nicholas Taleb,Nassim Nicholas Taleb,"stat.ME, q-fin.ST",Methodology,stat.ME,-,A:1802.05495,-,8,https://arxiv.org/pdf/1802.05495.pdf,2018-02-15T11:57:08Z,,"This note presents an operational measure of fat-tailedness for univariate probability distributions, in $[0,1]$ where 0 is maximally thin-tailed (Gaussian) and 1 is maximally fat-tailed. Among others,1) it helps assess the sample size needed to establish a comparative $n$ needed for statistical significance, 2) allows practical comparisons across classes of fat-tailed distributions, 3) helps understand some inconsistent attributes of the lognormal, pending on the parametrization of its scale parameter. The literature is rich for what concerns asymptotic behavior, but there is a large void for finite values of $n$, those needed for operational purposes. Conventional measures of fat-tailedness, namely 1) the tail index for the power law class, and 2) Kurtosis for finite moment distributions fail to apply to some distributions, and do not allow comparisons across classes and parametrization, that is between power laws outside the Levy-Stable basin, or power laws to distributions in other classes, or power laws for different number of summands. How can one compare a sum of 100 Student T distributed random variables with 3 degrees of freedom to one in a Levy-Stable or a Lognormal class? How can one compare a sum of 100 Student T with 3 degrees of freedom to a single Student T with 2 degrees of freedom? We propose an operational and heuristic measure that allow us to compare $n$-summed independent variables under all distributions with finite first moment. The method is based on the rate of convergence of the Law of Large numbers for finite sums, $n$-summands specifically. We get either explicit expressions or simulation results and bounds for the lognormal, exponential, Pareto, and the Student T distributions in their various calibrations --in addition to the general Pearson classes.",How Much Data Do You Need? An Operational Metric for Fat-tailedness,Comment: [ 8 pages. ],Subject: Methodology [stat.ME],"Updated 7 days ago in May 18, 2018",2018-05-18T15:24:55Z,-
"Chen Chen, Qifeng Chen, Jia Xu, Vladlen Koltun",Chen Chen et al.,"cs.CV, cs.GR, cs.LG",Computer Vision and Pattern Recognition,cs.CV,Published at the Conference on Computer Vision and Pattern Recognition (CVPR 2018),A:1805.01934,-,10,https://arxiv.org/pdf/1805.01934.pdf,2018-05-04T21:03:12Z,,"Imaging in low light is challenging due to low photon count and low SNR. Short-exposure images suffer from noise, while long exposure can induce blur and is often impractical. A variety of denoising, deblurring, and enhancement techniques have been proposed, but their effectiveness is limited in extreme conditions, such as video-rate imaging at night. To support the development of learning-based pipelines for low-light image processing, we introduce a dataset of raw short-exposure low-light images, with corresponding long-exposure reference images. Using the presented dataset, we develop a pipeline for processing low-light images, based on end-to-end training of a fully-convolutional network. The network operates directly on raw sensor data and replaces much of the traditional image processing pipeline, which tends to perform poorly on such data. We report promising results on the new dataset, analyze factors that affect performance, and highlight opportunities for future work. The results are shown in the supplementary video at https://youtu.be/qWKUFK7MWvg",Learning to See in the Dark,Comment: Published at the Conference on Computer Vision and Pattern Recognition (CVPR 2018),Subject: Computer Vision and Pattern Recognition [cs.CV],"Published 21 days ago in May 04, 2018",2018-05-04T21:03:12Z,-
"Justine Zhang, Jonathan P. Chang, Cristian Danescu-Niculescu-Mizil, Lucas Dixon, Yiqing Hua, Nithum Thain, Dario Taraborelli",Justine Zhang et al.,"cs.CL, cs.AI, cs.CY, cs.HC, physics.soc-ph",Computation and Language,cs.CL,"To appear in the Proceedings of ACL 2018, 15 pages, 1 figure. Data, quiz, code and additional information at http://www.cs.cornell.edu/~cristian/Conversations_gone_awry.html",A:1805.05345,-,16,https://arxiv.org/pdf/1805.05345.pdf,2018-05-14T18:00:03Z,,"One of the main challenges online social systems face is the prevalence of antisocial behavior, such as harassment and personal attacks. In this work, we introduce the task of predicting from the very start of a conversation whether it will get out of hand. As opposed to detecting undesirable behavior after the fact, this task aims to enable early, actionable prediction at a time when the conversation might still be salvaged. To this end, we develop a framework for capturing pragmatic devices---such as politeness strategies and rhetorical prompts---used to start a conversation, and analyze their relation to its future trajectory. Applying this framework in a controlled setting, we demonstrate the feasibility of detecting early warning signs of antisocial behavior in online discussions.",Conversations Gone Awry: Detecting Early Signs of Conversational Failure,"Comment: To appear in the Proceedings of ACL 2018, 15 pages, 1 figure. Data, quiz, code and additional information at http://www.cs.cornell.edu/~cristian/Conversations_gone_awry.html",Subject: Computation and Language [cs.CL],"Published 11 days ago in May 14, 2018",2018-05-14T18:00:03Z,-
"Kristine Spekkens RMC/Queen's, Nicholas Cofie Queen's, Dennis R. Crabtree NRC-Herzberg",Kristine Spekkens RMC/Queen's et al.,astro-ph.IM,Instrumentation and Methods for Astrophysics,astro-ph.IM,"11 pages, 5 figures. Submitted proceedings for SPIE Astronomical Telescopes + Instrumentation (AS18) in June 2018. Comments welcome",A:1805.06508,-,11,https://arxiv.org/pdf/1805.06508.pdf,2018-05-16T20:02:29Z,,"Recent studies have shown that the proposal peer review processes employed by a variety of organizations to allocate astronomical telescope time produce outcomes that are systematically biased depending on whether proposal's principal investigator (PI) is a man or a woman. Using Canada-France-Hawaii Telescope (CFHT) and Gemini Observatory proposal statistics from Canada over 10 recent proposal cycles, we assess whether or not the mean proposal scores assigned by the National Research Council's (NRC's) Canadian Time Allocation Committee (CanTAC) also correlate significantly with PI sex. Classical t-tests, bootstrap and jackknife replications show that proposals submitted by women were rated significantly worse than those submitted by men. We subdivide the data in order to investigate sex-disaggregated statistics in relation to PI career stage (faculty vs. non-faculty), telescope requested, scientific review panel, observing semester, and the PhD year of faculty PIs. Consistent with the bivariate results, a multivariate regression analysis controlling for other covariates confirmed that PI sex is the only significant predictor of proposal rating scores for the sample as a whole, although differences emerge for proposals submitted by faculty and non-faculty PIs. While further research is needed to explain our results, it is possible that implicit social cognition is at work. NRC and CanTAC have taken steps to mitigate this possibility by altering proposal author lists in order to conceal the PI's identity among co-investigators. We recommend that the impact of this measure on mitigating bias in future observing semesters be quantitatively assessed using statistical techniques such as those employed here.",Sex-Disaggregated Systematics in Canadian Time Allocation Committee Telescope Proposal Reviews,"Comment: 11 pages, 5 figures. Submitted proceedings for SPIE Astronomical Telescopes + Instrumentation (AS18) in June 2018. Comments welcome",Subject: Instrumentation and Methods for Astrophysics [astro-ph.IM],"Published 9 days ago in May 16, 2018",2018-05-16T20:02:29Z,-
"Miles Brundage, Shahar Avin, Jack Clark, Helen Toner, Peter Eckersley, Ben Garfinkel, Allan Dafoe, Paul Scharre, Thomas Zeitzoff, Bobby Filar, Hyrum Anderson, Heather Roff, Gregory C. Allen, Jacob Steinhardt, Carrick Flynn, Seán Ó hÉigeartaigh, Simon Beard, Haydn Belfield, Sebastian Farquhar, Clare Lyle, Rebecca Crootof, Owain Evans, Michael Page, Joanna Bryson, Roman Yampolskiy, Dario Amodei",Miles Brundage et al.,"cs.AI, cs.CR, cs.CY",Artificial Intelligence,cs.AI,-,A:1802.07228,-,101,https://arxiv.org/pdf/1802.07228.pdf,2018-02-20T18:07:50Z,,"This report surveys the landscape of potential security threats from malicious uses of AI, and proposes ways to better forecast, prevent, and mitigate these threats. After analyzing the ways in which AI may influence the threat landscape in the digital, physical, and political domains, we make four high-level recommendations for AI researchers and other stakeholders. We also suggest several promising areas for further research that could expand the portfolio of defenses, or make attacks less effective or harder to execute. Finally, we discuss, but do not conclusively resolve, the long-term equilibrium of attackers and defenders.","The Malicious Use of Artificial Intelligence: Forecasting, Prevention, and Mitigation",Comment: [ 101 pages. ],Subject: Artificial Intelligence [cs.AI],"Published in Feb 20, 2018",2018-02-20T18:07:50Z,-
S. Jay Olson,S. Jay Olson,"astro-ph.CO, gr-qc",Cosmology and Nongalactic Astrophysics,astro-ph.CO,"7 pages, 3 figures",A:1805.06329,-,7,https://arxiv.org/pdf/1805.06329.pdf,2018-05-15T17:57:59Z,,"We present a simplified description of expansionistic life in the standard relativistic cosmology. The resulting model is exactly integrable, yielding a simple set of predictive formulas. This allows one to quickly propose new scenarios for the life appearance rate and the dominant expansion speed and evaluate the observable consequences. These include the expected number and angular size of visible expanding domains, the total eclipsed fraction of the sky, and the life-saturated fraction of the universe. We also propose a simple anthropic bound on observable quantities, as a function of the dominant expansion velocity alone. The goal is to create a simple and intuition-building tool for use in the context of cosmology, extragalactic SETI, and futures studies. We discuss the general predictions of this framework, including conditions giving rise to an ""extragalactic Fermi paradox,"" in which zero civilizations are visible beyond the Milky Way. This can occur even if a substantial fraction of the universe is already saturated with ambitious life.",Expanding cosmological civilizations on the back of an envelope,"Comment: 7 pages, 3 figures",Subject: Cosmology and Nongalactic Astrophysics [astro-ph.CO],"Published 10 days ago in May 15, 2018",2018-05-15T17:57:59Z,-
"Sergey Feldman, Kyle Lo, Waleed Ammar",Sergey Feldman et al.,cs.DL,Digital Libraries,cs.DL,-,A:1805.05238,-,7,https://arxiv.org/pdf/1805.05238.pdf,2018-05-14T15:42:07Z,,"We explore the degree to which papers prepublished on arXiv garner more citations, in an attempt to paint a sharper picture of fairness issues related to prepublishing. A paper's citation count is estimated using a negative-binomial generalized linear model (GLM) while observing a binary variable which indicates whether the paper has been prepublished. We control for author influence (via the authors' h-index at the time of paper writing), publication venue, and overall time that paper has been available on arXiv. Our analysis only includes papers that were eventually accepted for publication at top-tier CS conferences, and were posted on arXiv either before or after the acceptance notification. We observe that papers submitted to arXiv before acceptance have, on average, 65\% more citations in the following year compared to papers submitted after. We note that this finding is not causal, and discuss possible next steps.",Citation Count Analysis for Papers with Preprints,Comment: [ 7 pages. ],Subject: Digital Libraries [cs.DL],"Published 11 days ago in May 14, 2018",2018-05-14T15:42:07Z,-
"Jessie L. Christiansen, Ian J. M. Crossfield, Geert Barentsen, Chris J. Lintott, Thomas Barclay, Brooke D. Simmons, Erik Petigura, Joshua E. Schlieder, Courtney D. Dressing, Andrew Vanderburg, David R. Ciardi, Campbell Allen, Adam McMaster, Grant Miller, Martin Veldthuis, Sarah Allen, Zach Wolfenbarger, Brian Cox, Julia Zemiro, Andrew W. Howard, John Livingston, Evan Sinukoff, Timothy Catron, Andrew Grey, Joshua J. E. Kusch, Ivan Terentev, Martin Vales, Martti H. Kristiansen",Jessie L. Christiansen et al.,astro-ph.EP,Earth and Planetary Astrophysics,astro-ph.EP,"11 pages, 9 figures, published in AJ, Volume 155, Number 2",A:1801.03874,-,11,https://arxiv.org/pdf/1801.03874.pdf,2018-01-11T17:05:43Z,,"K2-138 is a moderately bright (V = 12.2, K = 10.3) main sequence K-star observed in Campaign 12 of the NASA K2 mission. It hosts five small (1.6-3.3R_Earth) transiting planets in a compact architecture. The periods of the five planets are 2.35 d, 3.56 d, 5.40 d, 8.26 d, and 12.76 d, forming an unbroken chain of near 3:2 resonances. Although we do not detect the predicted 2-5 minute transit timing variations with the K2 timing precision, they may be observable by higher cadence observations with, for example, Spitzer or CHEOPS. The planets are amenable to mass measurement by precision radial velocity measurements, and therefore K2-138 could represent a new benchmark systems for comparing radial velocity and TTV masses. K2-138 is the first exoplanet discovery by citizen scientists participating in the Exoplanet Explorers project on the Zooniverse platform.",The K2-138 System: A Near-Resonant Chain of Five Sub-Neptune Planets Discovered by Citizen Scientists,"Comment: 11 pages, 9 figures, published in AJ, Volume 155, Number 2",Subject: Earth and Planetary Astrophysics [astro-ph.EP],"Updated in Jan 20, 2018",2018-01-20T01:04:02Z,-
"David E. Trilling, Eric C. Bellm, Renu Malhotra",David E. Trilling et al.,astro-ph.EP,Earth and Planetary Astrophysics,astro-ph.EP,AJ in press,A:1804.07713,-,7,https://arxiv.org/pdf/1804.07713.pdf,2018-04-20T16:36:11Z,,"Two planetary mass objects in the far outer Solar System --- collectively referred to here as Planet X --- have recently been hypothesized to explain the orbital distribution of distant Kuiper Belt Objects. Neither planet is thought to be exceptionally faint, but the sky locations of these putative planets are poorly constrained. Therefore, a wide area survey is needed to detect these possible planets. The Large Synoptic Survey Telescope (LSST) will carry out an unbiased, large area (around 18,000 deg$^2$), deep (limiting magnitude of individual frames of 24.5) survey (the ""wide-fast-deep"" survey) of the southern sky beginning in 2022, and is therefore an important tool to search for these hypothesized planets. Here we explore the effectiveness of LSST as a search platform for these possible planets. Assuming the current baseline cadence (which includes the wide-fast-deep survey plus additional coverage) we estimate that LSST will confidently detect or rule out the existence of Planet X in 61\% of the entire sky. At orbital distances up to $\sim$75 au, Planet X could simply be found in the normal nightly moving object processing; at larger distances, it will require custom data processing. We also discuss the implications of a non-detection of Planet X in LSST data.",On the detectability of Planet X with LSST,Comment: AJ in press,Subject: Earth and Planetary Astrophysics [astro-ph.EP],"Published in Apr 20, 2018",2018-04-20T16:36:11Z,-
"Shane Legg, Marcus Hutter",Shane Legg et al.,cs.AI,Artificial Intelligence,cs.AI,12 LaTeX pages,A:0706.3639,-,12,https://arxiv.org/pdf/0706.3639.pdf,2007-06-25T13:40:56Z,,"This paper is a survey of a large number of informal definitions of ``intelligence'' that the authors have collected over the years. Naturally, compiling a complete list would be impossible as many definitions of intelligence are buried deep inside articles and books. Nevertheless, the 70-odd definitions presented here are, to the authors' knowledge, the largest and most well referenced collection there is.",A Collection of Definitions of Intelligence,Comment: 12 LaTeX pages,Subject: Artificial Intelligence [cs.AI],"Published in Jun 25, 2007",2007-06-25T13:40:56Z,-
Jason Kalirai,Jason Kalirai,"astro-ph.IM, astro-ph.CO, astro-ph.EP, astro-ph.GA, astro-ph.SR",Instrumentation and Methods for Astrophysics,astro-ph.IM,"Accepted for Publication in Contemporary Physics. 67 pages, including 18 figures. Astro-ph version includes an Appendix on ""Observing Opportunities""",A:1805.06941,-,67,https://arxiv.org/pdf/1805.06941.pdf,2018-05-17T19:24:06Z,,"For the past 400 years, astronomers have sought to observe and interpret the Universe by building more powerful telescopes. These incredible instruments extend the capabilities of one of our most important senses, sight, towards new limits such as increased sensitivity and resolution, new dimensions such as exploration of wavelengths across the full electromagnetic spectrum, new information content such as analysis through spectroscopy, and new cadences such as rapid time-series views of the variable sky. The results from these investments, from small to large telescopes on the ground and in space, have completely transformed our understanding of the Universe; including the discovery that Earth is not the center of the Universe, that the Milky Way is one among many galaxies in the Universe, that relic cosmic background radiation fills all space in the early Universe, that that the expansion rate of the Universe is accelerating, that exoplanets are common around stars, that gravitational waves exist, and much more. For modern astronomical research, the next wave of breakthroughs in fields ranging over planetary, stellar, galactic, and extragalactic science motivate a general-purpose observatory that is optimized at near- and mid-infrared wavelengths, and that has much greater sensitivity, resolution, and spectroscopic multiplexing than all previous telescopes. This scientific vision, from measuring the composition of rocky worlds in the nearby Milky Way galaxy to finding the first sources of light in the Universe to other topics at the forefront of modern astrophysics, motivates the state-of-the-art James Webb Space Telescope (Webb). In this review paper, I summarize the design and technical capabilities of Webb and the scientific opportunities that it enables.",Scientific Discovery with the James Webb Space Telescope,"Comment: Accepted for Publication in Contemporary Physics. 67 pages, including 18 figures. Astro-ph version includes an Appendix on ""Observing Opportunities""",Subject: Instrumentation and Methods for Astrophysics [astro-ph.IM],"Published 8 days ago in May 17, 2018",2018-05-17T19:24:06Z,-
Gary Marcus,Gary Marcus,"cs.AI, cs.LG, stat.ML, 97R40, I.2.0; I.2.6",Artificial Intelligence,cs.AI,1 figure,A:1801.00631,-,27,https://arxiv.org/pdf/1801.00631.pdf,2018-01-02T12:49:35Z,,"Although deep learning has historical roots going back decades, neither the term ""deep learning"" nor the approach was popular just over five years ago, when the field was reignited by papers such as Krizhevsky, Sutskever and Hinton's now classic (2012) deep network model of Imagenet. What has the field discovered in the five subsequent years? Against a background of considerable progress in areas such as speech recognition, image recognition, and game playing, and considerable enthusiasm in the popular press, I present ten concerns for deep learning, and suggest that deep learning must be supplemented by other techniques if we are to reach artificial general intelligence.",Deep Learning: A Critical Appraisal,Comment: 1 figure,Subject: Artificial Intelligence [cs.AI],"Published in Jan 02, 2018",2018-01-02T12:49:35Z,-
"Matthew Jagielski, Alina Oprea, Battista Biggio, Chang Liu, Cristina Nita-Rotaru, Bo Li",Matthew Jagielski et al.,"cs.CR, cs.GT, cs.LG",Cryptography and Security,cs.CR,"Preprint of the work accepted for publication at the 39th IEEE Symposium on Security and Privacy, San Francisco, CA, USA, May 21-23, 2018",A:1804.00308,-,17,https://arxiv.org/pdf/1804.00308.pdf,2018-04-01T15:56:43Z,,"As machine learning becomes widely used for automated decisions, attackers have strong incentives to manipulate the results and models generated by machine learning algorithms. In this paper, we perform the first systematic study of poisoning attacks and their countermeasures for linear regression models. In poisoning attacks, attackers deliberately influence the training data to manipulate the results of a predictive model. We propose a theoretically-grounded optimization framework specifically designed for linear regression and demonstrate its effectiveness on a range of datasets and models. We also introduce a fast statistical attack that requires limited knowledge of the training process. Finally, we design a new principled defense method that is highly resilient against all poisoning attacks. We provide formal guarantees about its convergence and an upper bound on the effect of poisoning attacks when the defense is deployed. We evaluate extensively our attacks and defenses on three realistic datasets from health care, loan assessment, and real estate domains.",Manipulating Machine Learning: Poisoning Attacks and Countermeasures for Regression Learning,"Comment: Preprint of the work accepted for publication at the 39th IEEE Symposium on Security and Privacy, San Francisco, CA, USA, May 21-23, 2018",Subject: Cryptography and Security [cs.CR],"Published in Apr 01, 2018",2018-04-01T15:56:43Z,-
"D. Cordier, Gerard Liger-Belair",D. Cordier et al.,astro-ph.EP,Earth and Planetary Astrophysics,astro-ph.EP,Published in The Astrophysical Journal,A:1805.09006,-,10,https://arxiv.org/pdf/1805.09006.pdf,2018-05-23T08:20:02Z,,"In the polar regions of Titan, the main satellite of Saturn, hydrocarbon seas have been discovered by the Cassini-Huygens mission. RADAR observations have revealed surprising and transient bright areas over Ligeia Mare surface. As suggested by recent research, bubbles could explain these strange features. However, the nucleation and growth of such bubbles, together with their RADAR reflectivity, have never been investigated. All of these aspects are critical to an actual observation. We have thus applied the classical nucleation theory to our context, and we developed a specific radiative transfer model that is appropriate for bubbles streams in cryogenic liquids. According to our results, the sea bed appears to be the most plausible place for the generation of bubbles, leading to a signal comparable to observations. This conclusion is supported by thermodynamic arguments and by RADAR properties of a bubbly column. The latter are also valid in the case of bubble plumes, due to gas leaking from the sea floor.","Bubbles in Titan's seas: nucleation, growth and RADAR signature",Comment: Published in The Astrophysical Journal,Subject: Earth and Planetary Astrophysics [astro-ph.EP],"Published 3 days ago in May 23, 2018",2018-05-23T08:20:02Z,-
"R. Bates, M. Battistin, S. Berry, J. Berthoud, A. Bitadze, P. Bonneau, J. Botelho-Direito, N. Bousson, G. Boyd, G. Bozza, E. Da Riva, C. Degeorge, B. DiGirolamo, M. Doubek, D. Giugni, J. Godlewski, G. Hallewell, S. Katunin, D. Lombard, M. Mathieu, S. McMahon, K. Nagai, E. Perez-Rodriguez, C. Rossi, A. Rozanov, V. Vacek, M. Vitek, L. Zwalinski",R. Bates et al.,"physics.ins-det, hep-ex",Instrumentation and Detectors,physics.ins-det,"30 pages, 24 figures, 3 tables KEYWORDS: Sonar; Saturated fluorocarbons; Flowmetry; Sound velocity, Gas mixture analysis",A:1210.4835,-,30,https://arxiv.org/pdf/1210.4835.pdf,2012-10-17T19:59:14Z,,"An upgrade to the ATLAS silicon tracker cooling control system may require a change from C3F8 (octafluoro-propane) evaporative coolant to a blend containing 10-25% of C2F6 (hexafluoro-ethane). Such a change will reduce the evaporation temperature to assure thermal stability following radiation damage accumulated at full LHC luminosity. Central to this upgrade is a new ultrasonic instrument in which sound transit times are continuously measured in opposite directions in flowing gas at known temperature and pressure to deduce the C3F8/C2F6 flow rate and mixture composition. The instrument and its Supervisory, Control and Data Acquisition (SCADA) software are described in this paper. Several geometries for the instrument are in use or under evaluation. An instrument with a pinched axial geometry intended for analysis and measurement of moderate flow rates has demonstrated a mixture resolution of 3.10-3 for C3F8/C2F6 molar mixtures with 20%C2F6, and a flow resolution of 2% of full scale for mass flows up to 30gs-1. In mixtures of widely-differing molecular weight (mw), higher mixture precision is possible: a sensitivity of <5.10-5 to leaks of C3F8 into part of the ATLAS tracker nitrogen envelope (mw difference 160) has been seen. An instrument with an angled sound path geometry has been developed for use at high fluorocarbon mass flow rates of around 1.2 kgs-1 - corresponding to full flow in a new 60kW thermosiphon recirculator under construction for the ATLAS silicon tracker. Extensive computational fluid dynamics studies were performed to determine the preferred geometry (ultrasonic transducer spacing and placement, together with the sound crossing angle with respect to the vapour flow direction). A prototype with 45deg crossing angle has demonstrated a flow resolution of 1.9% of full scale for linear flow velocities up to 15 ms-1. The instrument has many potential applications.",A combined ultrasonic flow meter and binary vapour mixture analyzer for the ATLAS silicon tracker,"Comment: 30 pages, 24 figures, 3 tables KEYWORDS: Sonar; Saturated fluorocarbons; Flowmetry; Sound velocity, Gas mixture analysis",Subject: Instrumentation and Detectors [physics.ins-det],"Published in Oct 17, 2012",2012-10-17T19:59:14Z,-
"A. Pluchino. A. E. Biondo, A. Rapisarda",A. Pluchino. A. E. Biondo et al.,physics.soc-ph,Physics and Society,physics.soc-ph,"24 pages, 13 figures",A:1802.07068,-,24,https://arxiv.org/pdf/1802.07068.pdf,2018-02-20T11:37:02Z,,"The largely dominant meritocratic paradigm of highly competitive Western cultures is rooted on the belief that success is due mainly, if not exclusively, to personal qualities such as talent, intelligence, skills, efforts or risk taking. Sometimes, we are willing to admit that a certain degree of luck could also play a role in achieving significant material success. But, as a matter of fact, it is rather common to underestimate the importance of external forces in individual successful stories. It is very well known that intelligence or talent exhibit a Gaussian distribution among the population, whereas the distribution of wealth - considered a proxy of success - follows typically a power law (Pareto law). Such a discrepancy between a Normal distribution of inputs, with a typical scale, and the scale invariant distribution of outputs, suggests that some hidden ingredient is at work behind the scenes. In this paper, with the help of a very simple agent-based model, we suggest that such an ingredient is just randomness. In particular, we show that, if it is true that some degree of talent is necessary to be successful in life, almost never the most talented people reach the highest peaks of success, being overtaken by mediocre but sensibly luckier individuals. As to our knowledge, this counterintuitive result - although implicitly suggested between the lines in a vast literature - is quantified here for the first time. It sheds new light on the effectiveness of assessing merit on the basis of the reached level of success and underlines the risks of distributing excessive honors or resources to people who, at the end of the day, could have been simply luckier than others. With the help of this model, several policy hypotheses are also addressed and compared to show the most efficient strategies for public funding of research in order to improve meritocracy, diversity and innovation.",Talent vs Luck: the role of randomness in success and failure,"Comment: 24 pages, 13 figures",Subject: Physics and Society [physics.soc-ph],"Updated in Feb 25, 2018",2018-02-25T11:22:38Z,-
"Jim W. Barrett, Sebastian M. Gaebel, Coenraad J. Neijssel, Alejandro Vigna-Gómez, Simon Stevenson, Christopher P. L. Berry, Will M. Farr, Ilya Mandel",Jim W. Barrett et al.,"astro-ph.HE, astro-ph.SR, physics.data-an",High Energy Astrophysical Phenomena,astro-ph.HE,"12 pages, 9 figures; version accepted by Monthly Notices of the Royal Astronomical Society",A:1711.06287,-,12,https://arxiv.org/pdf/1711.06287.pdf,2017-11-16T19:07:00Z,,"The properties of the population of merging binary black holes encode some of the uncertain physics of the evolution of massive stars in binaries. The binary black hole merger rate and chirp mass distribution are being measured by ground-based gravitational-wave detectors. We consider isolated binary evolution and explore how accurately the physical model can be constrained with such observations by applying the Fisher information matrix to the merging black hole population simulated with the rapid binary population synthesis code COMPAS. We investigate variations in four COMPAS parameters: common envelope efficiency, kick velocity dispersion, and mass loss rates during the luminous blue variable and Wolf--Rayet stellar evolutionary phases. We find that 1000 observations would constrain these model parameters to a fractional accuracy of a few percent. Given the empirically determined binary black hole merger rate, we can expect gravitational-wave observations alone to place strong constraints on the physics of stellar and binary evolution within a few years.",Accuracy of inference on the physics of binary evolution from gravitational-wave observations,"Comment: 12 pages, 9 figures; version accepted by Monthly Notices of the Royal Astronomical Society",Subject: High Energy Astrophysical Phenomena [astro-ph.HE],"Updated 9 days ago in May 16, 2018",2018-05-16T20:07:12Z,-
"Magdalena Larfors, Andre Lukas, Fabian Ruehle",Magdalena Larfors et al.,hep-th,High Energy Physics - Theory,hep-th,"27 pages, 3 tables",A:1805.08499,-,28,https://arxiv.org/pdf/1805.08499.pdf,2018-05-22T11:03:27Z,,"We show that non-trivial SU(3) structures can be constructed on large classes of Calabi-Yau three-folds. Specifically, we focus on Calabi-Yau three-folds constructed as complete intersections in products of projective spaces, although we expect similar methods to apply to other constructions and also to Calabi-Yau four-folds. Among the wide range of possible SU(3) structures we find Strominger-Hull systems, suitable for heterotic or type II string compactifications, on all complete intersection Calabi-Yau manifolds. These SU(3) structures of Strominger-Hull type have a non-vanishing and non-closed three-form flux which needs to be supported by source terms in the associated Bianchi identity. We discuss the possibility of finding such source terms and present first steps towards their explicit construction. Provided suitable sources exist, our methods lead to Calabi-Yau compactifications of string theory with a non Ricci-flat, physical metric which can be written down explicitly and in analytic form.",Calabi-Yau Manifolds and SU(3) Structure,"Comment: 27 pages, 3 tables",Subject: High Energy Physics - Theory [hep-th],"Published 4 days ago in May 22, 2018",2018-05-22T11:03:27Z,-
David R. Morrison,David R. Morrison,math.HO,History and Overview,math.HO,-,A:1805.06932,-,13,https://arxiv.org/pdf/1805.06932.pdf,2018-05-17T19:06:54Z,,We present some episodes from the history of interactions between geometry and physics over the past century.,Geometry and Physics: An Overview,Comment: [ 13 pages. ],Subject: History and Overview [math.HO],"Published 8 days ago in May 17, 2018",2018-05-17T19:06:54Z,-
"Konrad Zolna, Krzysztof J. Geras, Kyunghyun Cho",Konrad Zolna et al.,"cs.LG, cs.AI, cs.CV, cs.NE, stat.ML",Learning,cs.LG,-,A:1805.08249,-,27,https://arxiv.org/pdf/1805.08249.pdf,2018-05-21T18:36:52Z,,We argue for the importance of decoupling saliency map extraction from any specific classifier. We propose a practical algorithm to train a classifier-agnostic saliency mapping by simultaneously training a classifier and a saliency mapping. The proposed algorithm is motivated as finding the mapping that is not strongly coupled with any specific classifier. We qualitatively and quantitatively evaluate the proposed approach and verify that it extracts higher quality saliency maps compared to the existing approaches that are dependent on a fixed classifier. The proposed approach performs well even on images containing objects from classes unseen during training.,Classifier-agnostic saliency map extraction,Comment: [ 27 pages. ],Subject: Learning [cs.LG],"Published 4 days ago in May 21, 2018",2018-05-21T18:36:52Z,-
"Jing An, Jianfeng Lu, Lexing Ying",Jing An et al.,"stat.ML, cs.LG",Machine Learning,stat.ML,-,A:1805.08244,-,17,https://arxiv.org/pdf/1805.08244.pdf,2018-05-21T18:24:20Z,,"We propose a stochastic modified equations (SME) for modeling the asynchronous stochastic gradient descent (ASGD) algorithms. The resulting SME of Langevin type extracts more information about the ASGD dynamics and elucidates the relationship between different types of stochastic gradient algorithms. We show the convergence of ASGD to the SME in the continuous time limit, as well as the SME's precise prediction to the trajectories of ASGD with various forcing terms. As an application of the SME, we propose an optimal mini-batching strategy for ASGD via solving the optimal control problem of the associated SME.",Stochastic modified equations for the asynchronous stochastic gradient descent,Comment: [ 17 pages. ],Subject: Machine Learning [stat.ML],"Published 4 days ago in May 21, 2018",2018-05-21T18:24:20Z,-
"T. Cantat-Gaudin, C. Jordi, A. Vallenari, A. Bragaglia, L. Balaguer-Núñez, C. Soubiran, D. Bossini, A. Moitinho, A. Castro-Ginard, A. Krone-Martins, L. Casamiquela, R. Sordo, R. Carrera",T. Cantat-Gaudin et al.,astro-ph.GA,Astrophysics of Galaxies,astro-ph.GA,"17 pages, 11+20 figures, full data available as electronic tables",A:1805.08726,-,17,https://arxiv.org/pdf/1805.08726.pdf,2018-05-22T16:31:19Z,,"Open clusters are convenient probes of the structure and history of the Galactic disk. They are also fundamental to stellar evolution studies. The second Gaia data release contains precise astrometry at the sub-milliarcsecond level and homogeneous photometry at the mmag level, that can be used to characterise a large number of clusters over the entire sky. In this study we aim to a establish list of members and derive mean parameters, in particular distances, for as many clusters as possible, making use of Gaia data alone. We compile a list of thousands of known or putative clusters from the literature. We then apply an unsupervised membership assignment code, UPMASK, to the Gaia DR2 data contained within the fields of those clusters. We obtained a list of members and cluster parameters for 1212 clusters. As expected, the youngest clusters are seen to be tightly distributed near the Galactic plane and to trace the spiral arms of the Milky Way, while older objects are more uniformly distributed, deviate further from the plane, and tend to be located at larger Galactocentric distances. Thanks to the quality of GaiaDR2 astrometry, the fully homogeneous parameters derived in this study are the most precise to date. Furthermore, we report on the serendipitous discovery of 54 new open clusters in the fields analysed during this study.",A Gaia DR2 view of the Open Cluster population in the Milky Way,"Comment: 17 pages, 11+20 figures, full data available as electronic tables",Subject: Astrophysics of Galaxies [astro-ph.GA],"Published 3 days ago in May 22, 2018",2018-05-22T16:31:19Z,-
"Tara Safavi, Maryam Davoodi, Danai Koutra",Tara Safavi et al.,cs.SI,Social and Information Networks,cs.SI,To appear in KDD 2018,A:1805.06534,-,9,https://arxiv.org/pdf/1805.06534.pdf,2018-05-16T21:40:52Z,,"From artificial intelligence to network security to hardware design, it is well-known that computing research drives many important technological and societal advancements. However, less is known about the long-term career paths of the people behind these innovations. What do their careers reveal about the evolution of computing research? Which institutions were and are the most important in this field, and for what reasons? Can insights into computing career trajectories help predict employer retention? In this paper we analyze several decades of post-PhD computing careers using a large new dataset rich with professional information, and propose a versatile career network model, R^3, that captures temporal career dynamics. With R^3 we track important organizations in computing research history, analyze career movement between industry, academia, and government, and build a powerful predictive model for individual career transitions. Our study, the first of its kind, is a starting point for understanding computing research careers, and may inform employer recruitment and retention mechanisms at a time when the demand for specialized computational expertise far exceeds supply.",Career Transitions and Trajectories: A Case Study in Computing,Comment: To appear in KDD 2018,Subject: Social and Information Networks [cs.SI],"Published 10 days ago in May 16, 2018",2018-05-16T21:40:52Z,-
"Enrico Mariconti, Guillermo Suarez-Tangil, Jeremy Blackburn, Emiliano De Cristofaro, Nicolas Kourtellis, Ilias Leontiadis, Jordi Luque Serrano, Gianluca Stringhini",Enrico Mariconti et al.,"cs.CY, cs.CR, cs.SI",Computers and Society,cs.CY,-,A:1805.08168,-,14,https://arxiv.org/pdf/1805.08168.pdf,2018-05-21T16:41:57Z,,"Over the years, the Web has shrunk the world, allowing individuals to share viewpoints with many more people than they are able to in real life. At the same time, however, it has also enabled anti-social and toxic behavior to occur at an unprecedented scale. Video sharing platforms like YouTube receive uploads from millions of users, covering a wide variety of topics and allowing others to comment and interact in response. Unfortunately, these communities are periodically plagued with aggression and hate attacks. In particular, recent work has showed how these attacks often take place as a result of ""raids,"" i.e., organized efforts coordinated by ad-hoc mobs from third-party communities. Despite the increasing relevance of this phenomenon, online services often lack effective countermeasures to mitigate it. Unlike well-studied problems like spam and phishing, coordinated aggressive behavior both targets and is perpetrated by humans, making defense mechanisms that look for automated activity unsuitable. Therefore, the de-facto solution is to reactively rely on user reports and human reviews. In this paper, we propose an automated solution to identify videos that are likely to be targeted by coordinated harassers. First, we characterize and model YouTube videos along several axes (metadata, audio transcripts, thumbnails) based on a ground truth dataset of raid victims. Then, we use an ensemble of classifiers to determine the likelihood that a video will be raided with high accuracy (AUC up to 94%). Overall, our work paves the way for providing video platforms like YouTube with proactive systems to detect and mitigate coordinated hate attacks.","""You Know What to Do"": Proactive Detection of YouTube Videos Targeted by Coordinated Hate Attacks",Comment: [ 14 pages. ],Subject: Computers and Society [cs.CY],"Published 5 days ago in May 21, 2018",2018-05-21T16:41:57Z,-
"Kevis-Kokitsi Maninis, Sergi Caelles, Jordi Pont-Tuset, Luc Van Gool",Kevis-Kokitsi Maninis et al.,cs.CV,Computer Vision and Pattern Recognition,cs.CV,CVPR 2018 camera ready. Project webpage and code: http://www.vision.ee.ethz.ch/~cvlsegmentation/dextr/,A:1711.09081,-,10,https://arxiv.org/pdf/1711.09081.pdf,2017-11-24T18:54:35Z,,"This paper explores the use of extreme points in an object (left-most, right-most, top, bottom pixels) as input to obtain precise object segmentation for images and videos. We do so by adding an extra channel to the image in the input of a convolutional neural network (CNN), which contains a Gaussian centered in each of the extreme points. The CNN learns to transform this information into a segmentation of an object that matches those extreme points. We demonstrate the usefulness of this approach for guided segmentation (grabcut-style), interactive segmentation, video object segmentation, and dense segmentation annotation. We show that we obtain the most precise results to date, also with less user input, in an extensive and varied selection of benchmarks and datasets. All our models and code are publicly available on http://www.vision.ee.ethz.ch/~cvlsegmentation/dextr/.",Deep Extreme Cut: From Extreme Points to Object Segmentation,Comment: CVPR 2018 camera ready. Project webpage and code: http://www.vision.ee.ethz.ch/~cvlsegmentation/dextr/,Subject: Computer Vision and Pattern Recognition [cs.CV],"Updated in Mar 27, 2018",2018-03-27T11:47:16Z,-
"D. J. Lennon, C. J. Evans, R. P. van der Marel, J. Anderson, I. Platais, A. Herrero, S. E. de Mink, H. Sana, E. Sabbi, P. A. Crowther, N. Langer, M. Ramos Lerate, A. del Pino, M. Renzo, S. Simón-Díaz, F. R. N. Schneider",D. J. Lennon et al.,astro-ph.SR,Solar and Stellar Astrophysics,astro-ph.SR,-,A:1805.08277,-,7,https://arxiv.org/pdf/1805.08277.pdf,2018-05-21T20:06:18Z,,"A previous spectroscopic study identified the very massive O2 III star VFTS 16 in the Tarantula Nebula as a runaway star based on its peculiar line-of-sight velocity. We use the Gaia DR2 catalog to measure the relative proper motion of VFTS 16 and nearby bright stars to test if this star might have been ejected from the central cluster, R136, via dynamical ejection. We find that the position angle and magnitude of the relative proper motion (0.338 +/- 0.046 mas/yr, or approximately 80 +\- 11 km/s) of VFTS 16 are consistent with ejection from R136 approximately 1.5 +/- 0.2 Myr ago, very soon after the cluster was formed. There is some tension with the presumed age of VFTS 16 that, from published stellar parameters, cannot be greater than 0.9 +0.3/-0.2 Myr. Older ages for this star would appear to be prohibited due to the absence of He I lines in its optical spectrum, since this sets a firm lower limit on its effective temperature. The dynamical constraints may imply an unusual evolutionary history for this object, perhaps indicating it is a merger product. Gaia DR2 also confirms that another very massive star in the Tarantula Nebula, VFTS 72 (alias BI253; O2 III-V(n)((f*)), is also a runaway on the basis of its proper motion as measured by Gaia. While its tangential proper motion (0.392 +/-0.062 mas/yr or 93 +/-15 km/s) would be consistent with dynamical ejection from R136 approximately 1 Myr ago, its position angle is discrepant with this direction at the 2$\sigma$ level. From their Gaia DR2 proper motions we conclude that the two ~100 solar mass O2 stars, VFTS 16 and VFTS72, are fast runaway stars, with space velocities of around 100 km/s relative to R136 and the local massive star population. The dynamics of VFTS16 are consistent with it having been ejected from R136, and this star therefore sets a robust lower limit on the age of the central cluster of ~1.3 Myr.",Gaia DR2 reveals a very massive runaway star ejected from R136,Comment: [ 7 pages. ],Subject: Solar and Stellar Astrophysics [astro-ph.SR],"Published 5 days ago in May 21, 2018",2018-05-21T20:06:18Z,-
"Xi Chen, Yan Duan, Rein Houthooft, John Schulman, Ilya Sutskever, Pieter Abbeel",Xi Chen et al.,"cs.LG, stat.ML",Learning,cs.LG,-,A:1606.03657,-,14,https://arxiv.org/pdf/1606.03657.pdf,2016-06-12T02:14:31Z,,"This paper describes InfoGAN, an information-theoretic extension to the Generative Adversarial Network that is able to learn disentangled representations in a completely unsupervised manner. InfoGAN is a generative adversarial network that also maximizes the mutual information between a small subset of the latent variables and the observation. We derive a lower bound to the mutual information objective that can be optimized efficiently, and show that our training procedure can be interpreted as a variation of the Wake-Sleep algorithm. Specifically, InfoGAN successfully disentangles writing styles from digit shapes on the MNIST dataset, pose from lighting of 3D rendered images, and background digits from the central digit on the SVHN dataset. It also discovers visual concepts that include hair styles, presence/absence of eyeglasses, and emotions on the CelebA face dataset. Experiments show that InfoGAN learns interpretable representations that are competitive with representations learned by existing fully supervised methods.",InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets,Comment: [ 14 pages. ],Subject: Learning [cs.LG],"Published in Jun 12, 2016",2016-06-12T02:14:31Z,-
"Leon A. Gatys, Alexander S. Ecker, Matthias Bethge",Leon A. Gatys et al.,"cs.CV, cs.NE, q-bio.NC",Computer Vision and Pattern Recognition,cs.CV,-,A:1508.06576,-,16,https://arxiv.org/pdf/1508.06576.pdf,2015-08-26T17:14:42Z,,"In fine art, especially painting, humans have mastered the skill to create unique visual experiences through composing a complex interplay between the content and style of an image. Thus far the algorithmic basis of this process is unknown and there exists no artificial system with similar capabilities. However, in other key areas of visual perception such as object and face recognition near-human performance was recently demonstrated by a class of biologically inspired vision models called Deep Neural Networks. Here we introduce an artificial system based on a Deep Neural Network that creates artistic images of high perceptual quality. The system uses neural representations to separate and recombine content and style of arbitrary images, providing a neural algorithm for the creation of artistic images. Moreover, in light of the striking similarities between performance-optimised artificial neural networks and biological vision, our work offers a path forward to an algorithmic understanding of how humans create and perceive artistic imagery.",A Neural Algorithm of Artistic Style,Comment: [ 16 pages. ],Subject: Computer Vision and Pattern Recognition [cs.CV],"Updated in Sep 02, 2015",2015-09-02T08:24:59Z,-
"Benjamin Recht, Rebecca Roelofs, Ludwig Schmidt, Vaishaal Shankar",Benjamin Recht et al.,"cs.LG, stat.ML",Learning,cs.LG,-,A:1806.00451,-,25,https://arxiv.org/pdf/1806.00451.pdf,2018-06-01T17:16:56Z,,"Machine learning is currently dominated by largely experimental work focused on improvements in a few key tasks. However, the impressive accuracy numbers of the best performing models are questionable because the same test sets have been used to select these models for multiple years now. To understand the danger of overfitting, we measure the accuracy of CIFAR-10 classifiers by creating a new test set of truly unseen images. Although we ensure that the new test set is as close to the original data distribution as possible, we find a large drop in accuracy (4% to 10%) for a broad range of deep learning models. Yet more recent models with higher original accuracy show a smaller drop and better overall performance, indicating that this drop is likely not due to overfitting based on adaptivity. Instead, we view our results as evidence that current accuracy numbers are brittle and susceptible to even minute natural variations in the data distribution.",Do CIFAR-10 Classifiers Generalize to CIFAR-10?,Comment: [ 25 pages. ],Subject: Learning [cs.LG],"Published 3 days ago in Jun 01, 2018",2018-06-01T17:16:56Z,-
T. Daniel Brennan,T. Daniel Brennan,hep-th,High Energy Physics - Theory,hep-th,46 pages plus Appendix,A:1806.00024,-,57,https://arxiv.org/pdf/1806.00024.pdf,2018-05-31T18:00:26Z,,"In this paper, we propose a string theory description of generic 't Hooft defects in $\mathcal{N}=2$ $SU(N)$ supersymmetric gauge theories. We show that the space of supersymmetric ground states is given by the moduli space of singular monopoles and that in this setting, Kronheimer's correspondence is realized as T-duality. We conjecture that this brane configuration can be used to study the full dynamics of monopole bubbling.",Monopole Bubbling via String Theory,Comment: 46 pages plus Appendix,Subject: High Energy Physics - Theory [hep-th],"Published 5 days ago in May 31, 2018",2018-05-31T18:00:26Z,-
"Fekadu L. Bayisa, Xijia Liu, Anders Garpebring, Jun Yu",Fekadu L. Bayisa et al.,"stat.ME, stat.AP",Methodology,stat.ME,-,A:1805.11126,-,17,https://arxiv.org/pdf/1805.11126.pdf,2018-05-28T18:42:43Z,,"There is increasing interest in computed tomography (CT) image estimations from magnetic resonance (MR) images. This study aims to introduce a novel statistical learning approach for improving CT estimation from MR images. Prior knowledges about tissue-types, roughly speaking non-bone and bone tissue-types from CT images, have been used in collaboration with a Gaussian mixture model (GMM) to explore CT image estimations from MR images. Due to the introduced prior knowledges, GMMs were trained for each of the tissue-type. At the prediction stage, we have no CT image, that is there are no prior knowledges about the tissue-types and thereby we trained RUSBoost algorithm on the training dataset in order to estimate the tissue-types from MR images of the new patient. The estimated RUSBoost algorithm and GMMs were used to predict CT image from MR images of the new patient. We validated the RUSBoost algorithm by applying 10-fold cross-validation while the Gaussian mixture models were validated by using leave-one-out cross-validation of the datasets from the patients. In comparison with the existing model-based CT image estimation methods, the proposed method has improved the estimation, especially in bone tissues. More specifically, our method improved CT image estimation by 23 Hounsfield units (HU) and 6 HU on average for datasets obtained from nine and five patients, respectively. Bone tissue estimations have been improved by 107 HU and 62 HU on average for datasets from nine and five patients, respectively. Evaluation of our method shows that it is a promising method to generate CT image substitutes for the implementation of fully MR-based radiotherapy and PET/MRI applications. Keywords: Computed tomography; magnetic resonance imaging; CT image estimation; supervised learning; Gaussian mixture model",Statistical Methods in Computed Tomography Image Estimation,Comment: [ 17 pages. ],Subject: Methodology [stat.ME],"Published 8 days ago in May 28, 2018",2018-05-28T18:42:43Z,-
"Qirong Zhu, Dandan Xu, Massimo Gaspari, Vicente Rodriguez-Gomez, Dylan Nelson, Mark Vogelsberger, Paul Torrey, Annalisa Pillepich, Jolanta Zjupa, Rainer Weinberger, Federico Marinacci, Rüdiger Pakmor, Shy Genel, Yuexing Li, Volker Springel, Lars Hernquist",Qirong Zhu et al.,astro-ph.GA,Astrophysics of Galaxies,astro-ph.GA,"5 page, 5 figures; resubmitted to MNRAS Letters after first referee report; Comments welcome. Animations of gas/stars can be found here at https://youtu.be/Ibl4Cyybw2Q and https://youtu.be/3aIpCu6e9dQ, or downloaded at http://www.tng-project.org/movies/tng/TNG_Malin_1_gas.mpeg and http://www.tng-project.org/movies/tng/TNG_Malin_1_star.mpeg",A:1805.09341,-,5,https://arxiv.org/pdf/1805.09341.pdf,2018-05-23T18:00:06Z,,"The galaxy Malin 1 contains the largest stellar disk known but the formation mechanism of this structure has been elusive. In this paper, we report a Malin 1 analogue in the 100 Mpc IllustrisTNG simulation and describe its formation history. At redshift zero, this massive galaxy, having a maximum circular velocity $V_{\rm max}$ of 430 ${\rm km\ s^{-1}}$, contains a 100 kpc gas/stellar disk with morphology similar to Malin 1. The simulated galaxy reproduces well many observed features of Malin 1's vast disk, including its stellar ages, metallicities, and gas rotation curve. We trace the extended disk back in time and find that a large fraction of the cold gas at redshift zero originated from the cooling of hot halo gas, triggered by the merger of a pair of intruding galaxies. Our finding provides a novel way to form large galaxy disks as extreme as Malin 1 within the current galaxy formation framework.",Formation of a Malin 1 analogue in IllustrisTNG by stimulated accretion,"Comment: 5 page, 5 figures; resubmitted to MNRAS Letters after first referee report; Comments welcome. Animations of gas/stars can be found here at https://youtu.be/Ibl4Cyybw2Q and https://youtu.be/3aIpCu6e9dQ, or downloaded at http://www.tng-project.org/movies/tng/TNG_Malin_1_gas.mpeg and http://www.tng-project.org/movies/tng/TNG_Malin_1_star.mpeg",Subject: Astrophysics of Galaxies [astro-ph.GA],"Published 13 days ago in May 23, 2018",2018-05-23T18:00:06Z,-
"D. D. Liang, Y. J. Wang, C. Y. Xi, W. L. Zhen, J. Yang, L. Pi, C. J. Zhang, W. K. Zhu",D. D. Liang et al.,cond-mat.mtrl-sci,Materials Science,cond-mat.mtrl-sci,-,A:1805.09998,-,14,https://arxiv.org/pdf/1805.09998.pdf,2018-05-25T06:28:42Z,,"Rare earth monopnictides represent a novel electronic system for the extremely large magnetoresistance (XMR) and the potential to realize magnetic topological semimetal state, both of which are essential functionalities of electronic materials. In this material family, DySb is a special member, as it undergoes a tetragonal structural transition when it enters antiferromagnetic ground state. Such a ground state can be changed into a ferromagnetic state by magnetic field, via an intermediate phase. In the present paper, we study the electronic structures of DySb under high magnetic field (i.e., in the ferromagnetic state) from both experimental and theoretical aspects. A non-saturated XMR is observed (as large as 3.7*10^4% at 1.8 K and 38.7 T), along with Shubnikov-de Haas (SdH) oscillations. The SdH frequencies are well reproduced by our first principles calculations. Although a band inversion is found theoretically, suggesting that DySb is topologically nontrivial, it is deeply underneath the Fermi level, which rules out a topological nature of the XMR. The XMR is eventually attributed to the compensation mechanism, as evidenced by the nearly equal total densities of electron-like and hole-like carriers, and the high mobility that is associated with the linearly dispersive band at zone corner. This discovery is important to the intensive studies on the XMR of rare earth monopnictides.",Extreme magnetoresistance and Shubnikov-de Haas oscillations in ferromagnetic DySb,Comment: [ 14 pages. ],Subject: Materials Science [cond-mat.mtrl-sci],"Published 11 days ago in May 25, 2018",2018-05-25T06:28:42Z,-
"Nadia Boukhelifa, Anastasia Bezerianos, Evelyne Lutton",Nadia Boukhelifa et al.,"cs.AI, cs.HC",Artificial Intelligence,cs.AI,20,A:1801.07964,-,20,https://arxiv.org/pdf/1801.07964.pdf,2018-01-24T12:47:26Z,,"The evaluation of interactive machine learning systems remains a difficult task. These systems learn from and adapt to the human, but at the same time, the human receives feedback and adapts to the system. Getting a clear understanding of these subtle mechanisms of co-operation and co-adaptation is challenging. In this chapter, we report on our experience in designing and evaluating various interactive machine learning applications from different domains. We argue for coupling two types of validation: algorithm-centered analysis, to study the computational behaviour of the system; and human-centered evaluation, to observe the utility and effectiveness of the application for end-users. We use a visual analytics application for guided search, built using an interactive evolutionary approach, as an exemplar of our work. Our observation is that human-centered design and evaluation complement algorithmic analysis, and can play an important role in addressing the ""black-box"" effect of machine learning. Finally, we discuss research opportunities that require human-computer interaction methodologies, in order to support both the visible and hidden roles that humans play in interactive machine learning.",Evaluation of Interactive Machine Learning Systems,Comment: 20,Subject: Artificial Intelligence [cs.AI],"Published in Jan 24, 2018",2018-01-24T12:47:26Z,-
"Allison C. Morgan, Dimitrios Economou, Samuel F. Way, Aaron Clauset",Allison C. Morgan et al.,"cs.SI, cs.CY, physics.soc-ph",Social and Information Networks,cs.SI,"10 pages, 8 figures, 1 table",A:1805.09966,-,10,https://arxiv.org/pdf/1805.09966.pdf,2018-05-25T03:36:40Z,,"The spread of ideas in the scientific community is often viewed as a competition, in which good ideas spread further because of greater intrinsic fitness. As a result, it is commonly believed that publication venue and citation counts correlate with importance and impact. However, relatively little is known about how structural factors influence the spread of ideas, and specifically how where an idea originates can influence how it spreads. Here, we investigate the role of faculty hiring networks, which embody the set of researcher transitions from doctoral to faculty institutions, in shaping the spread of ideas in computer science, and the importance of where in the network an idea originates. We consider comprehensive data on the hiring events of 5,032 faculty at all 205 Ph.D.-granting departments of computer science in the U.S. and Canada, and on the timing and titles of 200,476 associated publications. Analyzing three popular research topics, we show empirically that faculty hiring plays a significant role in driving the spread of ideas across the community. We then use epidemic models to simulate the generic spread of research ideas and quantify the consequences of where an idea originates on its longterm diffusion across the network. We find that research from prestigious institutions spreads more quickly and completely than work of similar quality originating from less prestigious institutions. Our analyses establish the theoretical trade-offs between university prestige and the quality of ideas necessary for efficient circulation. These results suggest a lower bound for epistemic inequality, identify a mechanism for the persistent epistemic advantage observed for elite institutions, and highlight limitations for meritocratic ideals.",Prestige drives epistemic inequality in the diffusion of scientific ideas,"Comment: 10 pages, 8 figures, 1 table",Subject: Social and Information Networks [cs.SI],"Published 4 days ago in May 25, 2018",2018-05-25T03:36:40Z,-
"Yusuf Aytar, Tobias Pfaff, David Budden, Tom Le Paine, Ziyu Wang, Nando de Freitas",Yusuf Aytar et al.,"cs.LG, cs.AI, cs.CV, stat.ML",Learning,cs.LG,-,A:1805.11592,-,10,https://arxiv.org/pdf/1805.11592.pdf,2018-05-29T17:19:36Z,,"Deep reinforcement learning methods traditionally struggle with tasks where environment rewards are particularly sparse. One successful method of guiding exploration in these domains is to imitate trajectories provided by a human demonstrator. However, these demonstrations are typically collected under artificial conditions, i.e. with access to the agent's exact environment setup and the demonstrator's action and reward trajectories. Here we propose a two-stage method that overcomes these limitations by relying on noisy, unaligned footage without access to such data. First, we learn to map unaligned videos from multiple sources to a common representation using self-supervised objectives constructed over both time and modality (i.e. vision and sound). Second, we embed a single YouTube video in this representation to construct a reward function that encourages an agent to imitate human gameplay. This method of one-shot imitation allows our agent to convincingly exceed human-level performance on the infamously hard exploration games Montezuma's Revenge, Pitfall! and Private Eye for the first time, even if the agent is not presented with any environment rewards.",Playing hard exploration games by watching YouTube,Comment: [ 10 pages. ],Subject: Learning [cs.LG],"Published 5 days ago in May 29, 2018",2018-05-29T17:19:36Z,-
"The LIGO Scientific Collaboration, the Virgo Collaboration, B. P. Abbott, R. Abbott, T. D. Abbott, F. Acernese, K. Ackley, C. Adams, T. Adams, P. Addesso, R. X. Adhikari, V. B. Adya, C. Affeldt, B. Agarwal, M. Agathos, K. Agatsuma, N. Aggarwal, O. D. Aguiar, L. Aiello, A. Ain, P. Ajith, B. Allen, G. Allen, A. Allocca, M. A. Aloy, P. A. Altin, A. Amato, A. Ananyeva, S. B. Anderson, W. G. Anderson, S. V. Angelova, S. Antier, S. Appert, K. Arai, M. C. Araya, J. S. Areeda, M. Ar`ene, N. Arnaud, K. G. Arun, S. Ascenzi, G. Ashton, M. Ast, S. M. Aston, P. Astone, D. V. Atallah, F. Aubin, P. Aufmuth, C. Aulbert, K. AultONeal, C. Austin, A. Avila-Alvarez, S. Babak, P. Bacon, F. Badaracco, M. K. M. Bader, S. Bae, P. T. Baker, F. Baldaccini, G. Ballardin, S. W. Ballmer, S. Banagiri, J. C. Barayoga, S. E. Barclay, B. C. Barish, D. Barker, K. Barkett, S. Barnum, F. Barone, B. Barr, L. Barsotti, M. Barsuglia, D. Barta, J. Bartlett, I. Bartos, R. Bassiri, A. Basti, J. C. Batch, M. Bawaj, J. C. Bayley, M. Bazzan, B. B'ecsy, C. Beer, M. Bejger, I. Belahcene, A. S. Bell, D. Beniwal, M. Bensch, B. K. Berger, G. Bergmann, S. Bernuzzi, J. J. Bero, C. P. L. Berry, D. Bersanetti, A. Bertolini, J. Betzwieser, R. Bhandare, I. A. Bilenko, S. A. Bilgili, G. Billingsley, C. R. Billman, J. Birch, R. Birney, O. Birnholtz, S. Biscans, S. Biscoveanu, A. Bisht, M. Bitossi, M. A. Bizouard, J. K. Blackburn, J. Blackman, C. D. Blair, D. G. Blair, R. M. Blair, S. Bloemen, O. Bock, N. Bode, M. Boer, Y. Boetzel, G. Bogaert, A. Bohe, F. Bondu, E. Bonilla, R. Bonnand, P. Booker, B. A. Boom, C. D. Booth, R. Bork, V. Boschi, S. Bose, K. Bossie, V. Bossilkov, J. Bosveld, Y. Bouffanais, A. Bozzi, C. Bradaschia, P. R. Brady, A. Bramley, M. Branchesi, J. E. Brau, T. Briant, F. Brighenti, A. Brillet, M. Brinkmann, V. Brisson, P. Brockill, A. F. Brooks, D. D. Brown, S. Brunett, C. C. Buchanan, A. Buikema, T. Bulik, H. J. Bulten, A. Buonanno, D. Buskulic, C. Buy, R. L. Byer, M. Cabero, L. Cadonati, G. Cagnoli, C. Cahillane, J. Calder'on Bustillo, T. A. Callister, E. Calloni, J. B. Camp, M. Canepa, P. Canizares, K. C. Cannon, H. Cao, J. Cao, C. D. Capano, E. Capocasa, F. Carbognani, S. Caride, M. F. Carney, G. Carullo, J. Casanueva Diaz, C. Casentini, S. Caudill, M. Cavagli`a, F. Cavalier, R. Cavalieri, G. Cella, C. B. Cepeda, P. Cerd'a-Dur'an, G. Cerretani, E. Cesarini, O. Chaibi, S. J. Chamberlin, M. Chan, S. Chao, P. Charlton, E. Chase, E. Chassande-Mottin, D. Chatterjee, K. Chatziioannou, B. D. Cheeseboro, H. Y. Chen, X. Chen, Y. Chen, H. -P. Cheng, H. Y. Chia, A. Chincarini, A. Chiummo, T. Chmiel, H. S. Cho, M. Cho, J. H. Chow, N. Christensen, Q. Chu, A. J. K. Chua, S. Chua, K. W. Chung, S. Chung, G. Ciani, A. A. Ciobanu, R. Ciolfi, F. Cipriano, C. E. Cirelli, A. Cirone, F. Clara, J. A. Clark, P. Clearwater, F. Cleva, C. Cocchieri, E. Coccia, P. -F. Cohadon, D. Cohen, A. Colla, C. G. Collette, C. Collins, L. R. Cominsky, M. Constancio Jr., L. Conti, S. J. Cooper, P. Corban, T. R. Corbitt, I. Cordero-Carri'on, K. R. Corley, N. Cornish, A. Corsi, S. Cortese, C. A. Costa, R. Cotesta, M. W. Coughlin, S. B. Coughlin, J. -P. Coulon, S. T. Countryman, P. Couvares, P. B. Covas, E. E. Cowan, D. M. Coward, M. J. Cowart, D. C. Coyne, R. Coyne, J. D. E. Creighton, T. D. Creighton, J. Cripe, S. G. Crowder, T. J. Cullen, A. Cumming, L. Cunningham, E. Cuoco, T. Dal Canton, G. D'alya, S. L. Danilishin, S. D'Antonio, K. Danzmann, A. Dasgupta, C. F. Da Silva Costa, V. Dattilo, I. Dave, M. Davier, D. Davis, E. J. Daw, B. Day, D. DeBra, M. Deenadayalan, J. Degallaix, M. De Laurentis, S. Del'eglise, W. Del Pozzo, N. Demos, T. Denker, T. Dent, R. De Pietri, J. Derby, V. Dergachev, R. De Rosa, C. De Rossi, R. DeSalvo, O. de Varona, S. Dhurandhar, M. C. D'iaz, T. Dietrich, L. Di Fiore, M. Di Giovanni, T. Di Girolamo, A. Di Lieto, B. Ding, S. Di Pace, I. Di Palma, F. Di Renzo, A. Dmitriev, Z. Doctor, V. Dolique, F. Donovan, K. L. Dooley, S. Doravari, I. Dorrington, M. Dovale 'Alvarez, T. P. Downes, M. Drago, C. Dreissigacker, J. C. Driggers, Z. Du, P. Dupej, S. E. Dwyer, P. J. Easter, T. B. Edo, M. C. Edwards, A. Effler, H. -B. Eggenstein, P. Ehrens, J. Eichholz, S. S. Eikenberry, M. Eisenmann, R. A. Eisenstein, R. C. Essick, H. Estelles, D. Estevez, Z. B. Etienne, T. Etzel, M. Evans, T. M. Evans, V. Fafone, H. Fair, S. Fairhurst, X. Fan, S. Farinon, B. Farr, W. M. Farr, E. J. Fauchon-Jones, M. Favata, M. Fays, C. Fee, H. Fehrmann, J. Feicht, M. M. Fejer, F. Feng, A. Fernandez-Galiana, I. Ferrante, E. C. Ferreira, F. Ferrini, F. Fidecaro, I. Fiori, D. Fiorucci, M. Fishbach, R. P. Fisher, J. M. Fishner, M. Fitz-Axen, R. Flaminio, M. Fletcher, H. Fong, J. A. Font, P. W. F. Forsyth, S. S. Forsyth, J. -D. Fournier, S. Frasca, F. Frasconi, Z. Frei, A. Freise, R. Frey, V. Frey, P. Fritschel, V. V. Frolov, P. Fulda, M. Fyffe, H. A. Gabbard, B. U. Gadre, S. M. Gaebel, J. R. Gair, L. Gammaitoni, M. R. Ganija, S. G. Gaonkar, A. Garcia, C. Garc'ia-Quir'os, F. Garufi, B. Gateley, S. Gaudio, G. Gaur, V. Gayathri, G. Gemme, E. Genin, A. Gennai, D. George, J. George, L. Gergely, V. Germain, S. Ghonge, Abhirup Ghosh, Archisman Ghosh, S. Ghosh, B. Giacomazzo, J. A. Giaime, K. D. Giardina, A. Giazotto, K. Gill, G. Giordano, L. Glover, E. Goetz, R. Goetz, B. Goncharov, G. Gonz'alez, J. M. Gonzalez Castro, A. Gopakumar, M. L. Gorodetsky, S. E. Gossan, M. Gosselin, R. Gouaty, A. Grado, C. Graef, M. Granata, A. Grant, S. Gras, C. Gray, G. Greco, A. C. Green, R. Green, E. M. Gretarsson, P. Groot, H. Grote, S. Grunewald, P. Gruning, G. M. Guidi, H. K. Gulati, X. Guo, A. Gupta, M. K. Gupta, K. E. Gushwa, E. K. Gustafson, R. Gustafson, O. Halim, B. R. Hall, E. D. Hall, E. Z. Hamilton, H. F. Hamilton, G. Hammond, M. Haney, M. M. Hanke, J. Hanks, C. Hanna, M. D. Hannam, O. A. Hannuksela, J. Hanson, T. Hardwick, J. Harms, G. M. Harry, I. W. Harry, M. J. Hart, C. -J. Haster, K. Haughian, J. Healy, A. Heidmann, M. C. Heintze, H. Heitmann, P. Hello, G. Hemming, M. Hendry, I. S. Heng, J. Hennig, A. W. Heptonstall, F. J. Hernandez, M. Heurs, S. Hild, T. Hinderer, W. C. G. Ho, D. Hoak, S. Hochheim, D. Hofman, N. A. Holland, K. Holt, D. E. Holz, P. Hopkins, C. Horst, J. Hough, E. A. Houston, E. J. Howell, A. Hreibi, E. A. Huerta, D. Huet, B. Hughey, M. Hulko, S. Husa, S. H. Huttner, T. Huynh-Dinh, A. Iess, N. Indik, C. Ingram, R. Inta, G. Intini, B. S. Irwin, H. N. Isa, J. -M. Isac, M. Isi, B. R. Iyer, K. Izumi, T. Jacqmin, K. Jani, P. Jaranowski, D. S. Johnson, W. W. Johnson, D. I. Jones, R. Jones, R. J. G. Jonker, L. Ju, J. Junker, C. V. Kalaghatgi, V. Kalogera, B. Kamai, S. Kandhasamy, G. Kang, J. B. Kanner, S. J. Kapadia, S. Karki, K. S. Karvinen, M. Kasprzack, M. Katolik, S. Katsanevas, E. Katsavounidis, W. Katzman, S. Kaufer, K. Kawabe, N. V. Keerthana, F. K'ef'elian, D. Keitel, A. J. Kemball, R. Kennedy, J. S. Key, F. Y. Khalili, B. Khamesra, H. Khan, I. Khan, S. Khan, Z. Khan, E. A. Khazanov, N. Kijbunchoo, Chunglee Kim, J. C. Kim, K. Kim, W. Kim, W. S. Kim, Y. -M. Kim, E. J. King, P. J. King, M. Kinley-Hanlon, R. Kirchhoff, J. S. Kissel, L. Kleybolte, S. Klimenko, T. D. Knowles, P. Koch, S. M. Koehlenbeck, S. Koley, V. Kondrashov, A. Kontos, M. Korobko, W. Z. Korth, I. Kowalska, D. B. Kozak, C. Kr''amer, V. Kringel, B. Krishnan, A. Kr'olak, G. Kuehn, P. Kumar, R. Kumar, S. Kumar, L. Kuo, A. Kutynia, S. Kwang, B. D. Lackey, K. H. Lai, M. Landry, P. Landry, R. N. Lang, J. Lange, B. Lantz, R. K. Lanza, A. Lartaux-Vollard, P. D. Lasky, M. Laxen, A. Lazzarini, C. Lazzaro, P. Leaci, S. Leavey, C. H. Lee, H. K. Lee, H. M. Lee, H. W. Lee, K. Lee, J. Lehmann, A. Lenon, M. Leonardi, N. Leroy, N. Letendre, Y. Levin, J. Li, T. G. F. Li, X. Li, S. D. Linker, T. B. Littenberg, J. Liu, X. Liu, R. K. L. Lo, N. A. Lockerbie, L. T. London, A. Longo, M. Lorenzini, V. Loriette, M. Lormand, G. Losurdo, J. D. Lough, C. O. Lousto, G. Lovelace, H. L''uck, D. Lumaca, A. P. Lundgren, R. Lynch, Y. Ma, R. Macas, S. Macfoy, B. Machenschalk, M. MacInnis, D. M. Macleod, I. Magaña Hernandez, F. Magaña-Sandoval, L. Magaña Zertuche, R. M. Magee, E. Majorana, I. Maksimovic, N. Man, V. Mandic, V. Mangano, G. L. Mansell, M. Manske, M. Mantovani, F. Marchesoni, F. Marion, S. M'arka, Z. M'arka, C. Markakis, A. S. Markosyan, A. Markowitz, E. Maros, A. Marquina, F. Martelli, L. Martellini, I. W. Martin, R. M. Martin, D. V. Martynov, K. Mason, E. Massera, A. Masserot, T. J. Massinger, M. Masso-Reid, S. Mastrogiovanni, A. Matas, F. Matichard, L. Matone, N. Mavalvala, N. Mazumder, J. J. McCann, R. McCarthy, D. E. McClelland, S. McCormick, L. McCuller, S. C. McGuire, J. McIver, D. J. McManus, T. McRae, S. T. McWilliams, D. Meacher, G. D. Meadors, M. Mehmet, J. Meidam, E. Mejuto-Villa, A. Melatos, G. Mendell, D. Mendoza-Gandara, R. A. Mercer, L. Mereni, E. L. Merilh, M. Merzougui, S. Meshkov, C. Messenger, C. Messick, R. Metzdorff, P. M. Meyers, H. Miao, C. Michel, H. Middleton, E. E. Mikhailov, L. Milano, A. L. Miller, A. Miller, B. B. Miller, J. Miller, M. Millhouse, J. Mills, M. C. Milovich-Goff, O. Minazzoli, Y. Minenkov, J. Ming, C. Mishra, S. Mitra, V. P. Mitrofanov, G. Mitselmakher, R. Mittleman, D. Moffa, K. Mogushi, M. Mohan, S. R. P. Mohapatra, M. Montani, C. J. Moore, D. Moraru, G. Moreno, S. Morisaki, B. Mours, C. M. Mow-Lowry, G. Mueller, A. W. Muir, Arunava Mukherjee, D. Mukherjee, S. Mukherjee, N. Mukund, A. Mullavey, J. Munch, E. A. Muñiz, M. Muratore, P. G. Murray, A. Nagar, K. Napier, I. Nardecchia, L. Naticchioni, R. K. Nayak, J. Neilson, G. Nelemans, T. J. N. Nelson, M. Nery, A. Neunzert, L. Nevin, J. M. Newport, K. Y. Ng, S. Ng, P. Nguyen, T. T. Nguyen, D. Nichols, A. B. Nielsen, S. Nissanke, A. Nitz, F. Nocera, D. Nolting, C. North, L. K. Nuttall, M. Obergaulinger, J. Oberling, B. D. O'Brien, G. D. O'Dea, G. H. Ogin, J. J. Oh, S. H. Oh, F. Ohme, H. Ohta, M. A. Okada, M. Oliver, P. Oppermann, Richard J. Oram, B. O'Reilly, R. Ormiston, L. F. Ortega, R. O'Shaughnessy, S. Ossokine, D. J. Ottaway, H. Overmier, B. J. Owen, A. E. Pace, G. Pagano, J. Page, M. A. Page, A. Pai, S. A. Pai, J. R. Palamos, O. Palashov, C. Palomba, A. Pal-Singh, Howard Pan, Huang-Wei Pan, B. Pang, P. T. H. Pang, C. Pankow, F. Pannarale, B. C. Pant, F. Paoletti, A. Paoli, M. A. Papa, A. Parida, W. Parker, D. Pascucci, A. Pasqualetti, R. Passaquieti, D. Passuello, M. Patil, B. Patricelli, B. L. Pearlstone, C. Pedersen, M. Pedraza, R. Pedurand, L. Pekowsky, A. Pele, S. Penn, A. Perego, C. J. Perez, A. Perreca, L. M. Perri, H. P. Pfeiffer, M. Phelps, K. S. Phukon, O. J. Piccinni, M. Pichot, F. Piergiovanni, V. Pierro, G. Pillant, L. Pinard, I. M. Pinto, M. Pirello, M. Pitkin, R. Poggiani, P. Popolizio, E. K. Porter, L. Possenti, A. Post, J. Powell, J. Prasad, J. W. W. Pratt, G. Pratten, V. Predoi, T. Prestegard, M. Principe, S. Privitera, G. A. Prodi, L. G. Prokhorov, O. Puncken, M. Punturo, P. Puppo, M. P''urrer, H. Qi, V. Quetschke, E. A. Quintero, R. Quitzow-James, F. J. Raab, D. S. Rabeling, H. Radkins, P. Raffai, S. Raja, C. Rajan, B. Rajbhandari, M. Rakhmanov, K. E. Ramirez, A. Ramos-Buades, Javed Rana, P. Rapagnani, V. Raymond, M. Razzano, J. Read, T. Regimbau, L. Rei, S. Reid, D. H. Reitze, W. Ren, F. Ricci, P. M. Ricker, G. M. Riemenschneider, K. Riles, M. Rizzo, N. A. Robertson, R. Robie, F. Robinet, T. Robson, A. Rocchi, L. Rolland, J. G. Rollins, V. J. Roma, R. Romano, C. L. Romel, J. H. Romie, D. Rosi'nska, M. P. Ross, S. Rowan, A. R''udiger, P. Ruggi, G. Rutins, K. Ryan, S. Sachdev, T. Sadecki, M. Sakellariadou, L. Salconi, M. Saleem, F. Salemi, A. Samajdar, L. Sammut, L. M. Sampson, E. J. Sanchez, L. E. Sanchez, N. Sanchis-Gual, V. Sandberg, J. R. Sanders, N. Sarin, B. Sassolas, B. S. Sathyaprakash, P. R. Saulson, O. Sauter, R. L. Savage, A. Sawadsky, P. Schale, M. Scheel, J. Scheuer, P. Schmidt, R. Schnabel, R. M. S. Schofield, A. Sch''onbeck, E. Schreiber, D. Schuette, B. W. Schulte, B. F. Schutz, S. G. Schwalbe, J. Scott, S. M. Scott, E. Seidel, D. Sellers, A. S. Sengupta, D. Sentenac, V. Sequino, A. Sergeev, Y. Setyawati, D. A. Shaddock, T. J. Shaffer, A. A. Shah, M. S. Shahriar, M. B. Shaner, L. Shao, B. Shapiro, P. Shawhan, H. Shen, D. H. Shoemaker, D. M. Shoemaker, K. Siellez, X. Siemens, M. Sieniawska, D. Sigg, A. D. Silva, L. P. Singer, A. Singh, A. Singhal, A. M. Sintes, B. J. J. Slagmolen, T. J. Slaven-Blair, B. Smith, J. R. Smith, R. J. E. Smith, S. Somala, E. J. Son, B. Sorazu, F. Sorrentino, T. Souradeep, A. P. Spencer, A. K. Srivastava, K. Staats, M. Steinke, J. Steinlechner, S. Steinlechner, D. Steinmeyer, B. Steltner, S. P. Stevenson, D. Stocks, R. Stone, D. J. Stops, K. A. Strain, G. Stratta, S. E. Strigin, A. Strunk, R. Sturani, A. L. Stuver, T. Z. Summerscales, L. Sun, S. Sunil, J. Suresh, P. J. Sutton, B. L. Swinkels, M. J. Szczepa'nczyk, M. Tacca, S. C. Tait, C. Talbot, D. Talukder, D. B. Tanner, M. T'apai, A. Taracchini, J. D. Tasson, J. A. Taylor, R. Taylor, S. V. Tewari, T. Theeg, F. Thies, E. G. Thomas, M. Thomas, P. Thomas, K. A. Thorne, E. Thrane, S. Tiwari, V. Tiwari, K. V. Tokmakov, K. Toland, M. Tonelli, Z. Tornasi, A. Torres-Forn'e, C. I. Torrie, D. T''oyr''a, F. Travasso, G. Traylor, J. Trinastic, M. C. Tringali, A. Trovato, L. Trozzo, K. W. Tsang, M. Tse, R. Tso, D. Tsuna, L. Tsukada, D. Tuyenbayev, K. Ueno, D. Ugolini, A. L. Urban, S. A. Usman, H. Vahlbruch, G. Vajente, G. Valdes, N. van Bakel, M. van Beuzekom, J. F. J. van den Brand, C. Van Den Broeck, D. C. Vander-Hyde, L. van der Schaaf, J. V. van Heijningen, A. A. van Veggel, M. Vardaro, V. Varma, S. Vass, M. Vas'uth, A. Vecchio, G. Vedovato, J. Veitch, P. J. Veitch, K. Venkateswara, G. Venugopalan, D. Verkindt, F. Vetrano, A. Vicer'e, A. D. Viets, S. Vinciguerra, D. J. Vine, J. -Y. Vinet, S. Vitale, T. Vo, H. Vocca, C. Vorvick, S. P. Vyatchanin, A. R. Wade, L. E. Wade, M. Wade, R. Walet, M. Walker, L. Wallace, S. Walsh, G. Wang, H. Wang, J. Z. Wang, W. H. Wang, Y. F. Wang, R. L. Ward, J. Warner, M. Was, J. Watchi, B. Weaver, L. -W. Wei, M. Weinert, A. J. Weinstein, R. Weiss, F. Wellmann, L. Wen, E. K. Wessel, P. Wessels, J. Westerweck, K. Wette, J. T. Whelan, B. F. Whiting, C. Whittle, D. Wilken, D. Williams, R. D. Williams, A. R. Williamson, J. L. Willis, B. Willke, M. H. Wimmer, W. Winkler, C. C. Wipf, H. Wittel, G. Woan, J. Woehler, J. K. Wofford, W. K. Wong, J. Worden, J. L. Wright, D. S. Wu, D. M. Wysocki, S. Xiao, W. Yam, H. Yamamoto, C. C. Yancey, L. Yang, M. J. Yap, M. Yazback, Hang Yu, Haocun Yu, M. Yvert, A. Zadro. zny, M. Zanolin, T. Zelenova, J. -P. Zendri, M. Zevin, J. Zhang, L. Zhang, M. Zhang, T. Zhang, Y. -H. Zhang, C. Zhao, M. Zhou, Z. Zhou, S. J. Zhu, X. J. Zhu, A. B. Zimmerman, Y. Zlochower, M. E. Zucker, J. Zweizig",The LIGO Scientific Collaboration et al.,"gr-qc, astro-ph.HE",General Relativity and Quantum Cosmology,gr-qc,-,A:1805.11581,-,16,https://arxiv.org/pdf/1805.11581.pdf,2018-05-29T16:56:13Z,,"On August 17, 2017, the LIGO and Virgo observatories made the first direct detection of gravitational waves from the coalescence of a neutron star binary system. The detection of this gravitational wave signal, GW170817, offers a novel opportunity to directly probe the properties of matter at the extreme conditions found in the interior of these stars. The initial, minimal-assumption analysis of the LIGO and Virgo data placed constraints on the tidal effects of the coalescing bodies, which were then translated to constraints on neutron star radii. Here, we expand upon previous analyses by working under the hypothesis that both bodies were neutron stars that are described by the same equation of state and have spins within the range observed in Galactic binary neutron stars. Our analysis employs two methods: the use of equation-of-state-insensitive relations between various macroscopic properties of the neutron stars and the use of an efficient parameterization of the defining function $p(\rho)$ of the equation of state itself. From the LIGO and Virgo data alone and the first method, we measure the two neutron star radii as $R_1=10.8^{+2.0}_{-1.7}$ km for the heavier star and $R_2= 10.7^{+2.1}_{-1.5}$ km for the lighter star at the 90% credible level. If we additionally require that the equation of state supports neutron stars with masses larger than $1.97 \,M_\odot$ as required from electromagnetic observations and employ the equation of state parametrization, we further constrain $R_1= 11.9^{+1.4}_{-1.4}$ km and $R_2= 11.9^{+1.4}_{-1.4}$ km at the 90% credible level. Finally, we obtain constraints on $p(\rho)$ at supranuclear densities, with pressure at twice nuclear saturation density measured at $3.5^{+2.7}_{-1.7}\times 10^{34} \,\mathrm{dyn}/\mathrm{cm}^{2}$ at the 90% level.",GW170817: Measurements of neutron star radii and equation of state,Comment: [ 16 pages. ],Subject: General Relativity and Quantum Cosmology [gr-qc],"Published 5 days ago in May 29, 2018",2018-05-29T16:56:13Z,-
"MiniBooNE Collaboration, A. A. Aguilar-Arevalo, B. C. Brown, L. Bugel, G. Cheng, J. M. Conrad, R. L. Cooper, R. Dharmapalan, A. Diaz, Z. Djurcic, D. A. Finley, R. Ford, F. G. Garcia, G. T. Garvey, J. Grange, E. -C. Huang, W. Huelsnitz, C. Ignarra, R. A. Johnson, G. Karagiorgi, T. Katori, T. Kobilarcik, W. C. Louis, C. Mariani, W. Marsh, G. B. Mills, J. Mirabal, J. Monroe, C. D. Moore, J. Mousseau, P. Nienaber, J. Nowak, B. Osmanov, Z. Pavlovic, D. Perevalov, H. Ray, B. P. Roe, A. D. Russell, M. H. Shaevitz, J. Spitz, I. Stancu, R. Tayloe, R. T. Thornton, M. Tzanov, R. G. Van de Water, D. H. White, D. A. Wickremasinghe, E. D. Zimmerman",MiniBooNE Collaboration et al.,"hep-ex, hep-ph",High Energy Physics - Experiment,hep-ex,-,A:1805.12028,-,12,https://arxiv.org/pdf/1805.12028.pdf,2018-05-30T15:13:20Z,,"The MiniBooNE experiment at Fermilab reports results from an analysis of $\nu_e$ appearance data from $12.84 \times 10^{20}$ protons on target in neutrino mode, an increase of approximately a factor of two over previously reported results. A $\nu_e$ charged-current quasi-elastic event excess of $381.2 \pm 85.2$ events ($4.5 \sigma$) is observed in the energy range $200<E_\nu^{QE}<1250$~MeV. Combining these data with the $\bar \nu_e$ appearance data from $11.27 \times 10^{20}$ protons on target in antineutrino mode, a total $\nu_e$ plus $\bar \nu_e$ charged-current quasi-elastic event excess of $460.5 \pm 95.8$ events ($4.8 \sigma$) is observed. If interpreted in a standard two-neutrino oscillation model, ${\nu}_{\mu} \rightarrow {\nu}_e$, the best oscillation fit to the excess has a probability of $20.1\%$ while the background-only fit has a $\chi^2$-probability of $5 \times 10^{-7}$ relative to the best fit. The MiniBooNE data are consistent in energy and magnitude with the excess of events reported by the Liquid Scintillator Neutrino Detector (LSND), and the significance of the combined LSND and MiniBooNE excesses is $6.1 \sigma$. All of the major backgrounds are constrained by in-situ event measurements, so non-oscillation explanations would need to invoke new anomalous background processes. Although the data are fit with a standard oscillation model, other models may provide better fits to the data.",Observation of a Significant Excess of Electron-Like Events in the MiniBooNE Short-Baseline Neutrino Experiment,Comment: [ 12 pages. ],Subject: High Energy Physics - Experiment [hep-ex],"Published 6 days ago in May 30, 2018",2018-05-30T15:13:20Z,-
"Lucas Theis, Iryna Korshunova, Alykhan Tejani, Ferenc Huszár",Lucas Theis et al.,"cs.CV, stat.ML",Computer Vision and Pattern Recognition,cs.CV,-,A:1801.05787,-,10,https://arxiv.org/pdf/1801.05787.pdf,2018-01-17T18:34:33Z,,"Predicting human fixations from images has recently seen large improvements by leveraging deep representations which were pretrained for object recognition. However, as we show in this paper, these networks are highly overparameterized for the task of fixation prediction. We first present a simple yet principled greedy pruning method which we call Fisher pruning. Through a combination of knowledge distillation and Fisher pruning, we obtain much more runtime-efficient architectures for saliency prediction, achieving a 10x speedup for the same AUC performance as a state of the art network on the CAT2000 dataset. Speeding up single-image gaze prediction is important for many real-world applications, but it is also a crucial step in the development of video saliency models, where the amount of data to be processed is substantially larger.",Faster gaze prediction with dense networks and Fisher pruning,Comment: [ 10 pages. ],Subject: Computer Vision and Pattern Recognition [cs.CV],"Published in Jan 17, 2018",2018-01-17T18:34:33Z,-
"Nate Zou, Eric Li, Henry Zhang",Nate Zou et al.,cs.DC,"Distributed, Parallel, and Cluster Computing",cs.DC,-,A:1805.11510,-,15,https://arxiv.org/pdf/1805.11510.pdf,2018-05-25T19:25:02Z,,"The efficiency of decentralized book systems like Bitcoin and Ethereum has always been a challenge. It is usually measured by three major factors: scalability, throughput, and latency. Scalability refers to how the system capacity is increased by adding more physical resources. Throughput measures the volume of transactions for a given period of time, where most current solutions attempt to improve such as NEO, EOS, etc. Latency measures the processing time of any single transaction. In current blockchain based systems, the block generation rate is the main latency bottleneck. Off-chain processes such as state channels are the most recent work that can integrate partial inbound transactions, reducing latency. Unfortunately, the state channel introduces more issues at the same time, such as cross-channel synchronization, which makes the state channel unavailable for full adoption of current blockchain solutions. In order to solve the efficiency problem, we proposed an end-to-end solution called ALZA, which links the dedicated high-throughput blockchain with self-organizing payment fields. This mechanism allows arbitrary set of users to create payment fields that process extremely low latency transactions within each field. Therefore, users can make transactions almost immediately. Since all transactions are conducted within fields, transaction costs will be reduced by several orders of magnitude. In addition, ALZA distributes main ledger to each client through an innovative replication mechanism. Therefore, the system will be significantly more robust to blockchain system failures. In theory, ALZA can complete millions of transactions in one second, which naturally supports high-frequency trading.",ALZA: An Efficient Hybrid Decentralized Payment System,Comment: [ 15 pages. ],"Subject: Distributed, Parallel, and Cluster Computing [cs.DC]","Published 11 days ago in May 25, 2018",2018-05-25T19:25:02Z,-
Lucianne M. Walkowicz,Lucianne M. Walkowicz,"physics.ed-ph, astro-ph.CO, astro-ph.EP, astro-ph.GA, astro-ph.HE, astro-ph.SR",Physics Education,physics.ed-ph,Essay based on a talk given at the 2018 NSF Astronomy and Astrophysics Postdoctoral Fellows Symposium,A:1805.09963,-,6,https://arxiv.org/pdf/1805.09963.pdf,2018-05-25T03:35:13Z,,"We've all heard how academia evaluates our work: papers, papers, and... more papers. While academic publishing is an essential part of disseminating research results, it is only one activity amongst many that make up a career (or for that matter, a life). The following essay is based on an invited talk for the NSF AAPF Symposium, given at the 2018 Winter AAS Meeting. Here, as in the original talk, I offer some practical advice for thinking about one's work within the larger frame of your personal values and goals. While I will draw examples from my own career, I hope to offer readers guidance in articulating what is important to them, aligning their career choices with those values, and establishing metrics that go beyond the h-index.",Choose Your Own Adventure: Developing A Values-Oriented Framework for Your Career,Comment: Essay based on a talk given at the 2018 NSF Astronomy and Astrophysics Postdoctoral Fellows Symposium,Subject: Physics Education [physics.ed-ph],"Published 11 days ago in May 25, 2018",2018-05-25T03:35:13Z,-
"Shibani Santurkar, Dimitris Tsipras, Andrew Ilyas, Aleksander Madry",Shibani Santurkar et al.,"stat.ML, cs.LG, cs.NE",Machine Learning,stat.ML,-,A:1805.11604,-,23,https://arxiv.org/pdf/1805.11604.pdf,2018-05-29T17:42:00Z,,"Batch Normalization (BatchNorm) is a widely adopted technique that enables faster and more stable training of deep neural networks (DNNs). Despite its pervasiveness, the exact reasons for BatchNorm's effectiveness are still poorly understood. The popular belief is that this effectiveness stems from controlling the change of the layers' input distributions during training to reduce the so-called ""internal covariate shift"". In this work, we demonstrate that such distributional stability of layer inputs has little to do with the success of BatchNorm. Instead, we uncover a more fundamental impact of BatchNorm on the training process: it makes the optimization landscape significantly smoother. This smoothness induces a more predictive and stable behavior of the gradients, allowing for faster training. These findings bring us closer to a true understanding of our DNN training toolkit.","How Does Batch Normalization Help Optimization? (No, It Is Not About Internal Covariate Shift)",Comment: [ 23 pages. ],Subject: Machine Learning [stat.ML],Updated today,2018-06-05T16:07:57Z,-
"Jochen Gast, Stefan Roth",Jochen Gast et al.,"cs.CV, cs.LG, stat.ML",Computer Vision and Pattern Recognition,cs.CV,To appear at CVPR 2018,A:1805.11327,-,18,https://arxiv.org/pdf/1805.11327.pdf,2018-05-29T09:40:52Z,,"Even though probabilistic treatments of neural networks have a long history, they have not found widespread use in practice. Sampling approaches are often too slow already for simple networks. The size of the inputs and the depth of typical CNN architectures in computer vision only compound this problem. Uncertainty in neural networks has thus been largely ignored in practice, despite the fact that it may provide important information about the reliability of predictions and the inner workings of the network. In this paper, we introduce two lightweight approaches to making supervised learning with probabilistic deep networks practical: First, we suggest probabilistic output layers for classification and regression that require only minimal changes to existing networks. Second, we employ assumed density filtering and show that activation uncertainties can be propagated in a practical fashion through the entire network, again with minor changes. Both probabilistic networks retain the predictive power of the deterministic counterpart, but yield uncertainties that correlate well with the empirical error induced by their predictions. Moreover, the robustness to adversarial examples is significantly increased.",Lightweight Probabilistic Deep Networks,Comment: To appear at CVPR 2018,Subject: Computer Vision and Pattern Recognition [cs.CV],"Published 7 days ago in May 29, 2018",2018-05-29T09:40:52Z,-
"Trapit Bansal, Jakub Pachocki, Szymon Sidor, Ilya Sutskever, Igor Mordatch",Trapit Bansal et al.,cs.AI,Artificial Intelligence,cs.AI,Published as a conference paper at ICLR 2018,A:1710.03748,-,12,https://arxiv.org/pdf/1710.03748.pdf,2017-10-10T17:59:41Z,,"Reinforcement learning algorithms can train agents that solve problems in complex, interesting environments. Normally, the complexity of the trained agent is closely related to the complexity of the environment. This suggests that a highly capable agent requires a complex environment for training. In this paper, we point out that a competitive multi-agent environment trained with self-play can produce behaviors that are far more complex than the environment itself. We also point out that such environments come with a natural curriculum, because for any skill level, an environment full of agents of this level will have the right level of difficulty. This work introduces several competitive multi-agent environments where agents compete in a 3D world with simulated physics. The trained agents learn a wide variety of complex and interesting skills, even though the environment themselves are relatively simple. The skills include behaviors such as running, blocking, ducking, tackling, fooling opponents, kicking, and defending using both arms and legs. A highlight of the learned behaviors can be found here: https://goo.gl/eR7fbX",Emergent Complexity via Multi-Agent Competition,Comment: Published as a conference paper at ICLR 2018,Subject: Artificial Intelligence [cs.AI],"Updated in Mar 14, 2018",2018-03-14T21:09:49Z,-
"Nicola De Cao, Thomas Kipf",Nicola De Cao et al.,"stat.ML, cs.LG",Machine Learning,stat.ML,"11 pages, 3 figures, 3 tables",A:1805.11973,"Machine Learning, ICML, DGM, GAN, RL",11,https://arxiv.org/pdf/1805.11973.pdf,2018-05-30T13:56:06Z,,"Deep generative models for graph-structured data offer a new angle on the problem of chemical synthesis: by optimizing differentiable models that directly generate molecular graphs, it is possible to side-step expensive search procedures in the discrete and vast space of chemical structures. We introduce MolGAN, an implicit, likelihood-free generative model for small molecular graphs that circumvents the need for expensive graph matching procedures or node ordering heuristics of previous likelihood-based methods. Our method adapts generative adversarial networks (GANs) to operate directly on graph-structured data. We combine our approach with a reinforcement learning objective to encourage the generation of molecules with specific desired chemical properties. In experiments on the QM9 chemical database, we demonstrate that our model is capable of generating close to 100% valid compounds. MolGAN compares favorably both to recent proposals that use string-based (SMILES) representations of molecules and to a likelihood-based method that directly generates graphs, albeit being susceptible to mode collapse.",MolGAN: An implicit generative model for small molecular graphs,"Comment: 11 pages, 3 figures, 3 tables",Subject: Machine Learning [stat.ML],"Published 6 days ago in May 30, 2018",2018-05-30T13:56:06Z,-
"Ian Simon, Adam Roberts, Colin Raffel, Jesse Engel, Curtis Hawthorne, Douglas Eck",Ian Simon et al.,"stat.ML, cs.LG, cs.SD, eess.AS",Machine Learning,stat.ML,-,A:1806.00195,-,8,https://arxiv.org/pdf/1806.00195.pdf,2018-06-01T04:59:05Z,,"Discovering and exploring the underlying structure of multi-instrumental music using learning-based approaches remains an open problem. We extend the recent MusicVAE model to represent multitrack polyphonic measures as vectors in a latent space. Our approach enables several useful operations such as generating plausible measures from scratch, interpolating between measures in a musically meaningful way, and manipulating specific musical attributes. We also introduce chord conditioning, which allows all of these operations to be performed while keeping harmony fixed, and allows chords to be changed while maintaining musical ""style"". By generating a sequence of measures over a predefined chord progression, our model can produce music with convincing long-term structure. We demonstrate that our latent space model makes it possible to intuitively control and generate musical sequences with rich instrumentation (see https://goo.gl/s2N7dV for generated audio).",Learning a Latent Space of Multitrack Measures,Comment: [ 8 pages. ],Subject: Machine Learning [stat.ML],"Published 4 days ago in Jun 01, 2018",2018-06-01T04:59:05Z,-
"Liwen Zhang, Gregory Naitzat, Lek-Heng Lim",Liwen Zhang et al.,"cs.LG, math.AG, stat.ML, 14T05, 62M45, 68T01",Learning,cs.LG,"18 pages, 6 figures",A:1805.07091,"Neural network, tropical geometry",18,https://arxiv.org/pdf/1805.07091.pdf,2018-05-18T08:30:50Z,,"We establish, for the first time, connections between feedforward neural networks with ReLU activation and tropical geometry --- we show that the family of such neural networks is equivalent to the family of tropical rational maps. Among other things, we deduce that feedforward ReLU neural networks with one hidden layer can be characterized by zonotopes, which serve as building blocks for deeper networks; we relate decision boundaries of such neural networks to tropical hypersurfaces, a major object of study in tropical geometry; and we prove that linear regions of such neural networks correspond to vertices of polytopes associated with tropical rational functions. An insight from our tropical formulation is that a deeper network is exponentially more expressive than a shallow network.",Tropical Geometry of Deep Neural Networks,"Comment: 18 pages, 6 figures",Subject: Learning [cs.LG],"Published 19 days ago in May 18, 2018",2018-05-18T08:30:50Z,-
"Kota Yoshida, Munetaka Minoguchi, Kenichiro Wani, Akio Nakamura, Hirokatsu Kataoka",Kota Yoshida et al.,"cs.CV, cs.CL",Computer Vision and Pattern Recognition,cs.CV,Accepted to CVPR 2018 Language & Vision Workshop,A:1805.11850,-,4,https://arxiv.org/pdf/1805.11850.pdf,2018-05-30T08:20:55Z,,"What is an effective expression that draws laughter from human beings? In the present paper, in order to consider this question from an academic standpoint, we generate an image caption that draws a ""laugh"" by a computer. A system that outputs funny captions based on the image caption proposed in the computer vision field is constructed. Moreover, we also propose the Funny Score, which flexibly gives weights according to an evaluation database. The Funny Score more effectively brings out ""laughter"" to optimize a model. In addition, we build a self-collected BoketeDB, which contains a theme (image) and funny caption (text) posted on ""Bokete"", which is an image Ogiri website. In an experiment, we use BoketeDB to verify the effectiveness of the proposed method by comparing the results obtained using the proposed method and those obtained using MS COCO Pre-trained CNN+LSTM, which is the baseline and idiot created by humans. We refer to the proposed method, which uses the BoketeDB pre-trained model, as the Neural Joking Machine (NJM).",Neural Joking Machine : Humorous image captioning,Comment: Accepted to CVPR 2018 Language & Vision Workshop,Subject: Computer Vision and Pattern Recognition [cs.CV],"Published 7 days ago in May 30, 2018",2018-05-30T08:20:55Z,-
"Nicholas Guttenberg, Martin Biehl, Nathaniel Virgo, Ryota Kanai",Nicholas Guttenberg et al.,"cs.AI, cs.NE, stat.ML",Artificial Intelligence,cs.AI,"8 pages, 7 figures, ALife 2018",A:1806.00201,-,8,https://arxiv.org/pdf/1806.00201.pdf,2018-06-01T05:32:47Z,,"We investigate the use of attentional neural network layers in order to learn a `behavior characterization' which can be used to drive novelty search and curiosity-based policies. The space is structured towards answering a particular distribution of questions, which are used in a supervised way to train the attentional neural network. We find that in a 2d exploration task, the structure of the space successfully encodes local sensory-motor contingencies such that even a greedy local `do the most novel action' policy with no reinforcement learning or evolution can explore the space quickly. We also apply this to a high/low number guessing game task, and find that guessing according to the learned attention profile performs active inference and can discover the correct number more quickly than an exact but passive approach.",Being curious about the answers to questions: novelty search with learned attention,"Comment: 8 pages, 7 figures, ALife 2018",Subject: Artificial Intelligence [cs.AI],"Published 5 days ago in Jun 01, 2018",2018-06-01T05:32:47Z,-
"Reina Akama, Kento Watanabe, Sho Yokoi, Sosuke Kobayashi, Kentaro Inui",Reina Akama et al.,cs.CL,Computation and Language,cs.CL,"7 pages, Accepted at The 56th Annual Meeting of the Association for Computational Linguistics (ACL 2018)",A:1805.05581,-,7,https://arxiv.org/pdf/1805.05581.pdf,2018-05-15T06:19:12Z,,"This paper presents the first study aimed at capturing stylistic similarity between words in an unsupervised manner. We propose extending the continuous bag of words (CBOW) model (Mikolov et al., 2013) to learn style-sensitive word vectors using a wider context window under the assumption that the style of all the words in an utterance is consistent. In addition, we introduce a novel task to predict lexical stylistic similarity and to create a benchmark dataset for this task. Our experiment with this dataset supports our assumption and demonstrates that the proposed extensions contribute to the acquisition of style-sensitive word embeddings.",Unsupervised Learning of Style-sensitive Word Vectors,"Comment: 7 pages, Accepted at The 56th Annual Meeting of the Association for Computational Linguistics (ACL 2018)",Subject: Computation and Language [cs.CL],"Published 22 days ago in May 15, 2018",2018-05-15T06:19:12Z,-
"Genta Indra Winata, Onno Pepijn Kampman, Pascale Fung",Genta Indra Winata et al.,cs.CL,Computation and Language,cs.CL,Accepted in ICASSP 2018,A:1805.12307,-,5,https://arxiv.org/pdf/1805.12307.pdf,2018-05-31T03:27:53Z,,"We propose a Long Short-Term Memory (LSTM) with attention mechanism to classify psychological stress from self-conducted interview transcriptions. We apply distant supervision by automatically labeling tweets based on their hashtag content, which complements and expands the size of our corpus. This additional data is used to initialize the model parameters, and which it is fine-tuned using the interview data. This improves the model's robustness, especially by expanding the vocabulary size. The bidirectional LSTM model with attention is found to be the best model in terms of accuracy (74.1%) and f-score (74.3%). Furthermore, we show that distant supervision fine-tuning enhances the model's performance by 1.6% accuracy and 2.1% f-score. The attention mechanism helps the model to select informative words.",Attention-Based LSTM for Psychological Stress Detection from Spoken Language Using Distant Supervision,Comment: Accepted in ICASSP 2018,Subject: Computation and Language [cs.CL],"Published 6 days ago in May 31, 2018",2018-05-31T03:27:53Z,-
"The LIGO Scientific Collaboration, the Virgo Collaboration, B. P. Abbott, R. Abbott, T. D. Abbott, F. Acernese, K. Ackley, C. Adams, T. Adams, P. Addesso, R. X. Adhikari, V. B. Adya, C. Affeldt, B. Agarwal, M. Agathos, K. Agatsuma, N. Aggarwal, O. D. Aguiar, L. Aiello, A. Ain, P. Ajith, B. Allen, G. Allen, A. Allocca, M. A. Aloy, P. A. Altin, A. Amato, A. Ananyeva, S. B. Anderson, W. G. Anderson, S. V. Angelova, S. Antier, S. Appert, K. Arai, M. C. Araya, J. S. Areeda, M. Ar`ene, N. Arnaud, K. G. Arun, S. Ascenzi, G. Ashton, M. Ast, S. M. Aston, P. Astone, D. V. Atallah, F. Aubin, P. Aufmuth, C. Aulbert, K. AultONeal, C. Austin, A. Avila-Alvarez, S. Babak, P. Bacon, F. Badaracco, M. K. M. Bader, S. Bae, P. T. Baker, F. Baldaccini, G. Ballardin, S. W. Ballmer, S. Banagiri, J. C. Barayoga, S. E. Barclay, B. C. Barish, D. Barker, K. Barkett, S. Barnum, F. Barone, B. Barr, L. Barsotti, M. Barsuglia, D. Barta, J. Bartlett, I. Bartos, R. Bassiri, A. Basti, J. C. Batch, M. Bawaj, J. C. Bayley, M. Bazzan, B. B'ecsy, C. Beer, M. Bejger, I. Belahcene, A. S. Bell, D. Beniwal, M. Bensch, B. K. Berger, G. Bergmann, S. Bernuzzi, J. J. Bero, C. P. L. Berry, D. Bersanetti, A. Bertolini, J. Betzwieser, R. Bhandare, I. A. Bilenko, S. A. Bilgili, G. Billingsley, C. R. Billman, J. Birch, R. Birney, O. Birnholtz, S. Biscans, S. Biscoveanu, A. Bisht, M. Bitossi, M. A. Bizouard, J. K. Blackburn, J. Blackman, C. D. Blair, D. G. Blair, R. M. Blair, S. Bloemen, O. Bock, N. Bode, M. Boer, Y. Boetzel, G. Bogaert, A. Bohe, F. Bondu, E. Bonilla, R. Bonnand, P. Booker, B. A. Boom, C. D. Booth, R. Bork, V. Boschi, S. Bose, K. Bossie, V. Bossilkov, J. Bosveld, Y. Bouffanais, A. Bozzi, C. Bradaschia, P. R. Brady, A. Bramley, M. Branchesi, J. E. Brau, T. Briant, F. Brighenti, A. Brillet, M. Brinkmann, V. Brisson, P. Brockill, A. F. Brooks, D. D. Brown, S. Brunett, C. C. Buchanan, A. Buikema, T. Bulik, H. J. Bulten, A. Buonanno, D. Buskulic, C. Buy, R. L. Byer, M. Cabero, L. Cadonati, G. Cagnoli, C. Cahillane, J. Calder'on Bustillo, T. A. Callister, E. Calloni, J. B. Camp, M. Canepa, P. Canizares, K. C. Cannon, H. Cao, J. Cao, C. D. Capano, E. Capocasa, F. Carbognani, S. Caride, M. F. Carney, G. Carullo, J. Casanueva Diaz, C. Casentini, S. Caudill, M. Cavagli`a, F. Cavalier, R. Cavalieri, G. Cella, C. B. Cepeda, P. Cerd'a-Dur'an, G. Cerretani, E. Cesarini, O. Chaibi, S. J. Chamberlin, M. Chan, S. Chao, P. Charlton, E. Chase, E. Chassande-Mottin, D. Chatterjee, K. Chatziioannou, B. D. Cheeseboro, H. Y. Chen, X. Chen, Y. Chen, H. -P. Cheng, H. Y. Chia, A. Chincarini, A. Chiummo, T. Chmiel, H. S. Cho, M. Cho, J. H. Chow, N. Christensen, Q. Chu, A. J. K. Chua, S. Chua, K. W. Chung, S. Chung, G. Ciani, A. A. Ciobanu, R. Ciolfi, F. Cipriano, C. E. Cirelli, A. Cirone, F. Clara, J. A. Clark, P. Clearwater, F. Cleva, C. Cocchieri, E. Coccia, P. -F. Cohadon, D. Cohen, A. Colla, C. G. Collette, C. Collins, L. R. Cominsky, M. Constancio Jr., L. Conti, S. J. Cooper, P. Corban, T. R. Corbitt, I. Cordero-Carri'on, K. R. Corley, N. Cornish, A. Corsi, S. Cortese, C. A. Costa, R. Cotesta, M. W. Coughlin, S. B. Coughlin, J. -P. Coulon, S. T. Countryman, P. Couvares, P. B. Covas, E. E. Cowan, D. M. Coward, M. J. Cowart, D. C. Coyne, R. Coyne, J. D. E. Creighton, T. D. Creighton, J. Cripe, S. G. Crowder, T. J. Cullen, A. Cumming, L. Cunningham, E. Cuoco, T. Dal Canton, G. D'alya, S. L. Danilishin, S. D'Antonio, K. Danzmann, A. Dasgupta, C. F. Da Silva Costa, V. Dattilo, I. Dave, M. Davier, D. Davis, E. J. Daw, B. Day, D. DeBra, M. Deenadayalan, J. Degallaix, M. De Laurentis, S. Del'eglise, W. Del Pozzo, N. Demos, T. Denker, T. Dent, R. De Pietri, J. Derby, V. Dergachev, R. De Rosa, C. De Rossi, R. DeSalvo, O. de Varona, S. Dhurandhar, M. C. D'iaz, T. Dietrich, L. Di Fiore, M. Di Giovanni, T. Di Girolamo, A. Di Lieto, B. Ding, S. Di Pace, I. Di Palma, F. Di Renzo, A. Dmitriev, Z. Doctor, V. Dolique, F. Donovan, K. L. Dooley, S. Doravari, I. Dorrington, M. Dovale 'Alvarez, T. P. Downes, M. Drago, C. Dreissigacker, J. C. Driggers, Z. Du, R. Dudi, P. Dupej, S. E. Dwyer, P. J. Easter, T. B. Edo, M. C. Edwards, A. Effler, H. -B. Eggenstein, P. Ehrens, J. Eichholz, S. S. Eikenberry, M. Eisenmann, R. A. Eisenstein, R. C. Essick, H. Estelles, D. Estevez, Z. B. Etienne, T. Etzel, M. Evans, T. M. Evans, V. Fafone, H. Fair, S. Fairhurst, X. Fan, S. Farinon, B. Farr, W. M. Farr, E. J. Fauchon-Jones, M. Favata, M. Fays, C. Fee, H. Fehrmann, J. Feicht, M. M. Fejer, F. Feng, A. Fernandez-Galiana, I. Ferrante, E. C. Ferreira, F. Ferrini, F. Fidecaro, I. Fiori, D. Fiorucci, M. Fishbach, R. P. Fisher, J. M. Fishner, M. Fitz-Axen, R. Flaminio, M. Fletcher, H. Fong, J. A. Font, P. W. F. Forsyth, S. S. Forsyth, J. -D. Fournier, S. Frasca, F. Frasconi, Z. Frei, A. Freise, R. Frey, V. Frey, P. Fritschel, V. V. Frolov, P. Fulda, M. Fyffe, H. A. Gabbard, B. U. Gadre, S. M. Gaebel, J. R. Gair, L. Gammaitoni, M. R. Ganija, S. G. Gaonkar, A. Garcia, C. Garc'ia-Quir'os, F. Garufi, B. Gateley, S. Gaudio, G. Gaur, V. Gayathri, G. Gemme, E. Genin, A. Gennai, D. George, J. George, L. Gergely, V. Germain, S. Ghonge, Abhirup Ghosh, Archisman Ghosh, S. Ghosh, B. Giacomazzo, J. A. Giaime, K. D. Giardina, A. Giazotto, K. Gill, G. Giordano, L. Glover, E. Goetz, R. Goetz, B. Goncharov, G. Gonz'alez, J. M. Gonzalez Castro, A. Gopakumar, M. L. Gorodetsky, S. E. Gossan, M. Gosselin, R. Gouaty, A. Grado, C. Graef, M. Granata, A. Grant, S. Gras, C. Gray, G. Greco, A. C. Green, R. Green, E. M. Gretarsson, P. Groot, H. Grote, S. Grunewald, P. Gruning, G. M. Guidi, H. K. Gulati, X. Guo, A. Gupta, M. K. Gupta, K. E. Gushwa, E. K. Gustafson, R. Gustafson, O. Halim, B. R. Hall, E. D. Hall, E. Z. Hamilton, H. F. Hamilton, G. Hammond, M. Haney, M. M. Hanke, J. Hanks, C. Hanna, M. D. Hannam, O. A. Hannuksela, J. Hanson, T. Hardwick, J. Harms, G. M. Harry, I. W. Harry, M. J. Hart, C. -J. Haster, K. Haughian, J. Healy, A. Heidmann, M. C. Heintze, H. Heitmann, P. Hello, G. Hemming, M. Hendry, I. S. Heng, J. Hennig, A. W. Heptonstall, F. J. Hernandez, M. Heurs, S. Hild, T. Hinderer, D. Hoak, S. Hochheim, D. Hofman, N. A. Holland, K. Holt, D. E. Holz, P. Hopkins, C. Horst, J. Hough, E. A. Houston, E. J. Howell, A. Hreibi, E. A. Huerta, D. Huet, B. Hughey, M. Hulko, S. Husa, S. H. Huttner, T. Huynh-Dinh, A. Iess, N. Indik, C. Ingram, R. Inta, G. Intini, H. N. Isa, J. -M. Isac, M. Isi, B. R. Iyer, K. Izumi, T. Jacqmin, K. Jani, P. Jaranowski, D. S. Johnson, W. W. Johnson, D. I. Jones, R. Jones, R. J. G. Jonker, L. Ju, J. Junker, C. V. Kalaghatgi, V. Kalogera, B. Kamai, S. Kandhasamy, G. Kang, J. B. Kanner, S. J. Kapadia, S. Karki, K. S. Karvinen, M. Kasprzack, W. Kastaun, M. Katolik, S. Katsanevas, E. Katsavounidis, W. Katzman, S. Kaufer, K. Kawabe, N. V. Keerthana, F. K'ef'elian, D. Keitel, A. J. Kemball, R. Kennedy, J. S. Key, F. Y. Khalili, B. Khamesra, H. Khan, I. Khan, S. Khan, Z. Khan, E. A. Khazanov, N. Kijbunchoo, Chunglee Kim, J. C. Kim, K. Kim, W. Kim, W. S. Kim, Y. -M. Kim, E. J. King, P. J. King, M. Kinley-Hanlon, R. Kirchhoff, J. S. Kissel, L. Kleybolte, S. Klimenko, T. D. Knowles, P. Koch, S. M. Koehlenbeck, S. Koley, V. Kondrashov, A. Kontos, M. Korobko, W. Z. Korth, I. Kowalska, D. B. Kozak, C. Kr""amer, V. Kringel, B. Krishnan, A. Kr'olak, G. Kuehn, P. Kumar, R. Kumar, S. Kumar, L. Kuo, A. Kutynia, S. Kwang, B. D. Lackey, K. H. Lai, M. Landry, P. Landry, R. N. Lang, J. Lange, B. Lantz, R. K. Lanza, A. Lartaux-Vollard, P. D. Lasky, M. Laxen, A. Lazzarini, C. Lazzaro, P. Leaci, S. Leavey, C. H. Lee, H. K. Lee, H. M. Lee, H. W. Lee, K. Lee, J. Lehmann, A. Lenon, M. Leonardi, N. Leroy, N. Letendre, Y. Levin, J. Li, T. G. F. Li, X. Li, S. D. Linker, T. B. Littenberg, J. Liu, X. Liu, R. K. L. Lo, N. A. Lockerbie, L. T. London, A. Longo, M. Lorenzini, V. Loriette, M. Lormand, G. Losurdo, J. D. Lough, C. O. Lousto, G. Lovelace, H. L""uck, D. Lumaca, A. P. Lundgren, R. Lynch, Y. Ma, R. Macas, S. Macfoy, B. Machenschalk, M. MacInnis, D. M. Macleod, I. Magaña Hernandez, F. Magaña-Sandoval, L. Magaña Zertuche, R. M. Magee, E. Majorana, I. Maksimovic, N. Man, V. Mandic, V. Mangano, G. L. Mansell, M. Manske, M. Mantovani, F. Marchesoni, F. Marion, S. M'arka, Z. M'arka, C. Markakis, A. S. Markosyan, A. Markowitz, E. Maros, A. Marquina, F. Martelli, L. Martellini, I. W. Martin, R. M. Martin, D. V. Martynov, K. Mason, E. Massera, A. Masserot, T. J. Massinger, M. Masso-Reid, S. Mastrogiovanni, A. Matas, F. Matichard, L. Matone, N. Mavalvala, N. Mazumder, J. J. McCann, R. McCarthy, D. E. McClelland, S. McCormick, L. McCuller, S. C. McGuire, J. McIver, D. J. McManus, T. McRae, S. T. McWilliams, D. Meacher, G. D. Meadors, M. Mehmet, J. Meidam, E. Mejuto-Villa, A. Melatos, G. Mendell, D. Mendoza-Gandara, R. A. Mercer, L. Mereni, E. L. Merilh, M. Merzougui, S. Meshkov, C. Messenger, C. Messick, R. Metzdorff, P. M. Meyers, H. Miao, C. Michel, H. Middleton, E. E. Mikhailov, L. Milano, A. L. Miller, A. Miller, B. B. Miller, J. Miller, M. Millhouse, J. Mills, M. C. Milovich-Goff, O. Minazzoli, Y. Minenkov, J. Ming, C. Mishra, S. Mitra, V. P. Mitrofanov, G. Mitselmakher, R. Mittleman, D. Moffa, K. Mogushi, M. Mohan, S. R. P. Mohapatra, M. Montani, C. J. Moore, D. Moraru, G. Moreno, S. Morisaki, B. Mours, C. M. Mow-Lowry, G. Mueller, A. W. Muir, Arunava Mukherjee, D. Mukherjee, S. Mukherjee, N. Mukund, A. Mullavey, J. Munch, E. A. Muñiz, M. Muratore, P. G. Murray, A. Nagar, K. Napier, I. Nardecchia, L. Naticchioni, R. K. Nayak, J. Neilson, G. Nelemans, T. J. N. Nelson, M. Nery, A. Neunzert, L. Nevin, J. M. Newport, K. Y. Ng, S. Ng, P. Nguyen, T. T. Nguyen, D. Nichols, A. B. Nielsen, S. Nissanke, A. Nitz, F. Nocera, D. Nolting, C. North, L. K. Nuttall, M. Obergaulinger, J. Oberling, B. D. O'Brien, G. D. O'Dea, G. H. Ogin, J. J. Oh, S. H. Oh, F. Ohme, H. Ohta, M. A. Okada, M. Oliver, P. Oppermann, Richard J. Oram, B. O'Reilly, R. Ormiston, L. F. Ortega, R. O'Shaughnessy, S. Ossokine, D. J. Ottaway, H. Overmier, B. J. Owen, A. E. Pace, G. Pagano, J. Page, M. A. Page, A. Pai, S. A. Pai, J. R. Palamos, O. Palashov, C. Palomba, A. Pal-Singh, Howard Pan, Huang-Wei Pan, B. Pang, P. T. H. Pang, C. Pankow, F. Pannarale, B. C. Pant, F. Paoletti, A. Paoli, M. A. Papa, A. Parida, W. Parker, D. Pascucci, A. Pasqualetti, R. Passaquieti, D. Passuello, M. Patil, B. Patricelli, B. L. Pearlstone, C. Pedersen, M. Pedraza, R. Pedurand, L. Pekowsky, A. Pele, S. Penn, C. J. Perez, A. Perreca, L. M. Perri, H. P. Pfeiffer, M. Phelps, K. S. Phukon, O. J. Piccinni, M. Pichot, F. Piergiovanni, V. Pierro, G. Pillant, L. Pinard, I. M. Pinto, M. Pirello, M. Pitkin, R. Poggiani, P. Popolizio, E. K. Porter, L. Possenti, A. Post, J. Powell, J. Prasad, J. W. W. Pratt, G. Pratten, V. Predoi, T. Prestegard, M. Principe, S. Privitera, G. A. Prodi, L. G. Prokhorov, O. Puncken, M. Punturo, P. Puppo, M. P""urrer, H. Qi, V. Quetschke, E. A. Quintero, R. Quitzow-James, F. J. Raab, D. S. Rabeling, H. Radkins, P. Raffai, S. Raja, C. Rajan, B. Rajbhandari, M. Rakhmanov, K. E. Ramirez, A. Ramos-Buades, Javed Rana, P. Rapagnani, V. Raymond, M. Razzano, J. Read, T. Regimbau, L. Rei, S. Reid, D. H. Reitze, W. Ren, F. Ricci, P. M. Ricker, G. Riemenschneider, K. Riles, M. Rizzo, N. A. Robertson, R. Robie, F. Robinet, T. Robson, A. Rocchi, L. Rolland, J. G. Rollins, V. J. Roma, R. Romano, C. L. Romel, J. H. Romie, D. Rosi'nska, M. P. Ross, S. Rowan, A. R""udiger, P. Ruggi, G. Rutins, K. Ryan, S. Sachdev, T. Sadecki, M. Sakellariadou, L. Salconi, M. Saleem, F. Salemi, A. Samajdar, L. Sammut, L. M. Sampson, E. J. Sanchez, L. E. Sanchez, N. Sanchis-Gual, V. Sandberg, J. R. Sanders, N. Sarin, B. Sassolas, B. S. Sathyaprakash, P. R. Saulson, O. Sauter, R. L. Savage, A. Sawadsky, P. Schale, M. Scheel, J. Scheuer, P. Schmidt, R. Schnabel, R. M. S. Schofield, A. Sch""onbeck, E. Schreiber, D. Schuette, B. W. Schulte, B. F. Schutz, S. G. Schwalbe, J. Scott, S. M. Scott, E. Seidel, D. Sellers, A. S. Sengupta, D. Sentenac, V. Sequino, A. Sergeev, Y. Setyawati, D. A. Shaddock, T. J. Shaffer, A. A. Shah, M. S. Shahriar, M. B. Shaner, L. Shao, B. Shapiro, P. Shawhan, H. Shen, D. H. Shoemaker, D. M. Shoemaker, K. Siellez, X. Siemens, M. Sieniawska, D. Sigg, A. D. Silva, L. P. Singer, A. Singh, A. Singhal, A. M. Sintes, B. J. J. Slagmolen, T. J. Slaven-Blair, B. Smith, J. R. Smith, R. J. E. Smith, S. Somala, E. J. Son, B. Sorazu, F. Sorrentino, T. Souradeep, A. P. Spencer, A. K. Srivastava, K. Staats, M. Steinke, J. Steinlechner, S. Steinlechner, D. Steinmeyer, B. Steltner, S. P. Stevenson, D. Stocks, R. Stone, D. J. Stops, K. A. Strain, G. Stratta, S. E. Strigin, A. Strunk, R. Sturani, A. L. Stuver, T. Z. Summerscales, L. Sun, S. Sunil, J. Suresh, P. J. Sutton, B. L. Swinkels, M. J. Szczepa'nczyk, M. Tacca, S. C. Tait, C. Talbot, D. Talukder, D. B. Tanner, M. T'apai, A. Taracchini, J. D. Tasson, J. A. Taylor, R. Taylor, S. V. Tewari, T. Theeg, F. Thies, E. G. Thomas, M. Thomas, P. Thomas, K. A. Thorne, E. Thrane, S. Tiwari, V. Tiwari, K. V. Tokmakov, K. Toland, M. Tonelli, Z. Tornasi, A. Torres-Forn'e, C. I. Torrie, D. T""oyr""a, F. Travasso, G. Traylor, J. Trinastic, M. C. Tringali, L. Trozzo, K. W. Tsang, M. Tse, R. Tso, D. Tsuna, L. Tsukada, D. Tuyenbayev, K. Ueno, D. Ugolini, A. L. Urban, S. A. Usman, H. Vahlbruch, G. Vajente, G. Valdes, N. van Bakel, M. van Beuzekom, J. F. J. van den Brand, C. Van Den Broeck, D. C. Vander-Hyde, L. van der Schaaf, J. V. van Heijningen, A. A. van Veggel, M. Vardaro, V. Varma, S. Vass, M. Vas'uth, A. Vecchio, G. Vedovato, J. Veitch, P. J. Veitch, K. Venkateswara, G. Venugopalan, D. Verkindt, F. Vetrano, A. Vicer'e, A. D. Viets, S. Vinciguerra, D. J. Vine, J. -Y. Vinet, S. Vitale, T. Vo, H. Vocca, C. Vorvick, S. P. Vyatchanin, A. R. Wade, L. E. Wade, M. Wade, R. Walet, M. Walker, L. Wallace, S. Walsh, G. Wang, H. Wang, J. Z. Wang, W. H. Wang, Y. F. Wang, R. L. Ward, J. Warner, M. Was, J. Watchi, B. Weaver, L. -W. Wei, M. Weinert, A. J. Weinstein, R. Weiss, F. Wellmann, L. Wen, E. K. Wessel, P. Wessels, J. Westerweck, K. Wette, J. T. Whelan, B. F. Whiting, C. Whittle, D. Wilken, D. Williams, R. D. Williams, A. R. Williamson, J. L. Willis, B. Willke, M. H. Wimmer, W. Winkler, C. C. Wipf, H. Wittel, G. Woan, J. Woehler, J. K. Wofford, W. K. Wong, J. Worden, J. L. Wright, D. S. Wu, D. M. Wysocki, S. Xiao, W. Yam, H. Yamamoto, C. C. Yancey, L. Yang, M. J. Yap, M. Yazback, Hang Yu, Haocun Yu, M. Yvert, A. Zadro. zny, M. Zanolin, T. Zelenova, J. -P. Zendri, M. Zevin, J. Zhang, L. Zhang, M. Zhang, T. Zhang, Y. -H. Zhang, C. Zhao, M. Zhou, Z. Zhou, S. J. Zhu, X. J. Zhu, A. B. Zimmerman, Y. Zlochower, M. E. Zucker, J. Zweizig",The LIGO Scientific Collaboration et al.,"gr-qc, astro-ph.HE",General Relativity and Quantum Cosmology,gr-qc,"29 pages, 15 figures",A:1805.11579,-,29,https://arxiv.org/pdf/1805.11579.pdf,2018-05-29T16:55:48Z,,"On August 17, 2017, the Advanced LIGO and Advanced Virgo gravitational-wave detectors observed a low-mass compact binary inspiral. The initial sky localization of the source of the gravitational-wave signal, GW170817, allowed electromagnetic observatories to identify NGC 4993 as the host galaxy. In this work we improve initial estimates of the binary's properties, including component masses, spins, and tidal parameters, using the known source location, improved modeling, and re-calibrated Virgo data. We extend the range of gravitational-wave frequencies considered down to 23 Hz, compared to 30 Hz in the initial analysis. We also compare results inferred using several signal models, which are more accurate and incorporate additional physical effects as compared to the initial analysis. We improve the localization of the gravitational-wave source to a 90% credible region of $16~\mathrm{deg}^2$. We find tighter constraints on the masses, spins, and tidal parameters, and continue to find no evidence for non-zero component spins. The component masses are inferred to lie between 1.00 and 1.89 $M_\odot$ when allowing for large component spins, and to lie between 1.16 and 1.60 $M_\odot$ (with a total mass $2.73^{+0.04}_{-0.01} \, M_\odot$) when the spins are restricted to be within the range observed in Galactic binary neutron stars. Under minimal assumptions about the nature of the compact objects, our constraints for the tidal deformability parameter $\tilde \Lambda$ are $(0,630)$ when we allow for large component spins, and $300^{+420}_{-230}$ (using a 90% highest posterior density interval) when restricting the magnitude of the component spins, ruling out several equation of state models at the 90% credible level. Finally, with LIGO and GEO600 data, we use a Bayesian analysis to place upper limits on the amplitude and spectral energy density of a possible post-merger signal. (Abridged)",Properties of the binary neutron star merger GW170817,"Comment: 29 pages, 15 figures",Subject: General Relativity and Quantum Cosmology [gr-qc],"Published 7 days ago in May 29, 2018",2018-05-29T16:55:48Z,-
"Marzyeh Ghassemi, Tristan Naumann, Peter Schulam, Andrew L. Beam, Rajesh Ranganath",Marzyeh Ghassemi et al.,"cs.LG, cs.CY, stat.ML",Learning,cs.LG,Corrected preprint footer,A:1806.00388,-,14,https://arxiv.org/pdf/1806.00388.pdf,2018-06-01T15:12:20Z,,"Healthcare is a natural arena for the application of machine learning, especially as modern electronic health records (EHRs) provide increasingly large amounts of data to answer clinically meaningful questions. However, clinical data and practice present unique challenges that complicate the use of common methodologies. This article serves as a primer on addressing these challenges and highlights opportunities for members of the machine learning and data science communities to contribute to this growing domain.",Opportunities in Machine Learning for Healthcare,Comment: Corrected preprint footer,Subject: Learning [cs.LG],Updated today,2018-06-05T17:11:13Z,-
"Max Jaderberg, Valentin Dalibard, Simon Osindero, Wojciech M. Czarnecki, Jeff Donahue, Ali Razavi, Oriol Vinyals, Tim Green, Iain Dunning, Karen Simonyan, Chrisantha Fernando, Koray Kavukcuoglu",Max Jaderberg et al.,"cs.LG, cs.NE",Learning,cs.LG,-,A:1711.09846,-,21,https://arxiv.org/pdf/1711.09846.pdf,2017-11-27T17:33:27Z,,"Neural networks dominate the modern machine learning landscape, but their training and success still suffer from sensitivity to empirical choices of hyperparameters such as model architecture, loss function, and optimisation algorithm. In this work we present \emph{Population Based Training (PBT)}, a simple asynchronous optimisation algorithm which effectively utilises a fixed computational budget to jointly optimise a population of models and their hyperparameters to maximise performance. Importantly, PBT discovers a schedule of hyperparameter settings rather than following the generally sub-optimal strategy of trying to find a single fixed set to use for the whole course of training. With just a small modification to a typical distributed hyperparameter training framework, our method allows robust and reliable training of models. We demonstrate the effectiveness of PBT on deep reinforcement learning problems, showing faster wall-clock convergence and higher final performance of agents by optimising over a suite of hyperparameters. In addition, we show the same method can be applied to supervised learning for machine translation, where PBT is used to maximise the BLEU score directly, and also to training of Generative Adversarial Networks to maximise the Inception score of generated images. In all cases PBT results in the automatic discovery of hyperparameter schedules and model selection which results in stable training and better final performance.",Population Based Training of Neural Networks,Comment: [ 21 pages. ],Subject: Learning [cs.LG],"Updated in Nov 28, 2017",2017-11-28T16:16:21Z,-
"Peter W. Battaglia, Jessica B. Hamrick, Victor Bapst, Alvaro Sanchez-Gonzalez, Vinicius Zambaldi, Mateusz Malinowski, Andrea Tacchetti, David Raposo, Adam Santoro, Ryan Faulkner, Caglar Gulcehre, Francis Song, Andrew Ballard, Justin Gilmer, George Dahl, Ashish Vaswani, Kelsey Allen, Charles Nash, Victoria Langston, Chris Dyer, Nicolas Heess, Daan Wierstra, Pushmeet Kohli, Matt Botvinick, Oriol Vinyals, Yujia Li, Razvan Pascanu",Peter W. Battaglia et al.,"cs.LG, cs.AI, stat.ML",Learning,cs.LG,-,A:1806.01261,-,37,https://arxiv.org/pdf/1806.01261.pdf,2018-06-04T17:58:18Z,,"Artificial intelligence (AI) has undergone a renaissance recently, making major progress in key domains such as vision, language, control, and decision-making. This has been due, in part, to cheap data and cheap compute resources, which have fit the natural strengths of deep learning. However, many defining characteristics of human intelligence, which developed under much different pressures, remain out of reach for current approaches. In particular, generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI. The following is part position paper, part review, and part unification. We argue that combinatorial generalization must be a top priority for AI to achieve human-like abilities, and that structured representations and computations are key to realizing this objective. Just as biology uses nature and nurture cooperatively, we reject the false choice between ""hand-engineering"" and ""end-to-end"" learning, and instead advocate for an approach which benefits from their complementary strengths. We explore how using relational inductive biases within deep learning architectures can facilitate learning about entities, relations, and rules for composing them. We present a new building block for the AI toolkit with a strong relational inductive bias--the graph network--which generalizes and extends various approaches for neural networks that operate on graphs, and provides a straightforward interface for manipulating structured knowledge and producing structured behaviors. We discuss how graph networks can support relational reasoning and combinatorial generalization, laying the foundation for more sophisticated, interpretable, and flexible patterns of reasoning.","Relational inductive biases, deep learning, and graph networks",Comment: [ 37 pages. ],Subject: Learning [cs.LG],"Published 2 days ago in Jun 04, 2018",2018-06-04T17:58:18Z,-
Amri Wandel,Amri Wandel,astro-ph.EP,Earth and Planetary Astrophysics,astro-ph.EP,"33 pages, 15 figures",A:1802.00141,-,33,https://arxiv.org/pdf/1802.00141.pdf,2018-02-01T03:09:17Z,,"The recent detection of Earth-sized planets in the habitable zone of Proxima Centauri, Trappist-1 and many other nearby M-type stars has led to speculations, whether liquid water and life actually exist on these planets. To a large extent, the answer depends on their yet unknown atmospheres, which may though be within observational reach in the near future by JWST, ELT and other planned telescopes. We consider the habitability of planets of M-type stars in the context of their atmospheric properties, heat transport and irradiation. Instead of the traditional definition of the habitable zone, we define the bio-habitable zone, where liquid water and complex organic molecules can survive on at least part of the planetary surface. The atmospheric impact on the temperature is quantified in terms of the heating factor (a combination of greenhouse heating, stellar irradiation, albedo etc.) and heat redistribution (horizontal energy transport). We investigate the bio-habitable domain (where planets can support surface liquid water and organics) in terms of these two factors. Our results suggest that planets orbiting M-type stars may have life-supporting temperatures, at least on part of their surface, for a wide range of atmospheric properties. We apply this analyses to Proxima b and the Trappist-1 system. Finally we discuss the implications to the search of biosignatures and demonstrate how they may be used to estimate the abundance of photosynthesis and biotic planets.",On the bio-habitability of M-dwarf planets,"Comment: 33 pages, 15 figures",Subject: Earth and Planetary Astrophysics [astro-ph.EP],"Published in Feb 01, 2018",2018-02-01T03:09:17Z,-
"Aharon Azulay, Yair Weiss",Aharon Azulay et al.,cs.CV,Computer Vision and Pattern Recognition,cs.CV,-,A:1805.12177,-,11,https://arxiv.org/pdf/1805.12177.pdf,2018-05-30T18:56:33Z,,"Deep convolutional network architectures are often assumed to guarantee generalization for small image translations and deformations. In this paper we show that modern CNNs (VGG16, ResNet50, and InceptionResNetV2) can drastically change their output when an image is translated in the image plane by a few pixels, and that this failure of generalization also happens with other realistic small image transformations. Furthermore, the deeper the network the more we see these failures to generalize. We show that these failures are related to the fact that the architecture of modern CNNs ignores the classical sampling theorem so that generalization is not guaranteed. We also show that biases in the statistics of commonly used image datasets makes it unlikely that CNNs will learn to be invariant to these transformations. Taken together our results suggest that the performance of CNNs in object recognition falls far short of the generalization capabilities of humans.",Why do deep convolutional networks generalize so poorly to small image transformations?,Comment: [ 11 pages. ],Subject: Computer Vision and Pattern Recognition [cs.CV],"Published 7 days ago in May 30, 2018",2018-05-30T18:56:33Z,-
"Savvas Zannettou, Tristan Caulfield, Jeremy Blackburn, Emiliano De Cristofaro, Michael Sirivianos, Gianluca Stringhini, Guillermo Suarez-Tangil",Savvas Zannettou et al.,"cs.SI, cs.CY",Social and Information Networks,cs.SI,-,A:1805.12512,-,20,https://arxiv.org/pdf/1805.12512.pdf,2018-05-31T15:22:55Z,,"Internet memes are increasingly used to sway and possibly manipulate public opinion, thus prompting the need to study their propagation, evolution, and influence across the Web. In this paper, we detect and measure the propagation of memes across multiple Web communities, using a processing pipeline based on perceptual hashing and clustering techniques, and a dataset of 160M images from 2.6B posts gathered from Twitter, Reddit, 4chan's Politically Incorrect board (/pol/), and Gab over the course of 13 months. We group the images posted on fringe Web communities (/pol/, Gab, and The_Donald subreddit) into clusters, annotate them using meme metadata obtained from Know Your Meme, and also map images from mainstream communities (Twitter and Reddit) to the clusters. Our analysis provides an assessment of the popularity and diversity of memes in the context of each community, showing, e.g., that racist memes are extremely common in fringe Web communities. We also find a substantial number of politics-related memes on both mainstream and fringe Web communities, supporting media reports that memes might be used to enhance or harm politicians. Finally, we use Hawkes processes to model the interplay between Web communities and quantify their reciprocal influence, finding that /pol/ substantially influences the meme ecosystem with the number of memes it produces, while The_Donald has a higher success rate in pushing them to other communities.",On the Origins of Memes by Means of Fringe Web Communities,Comment: [ 20 pages. ],Subject: Social and Information Networks [cs.SI],"Published 5 days ago in May 31, 2018",2018-05-31T15:22:55Z,-
"Fernando Martínez-Plumed, Shahar Avin, Miles Brundage, Allan Dafoe, Sean Ó hÉigeartaigh, José Hernández-Orallo",Fernando Martínez-Plumed et al.,cs.AI,Artificial Intelligence,cs.AI,-,A:1806.00610,-,12,https://arxiv.org/pdf/1806.00610.pdf,2018-06-02T09:21:12Z,,"We analyze and reframe AI progress. In addition to the prevailing metrics of performance, we highlight the usually neglected costs paid in the development and deployment of a system, including: data, expert knowledge, human oversight, software resources, computing cycles, hardware and network facilities, development time, etc. These costs are paid throughout the life cycle of an AI system, fall differentially on different individuals, and vary in magnitude depending on the replicability and generality of the AI solution. The multidimensional performance and cost space can be collapsed to a single utility metric for a user with transitive and complete preferences. Even absent a single utility function, AI advances can be generically assessed by whether they expand the Pareto (optimal) surface. We explore a subset of these neglected dimensions using the two case studies of Alpha* and ALE. This broadened conception of progress in AI should lead to novel ways of measuring success in AI, and can help set milestones for future progress.",Accounting for the Neglected Dimensions of AI Progress,Comment: [ 12 pages. ],Subject: Artificial Intelligence [cs.AI],"Published 4 days ago in Jun 02, 2018",2018-06-02T09:21:12Z,-
"Jessica B. Hamrick, Kelsey R. Allen, Victor Bapst, Tina Zhu, Kevin R. McKee, Joshua B. Tenenbaum, Peter W. Battaglia",Jessica B. Hamrick et al.,"cs.LG, cs.AI, stat.ML",Learning,cs.LG,In Proceedings of the Annual Meeting of the Cognitive Science Society (CogSci 2018),A:1806.01203,-,7,https://arxiv.org/pdf/1806.01203.pdf,2018-06-04T16:45:19Z,,"While current deep learning systems excel at tasks such as object classification, language processing, and gameplay, few can construct or modify a complex system such as a tower of blocks. We hypothesize that what these systems lack is a ""relational inductive bias"": a capacity for reasoning about inter-object relations and making choices over a structured description of a scene. To test this hypothesis, we focus on a task that involves gluing pairs of blocks together to stabilize a tower, and quantify how well humans perform. We then introduce a deep reinforcement learning agent which uses object- and relation-centric scene and policy representations and apply it to the task. Our results show that these structured representations allow the agent to outperform both humans and more naive approaches, suggesting that relational inductive bias is an important component in solving structured reasoning problems and for building more intelligent, flexible machines.",Relational inductive bias for physical construction in humans and machines,Comment: In Proceedings of the Annual Meeting of the Cognitive Science Society (CogSci 2018),Subject: Learning [cs.LG],"Published 2 days ago in Jun 04, 2018",2018-06-04T16:45:19Z,-
"Lorenz A. Gilch, Sebastian Müller",Lorenz A. Gilch et al.,stat.AP,Applications,stat.AP,"22 pages, 7 figures",A:1806.01930,-,22,https://arxiv.org/pdf/1806.01930.pdf,2018-06-05T20:36:30Z,,We propose an approach for the analysis and prediction of a football championship. It is based on Poisson regression models that include the Elo points of the teams as covariates and incorporates differences of team-specific effects. These models for the prediction of the FIFA World Cup 2018 are fitted on all football games on neutral ground of the participating teams since 2010. Based on the model estimates for single matches Monte-Carlo simulations are used to estimate probabilities for reaching the different stages in the FIFA World Cup 2018 for all teams. We propose two score functions for ordinal random variables that serve together with the rank probability score for the validation of our models with the results of the FIFA World Cups 2010 and 2014. All models favor Germany as the new FIFA World Champion. All possible courses of the tournament and their probabilities are visualized using a single Sankey diagram.,On Elo based prediction models for the FIFA Worldcup 2018,"Comment: 22 pages, 7 figures",Subject: Applications [stat.AP],Published yesterday,2018-06-05T20:36:30Z,-
"Giuseppe Cuccu, Julian Togelius, Philippe Cudre-Mauroux",Giuseppe Cuccu et al.,"cs.LG, cs.AI, cs.NE, stat.ML",Learning,cs.LG,-,A:1806.01363,-,11,https://arxiv.org/pdf/1806.01363.pdf,2018-06-04T20:09:43Z,,"Deep reinforcement learning on Atari games maps pixel directly to actions; internally, the deep neural network bears the responsibility of both extracting useful information and making decisions based on it. Aiming at devoting entire deep networks to decision making alone, we propose a new method for learning policies and compact state representations separately but simultaneously for policy approximation in reinforcement learning. State representations are generated by a novel algorithm based on Vector Quantization and Sparse Coding, trained online along with the network, and capable of growing its dictionary size over time. We also introduce new techniques allowing both the neural network and the evolution strategy to cope with varying dimensions. This enables networks of only 6 to 18 neurons to learn to play a selection of Atari games with performance comparable---and occasionally superior---to state-of-the-art techniques using evolution strategies on deep networks two orders of magnitude larger.",Playing Atari with Six Neurons,Comment: [ 11 pages. ],Subject: Learning [cs.LG],"Published 2 days ago in Jun 04, 2018",2018-06-04T20:09:43Z,-
"Vinicius Zambaldi, David Raposo, Adam Santoro, Victor Bapst, Yujia Li, Igor Babuschkin, Karl Tuyls, David Reichert, Timothy Lillicrap, Edward Lockhart, Murray Shanahan, Victoria Langston, Razvan Pascanu, Matthew Botvinick, Oriol Vinyals, Peter Battaglia",Vinicius Zambaldi et al.,"cs.LG, stat.ML",Learning,cs.LG,-,A:1806.01830,-,15,https://arxiv.org/pdf/1806.01830.pdf,2018-06-05T17:39:12Z,,"We introduce an approach for deep reinforcement learning (RL) that improves upon the efficiency, generalization capacity, and interpretability of conventional approaches through structured perception and relational reasoning. It uses self-attention to iteratively reason about the relations between entities in a scene and to guide a model-free policy. Our results show that in a novel navigation and planning task called Box-World, our agent finds interpretable solutions that improve upon baselines in terms of sample complexity, ability to generalize to more complex scenes than experienced during training, and overall performance. In the StarCraft II Learning Environment, our agent achieves state-of-the-art performance on six mini-games -- surpassing human grandmaster performance on four. By considering architectural inductive biases, our work opens new directions for overcoming important, but stubborn, challenges in deep RL.",Relational Deep Reinforcement Learning,Comment: [ 15 pages. ],Subject: Learning [cs.LG],Published yesterday,2018-06-05T17:39:12Z,-
"Adam Santoro, Ryan Faulkner, David Raposo, Jack Rae, Mike Chrzanowski, Theophane Weber, Daan Wierstra, Oriol Vinyals, Razvan Pascanu, Timothy Lillicrap",Adam Santoro et al.,"cs.LG, stat.ML",Learning,cs.LG,-,A:1806.01822,-,17,https://arxiv.org/pdf/1806.01822.pdf,2018-06-05T17:24:46Z,,"Memory-based neural networks model temporal data by leveraging an ability to remember information for long periods. It is unclear, however, whether they also have an ability to perform complex relational reasoning with the information they remember. Here, we first confirm our intuitions that standard memory architectures may struggle at tasks that heavily involve an understanding of the ways in which entities are connected -- i.e., tasks involving relational reasoning. We then improve upon these deficits by using a new memory module -- a \textit{Relational Memory Core} (RMC) -- which employs multi-head dot product attention to allow memories to interact. Finally, we test the RMC on a suite of tasks that may profit from more capable relational reasoning across sequential information, and show large gains in RL domains (e.g. Mini PacMan), program evaluation, and language modeling, achieving state-of-the-art results on the WikiText-103, Project Gutenberg, and GigaWord datasets.",Relational recurrent neural networks,Comment: [ 17 pages. ],Subject: Learning [cs.LG],"Published 2 days ago in Jun 05, 2018",2018-06-05T17:24:46Z,-
"Wojciech Marian Czarnecki, Siddhant M. Jayakumar, Max Jaderberg, Leonard Hasenclever, Yee Whye Teh, Simon Osindero, Nicolas Heess, Razvan Pascanu",Wojciech Marian Czarnecki et al.,"cs.LG, stat.ML",Learning,cs.LG,ICML 2018,A:1806.01780,"reinforcement learning, curriculum learning",12,https://arxiv.org/pdf/1806.01780.pdf,2018-06-05T16:21:25Z,,"We introduce Mix&Match (M&M) - a training framework designed to facilitate rapid and effective learning in RL agents, especially those that would be too slow or too challenging to train otherwise. The key innovation is a procedure that allows us to automatically form a curriculum over agents. Through such a curriculum we can progressively train more complex agents by, effectively, bootstrapping from solutions found by simpler agents. In contradistinction to typical curriculum learning approaches, we do not gradually modify the tasks or environments presented, but instead use a process to gradually alter how the policy is represented internally. We show the broad applicability of our method by demonstrating significant performance gains in three different experimental setups: (1) We train an agent able to control more than 700 actions in a challenging 3D first-person task; using our method to progress through an action-space curriculum we achieve both faster training and better final performance than one obtains using traditional methods. (2) We further show that M&M can be used successfully to progress through a curriculum of architectural variants defining an agents internal state. (3) Finally, we illustrate how a variant of our method can be used to improve agent performance in a multitask setting.",Mix&Match - Agent Curricula for Reinforcement Learning,Comment: ICML 2018,Subject: Learning [cs.LG],"Published 2 days ago in Jun 05, 2018",2018-06-05T16:21:25Z,-
"Ryo Karakida, Shotaro Akaho, Shun-ichi Amari",Ryo Karakida et al.,"stat.ML, cond-mat.dis-nn, cs.LG",Machine Learning,stat.ML,"18 pages, 4 figures",A:1806.01316,-,18,https://arxiv.org/pdf/1806.01316.pdf,2018-06-04T18:34:58Z,,"This study analyzes the Fisher information matrix (FIM) by applying mean-field theory to deep neural networks with random weights. We theoretically find novel statistics of the FIM, which are universal among a wide class of deep networks with any number of layers and various activation functions. Although most of the FIM's eigenvalues are close to zero, the maximum eigenvalue takes on a huge value and the eigenvalue distribution has an extremely long tail. These statistics suggest that the shape of a loss landscape is locally flat in most dimensions, but strongly distorted in the other dimensions. Moreover, our theory of the FIM leads to quantitative evaluation of learning in deep networks. First, the maximum eigenvalue enables us to estimate an appropriate size of a learning rate for steepest gradient methods to converge. Second, the flatness induced by the small eigenvalues is connected to generalization ability through a norm-based capacity measure.",Universal Statistics of Fisher Information in Deep Neural Networks: Mean Field Approach,"Comment: 18 pages, 4 figures",Subject: Machine Learning [stat.ML],"Published 2 days ago in Jun 04, 2018",2018-06-04T18:34:58Z,-
"Christian Guckelsberger, Christoph Salge, Julian Togelius",Christian Guckelsberger et al.,cs.AI,Artificial Intelligence,cs.AI,"IEEE Computational Intelligence and Games (CIG) conference, 2018, Maastricht. 8 pages, 6 figures, 2 tables",A:1806.01387,-,8,https://arxiv.org/pdf/1806.01387.pdf,2018-06-04T21:02:49Z,,"Creating Non-Player Characters (NPCs) that can react robustly to unforeseen player behaviour or novel game content is difficult and time-consuming. This hinders the design of believable characters, and the inclusion of NPCs in games that rely heavily on procedural content generation. We have previously addressed this challenge by means of empowerment, a model of intrinsic motivation, and demonstrated how a coupled empowerment maximisation (CEM) policy can yield generic, companion-like behaviour. In this paper, we extend the CEM framework with a minimisation policy to give rise to adversarial behaviour. We conduct a qualitative, exploratory study in a dungeon-crawler game, demonstrating that CEM can exploit the affordances of different content facets in adaptive adversarial behaviour without modifications to the policy. Changes to the level design, underlying mechanics and our character's actions do not threaten our NPC's robustness, but yield new and surprising ways to be mean.",New And Surprising Ways to Be Mean. Adversarial NPCs with Coupled Empowerment Minimisation,"Comment: IEEE Computational Intelligence and Games (CIG) conference, 2018, Maastricht. 8 pages, 6 figures, 2 tables",Subject: Artificial Intelligence [cs.AI],"Published 3 days ago in Jun 04, 2018",2018-06-04T21:02:49Z,-
"Yen Yu, Acer Y. C. Chang, Ryota Kanai",Yen Yu et al.,"cs.AI, stat.ML",Artificial Intelligence,cs.AI,"21 pages, 4 figures",A:1806.01502,-,21,https://arxiv.org/pdf/1806.01502.pdf,2018-06-05T05:34:46Z,,"This paper presents the Homeo-Heterostatic Value Gradients (HHVG) algorithm as a formal account on the constructive interplay between boredom and curiosity which gives rise to effective exploration and superior forward model learning. We envisaged actions as instrumental in agent's own epistemic disclosure. This motivated two central algorithmic ingredients: devaluation and devaluation progress, both underpin agent's cognition concerning intrinsically generated rewards. The two serve as an instantiation of homeostatic and heterostatic intrinsic motivation. A key insight from our algorithm is that the two seemingly opposite motivations can be reconciled---without which exploration and information-gathering cannot be effectively carried out. We supported this claim with empirical evidence, showing that boredom-enabled agents consistently outperformed other curious or explorative agent variants in model building benchmarks based on self-assisted experience accumulation.",Boredom-driven curious learning by Homeo-Heterostatic Value Gradients,"Comment: 21 pages, 4 figures",Subject: Artificial Intelligence [cs.AI],"Published 3 days ago in Jun 05, 2018",2018-06-05T05:34:46Z,-
"Christopher W. Lynn, Ari E. Kahn, Danielle S. Bassett",Christopher W. Lynn et al.,"q-bio.NC, physics.bio-ph, physics.soc-ph",Neurons and Cognition,q-bio.NC,"45 pages, 6 figures, 4 tables",A:1805.12491,-,45,https://arxiv.org/pdf/1805.12491.pdf,2018-05-31T14:30:40Z,,"Humans are adept at uncovering complex associations in the world around them, yet the underlying mechanisms remain poorly understood. Intuitively, learning the higher-order structure of statistical relationships should involve sophisticated mental processes, expending valuable computational resources. Here we propose a competing perspective: that higher-order associations actually arise from natural errors in learning. Combining ideas from information theory and reinforcement learning, we derive a novel maximum entropy model of people's internal expectations about the transition structures underlying sequences of ordered events. Importantly, our model analytically accounts for previously unexplained network effects on human expectations and quantitatively describes human reaction times in probabilistic sequential motor tasks. Additionally, our model asserts that human expectations should depend critically on the different topological scales in a transition network, a prediction that we subsequently test and validate in a novel experiment. Generally, our results highlight the important role of mental errors in shaping abstract representations, and directly inspire new physically-motivated models of human behavior.",Structure from noise: Mental errors yield abstract representations of events,"Comment: 45 pages, 6 figures, 4 tables",Subject: Neurons and Cognition [q-bio.NC],"Published 7 days ago in May 31, 2018",2018-05-31T14:30:40Z,-
"Amarjot Singh, Devendra Patil, SN Omkar",Amarjot Singh et al.,cs.CV,Computer Vision and Pattern Recognition,cs.CV,To Appear in the Efficient Deep Learning for Computer Vision (ECV) workshop at IEEE Computer Vision and Pattern Recognition (CVPR) 2018. Youtube demo at this: https://www.youtube.com/watch?v=zYypJPJipYc,A:1806.00746,-,9,https://arxiv.org/pdf/1806.00746.pdf,2018-06-03T07:44:11Z,,"Drone systems have been deployed by various law enforcement agencies to monitor hostiles, spy on foreign drug cartels, conduct border control operations, etc. This paper introduces a real-time drone surveillance system to identify violent individuals in public areas. The system first uses the Feature Pyramid Network to detect humans from aerial images. The image region with the human is used by the proposed ScatterNet Hybrid Deep Learning (SHDL) network for human pose estimation. The orientations between the limbs of the estimated pose are next used to identify the violent individuals. The proposed deep network can learn meaningful representations quickly using ScatterNet and structural priors with relatively fewer labeled examples. The system detects the violent individuals in real-time by processing the drone images in the cloud. This research also introduces the aerial violent individual dataset used for training the deep network which hopefully may encourage researchers interested in using deep learning for aerial surveillance. The pose estimation and violent individuals identification performance is compared with the state-of-the-art techniques.",Eye in the Sky: Real-time Drone Surveillance System (DSS) for Violent Individuals Identification using ScatterNet Hybrid Deep Learning Network,Comment: To Appear in the Efficient Deep Learning for Computer Vision (ECV) workshop at IEEE Computer Vision and Pattern Recognition (CVPR) 2018. Youtube demo at this: https://www.youtube.com/watch?v=zYypJPJipYc,Subject: Computer Vision and Pattern Recognition [cs.CV],"Published 5 days ago in Jun 03, 2018",2018-06-03T07:44:11Z,-
"Felix Juefei-Xu, Vishnu Naresh Boddeti, Marios Savvides",Felix Juefei-Xu et al.,"cs.CV, cs.LG",Computer Vision and Pattern Recognition,cs.CV,To appear in CVPR 2018. http://xujuefei.com/pnn.html,A:1806.01817,-,14,https://arxiv.org/pdf/1806.01817.pdf,2018-06-05T17:15:08Z,,"Convolutional neural networks are witnessing wide adoption in computer vision systems with numerous applications across a range of visual recognition tasks. Much of this progress is fueled through advances in convolutional neural network architectures and learning algorithms even as the basic premise of a convolutional layer has remained unchanged. In this paper, we seek to revisit the convolutional layer that has been the workhorse of state-of-the-art visual recognition models. We introduce a very simple, yet effective, module called a perturbation layer as an alternative to a convolutional layer. The perturbation layer does away with convolution in the traditional sense and instead computes its response as a weighted linear combination of non-linearly activated additive noise perturbed inputs. We demonstrate both analytically and empirically that this perturbation layer can be an effective replacement for a standard convolutional layer. Empirically, deep neural networks with perturbation layers, called Perturbative Neural Networks (PNNs), in lieu of convolutional layers perform comparably with standard CNNs on a range of visual datasets (MNIST, CIFAR-10, PASCAL VOC, and ImageNet) with fewer parameters.",Perturbative Neural Networks,Comment: To appear in CVPR 2018. http://xujuefei.com/pnn.html,Subject: Computer Vision and Pattern Recognition [cs.CV],"Published 3 days ago in Jun 05, 2018",2018-06-05T17:15:08Z,-
"André F. T. Martins, Ramón Fernandez Astudillo",André F. T. Martins et al.,"cs.CL, cs.LG, stat.ML",Computation and Language,cs.CL,Minor corrections,A:1602.02068,"boring formatting information, machine learning, ICML",13,https://arxiv.org/pdf/1602.02068.pdf,2016-02-05T15:49:02Z,,"We propose sparsemax, a new activation function similar to the traditional softmax, but able to output sparse probabilities. After deriving its properties, we show how its Jacobian can be efficiently computed, enabling its use in a network trained with backpropagation. Then, we propose a new smooth and convex loss function which is the sparsemax analogue of the logistic loss. We reveal an unexpected connection between this new loss and the Huber classification loss. We obtain promising empirical results in multi-label classification problems and in attention-based neural networks for natural language inference. For the latter, we achieve a similar performance as the traditional softmax, but with a selective, more compact, attention focus.",From Softmax to Sparsemax: A Sparse Model of Attention and Multi-Label Classification,Comment: Minor corrections,Subject: Computation and Language [cs.CL],"Updated in Feb 08, 2016",2016-02-08T09:41:36Z,-
"Pengcheng Yang, Xu Sun, Wei Li, Shuming Ma",Pengcheng Yang et al.,cs.CL,Computation and Language,cs.CL,Accepted by ACL2018,A:1805.03977,-,7,https://arxiv.org/pdf/1805.03977.pdf,2018-05-10T13:42:29Z,,"As more and more academic papers are being submitted to conferences and journals, evaluating all these papers by professionals is time-consuming and can cause inequality due to the personal factors of the reviewers. In this paper, in order to assist professionals in evaluating academic papers, we propose a novel task: automatic academic paper rating (AAPR), which automatically determine whether to accept academic papers. We build a new dataset for this task and propose a novel modularized hierarchical convolutional neural network to achieve automatic academic paper rating. Evaluation results show that the proposed model outperforms the baselines by a large margin. The dataset and code are available at \url{https://github.com/lancopku/AAPR}",Automatic Academic Paper Rating Based on Modularized Hierarchical Convolutional Neural Network,Comment: Accepted by ACL2018,Subject: Computation and Language [cs.CL],"Published 29 days ago in May 10, 2018",2018-05-10T13:42:29Z,-
"Yuling Yao, Aki Vehtari, Daniel Simpson, Andrew Gelman",Yuling Yao et al.,"stat.ML, stat.CO",Machine Learning,stat.ML,"22 pages, 12 figures",A:1802.02538,-,22,https://arxiv.org/pdf/1802.02538.pdf,2018-02-07T17:25:36Z,,"While it's always possible to compute a variational approximation to a posterior distribution, it can be difficult to discover problems with this approximation"". We propose two diagnostic algorithms to alleviate this problem. The Pareto-smoothed importance sampling (PSIS) diagnostic gives a goodness of fit measurement for joint distributions, while simultaneously improving the error in the estimate. The variational simulation-based calibration (VSBC) assesses the average performance of point estimates.","Yes, but Did It Work?: Evaluating Variational Inference","Comment: 22 pages, 12 figures",Subject: Machine Learning [stat.ML],"Published in Feb 07, 2018",2018-02-07T17:25:36Z,-
"Shehar Bano, Alberto Sonnino, Mustafa Al-Bassam, Sarah Azouvi, Patrick McCorry, Sarah Meiklejohn, George Danezis",Shehar Bano et al.,cs.CR,Cryptography and Security,cs.CR,-,A:1711.03936,-,-,https://arxiv.org/pdf/1711.03936.pdf,2017-11-10T17:47:51Z,,"The blockchain initially gained traction in 2008 as the technology underlying bitcoin, but now has been employed in a diverse range of applications and created a global market worth over $150B as of 2017. What distinguishes blockchains from traditional distributed databases is the ability to operate in a decentralized setting without relying on a trusted third party. As such their core technical component is consensus: how to reach agreement among a group of nodes. This has been extensively studied already in the distributed systems community for closed systems, but its application to open blockchains has revitalized the field and led to a plethora of new designs. The inherent complexity of consensus protocols and their rapid and dramatic evolution makes it hard to contextualize the design landscape. We address this challenge by conducting a systematic and comprehensive study of blockchain consensus protocols. After first discussing key themes in classical consensus protocols, we describe: first protocols based on proof-of-work (PoW), second proof-of-X (PoX) protocols that replace PoW with more energy-efficient alternatives, and third hybrid protocols that are compositions or variations of classical consensus protocols. We develop a framework to evaluate their performance, security and design properties, and use it to systematize key themes in the protocol categories described above. This evaluation leads us to identify research gaps and challenges for the community to consider in future research endeavours.",Consensus in the Age of Blockchains,Comment: [ - pages. ],Subject: Cryptography and Security [cs.CR],"Updated in Nov 14, 2017",2017-11-14T03:18:54Z,-
"Aakanksha Naik, Abhilasha Ravichander, Norman Sadeh, Carolyn Rose, Graham Neubig",Aakanksha Naik et al.,cs.CL,Computation and Language,cs.CL,COLING 2018,A:1806.00692,-,12,https://arxiv.org/pdf/1806.00692.pdf,2018-06-02T19:14:39Z,,"Natural language inference (NLI) is the task of determining if a natural language hypothesis can be inferred from a given premise in a justifiable manner. NLI was proposed as a benchmark task for natural language understanding. Existing models perform well at standard datasets for NLI, achieving impressive results across different genres of text. However, the extent to which these models understand the semantic content of sentences is unclear. In this work, we propose an evaluation methodology consisting of automatically constructed ""stress tests"" that allow us to examine whether systems have the ability to make real inferential decisions. Our evaluation of six sentence-encoder models on these stress tests reveals strengths and weaknesses of these models with respect to challenging linguistic phenomena, and suggests important directions for future work in this area.",Stress Test Evaluation for Natural Language Inference,Comment: COLING 2018,Subject: Computation and Language [cs.CL],Updated yesterday,2018-06-07T04:23:55Z,-
"Hyunghoon Cho, Benjamin DeMeo, Jian Peng, Bonnie Berger",Hyunghoon Cho et al.,"cs.LG, stat.ML",Learning,cs.LG,-,A:1806.00437,-,14,https://arxiv.org/pdf/1806.00437.pdf,2018-06-01T16:52:16Z,,"Representing data in hyperbolic space can effectively capture latent hierarchical relationships. With the goal of enabling accurate classification of points in hyperbolic space while respecting their hyperbolic geometry, we introduce hyperbolic SVM, a hyperbolic formulation of support vector machine classifiers, and elucidate through new theoretical work its connection to the Euclidean counterpart. We demonstrate the performance improvement of hyperbolic SVM for multi-class prediction tasks on real-world complex networks as well as simulated datasets. Our work allows analytic pipelines that take the inherent hyperbolic geometry of the data into account in an end-to-end fashion without resorting to ill-fitting tools developed for Euclidean space.",Large-Margin Classification in Hyperbolic Space,Comment: [ 14 pages. ],Subject: Learning [cs.LG],"Published 8 days ago in Jun 01, 2018",2018-06-01T16:52:16Z,-
"Yixin Wang, David M. Blei",Yixin Wang et al.,"stat.ML, cs.LG, stat.ME",Machine Learning,stat.ML,54 pages,A:1805.06826,-,54,https://arxiv.org/pdf/1805.06826.pdf,2018-05-17T15:39:17Z,,"Causal inference from observation data often assumes ""strong ignorability,"" that all confounders are observed. This assumption is standard yet untestable. However, many scientific studies involve multiple causes, different variables whose effects are simultaneously of interest. We propose the deconfounder, an algorithm that combines unsupervised machine learning and predictive model checking to perform causal inference in multiple-cause settings. The deconfounder infers a latent variable as a substitute for unobserved confounders and then uses that substitute to perform causal inference. We develop theory for when the deconfounder leads to unbiased causal estimates, and show that it requires weaker assumptions than classical causal inference. We analyze its performance in three types of studies: semi-simulated data around smoking and lung cancer, semi-simulated data around genomewide association studies, and a real dataset about actors and movie revenue. The deconfounder provides a checkable approach to estimating close-to-truth causal effects.",The Blessings of Multiple Causes,Comment: 54 pages,Subject: Machine Learning [stat.ML],"Published 23 days ago in May 17, 2018",2018-05-17T15:39:17Z,-
"Adam R. Kosiorek, Hyunjik Kim, Ingmar Posner, Yee Whye Teh",Adam R. Kosiorek et al.,"cs.LG, cs.CV, stat.ML",Learning,cs.LG,"25 pages, 19 figures, submitted to NIPS",A:1806.01794,-,25,https://arxiv.org/pdf/1806.01794.pdf,2018-06-05T16:29:44Z,,"We present Sequential Attend, Infer, Repeat (SQAIR), an interpretable deep generative model for videos of moving objects. It can reliably discover and track objects throughout the sequence of frames, and can also generate future frames conditioning on the current frame, thereby simulating expected motion of objects. This is achieved by explicitly encoding object presence, locations and appearances in the latent variables of the model. SQAIR retains all strengths of its predecessor, Attend, Infer, Repeat (AIR, Eslami et. al., 2016), including learning in an unsupervised manner, and addresses its shortcomings. We use a moving multi-MNIST dataset to show limitations of AIR in detecting overlapping or partially occluded objects, and show how SQAIR overcomes them by leveraging temporal consistency of objects. Finally, we also apply SQAIR to real-world pedestrian CCTV data, where it learns to reliably detect, track and generate walking pedestrians with no supervision.","Sequential Attend, Infer, Repeat: Generative Modelling of Moving Objects","Comment: 25 pages, 19 figures, submitted to NIPS",Subject: Learning [cs.LG],"Published 4 days ago in Jun 05, 2018",2018-06-05T16:29:44Z,-
"Rodrigo A. Ibata, Khyati Malhan, Nicolas F. Martin, Else Starkenburg",Rodrigo A. Ibata et al.,astro-ph.GA,Astrophysics of Galaxies,astro-ph.GA,"6 pages, 8 figures",A:1806.01195,-,6,https://arxiv.org/pdf/1806.01195.pdf,2018-06-04T16:38:17Z,,"We report the discovery of a $60\deg$ long stellar stream in Gaia DR2 catalog, found using the new STREAMFINDER algorithm. The structure, which is probably the remnant of a now fully disrupted globular cluster, lies $\approx 3.6 \, {\rm kpc}$ away from the Sun in the direction of the Galactic bulge, and possesses highly retrograde motion. We find that the system orbits close to the Galactic plane at Galactocentric distances between $4.8$ and $15.4 \, {\rm kpc}$. The discovery of this extended and extremely low surface brightness stream ($\Sigma_G\sim 34.6 \, {\rm mag \, arcsec^{-2}}$) with a mass of only $1180\pm90 \, {\rm\,M_\odot}$, demonstrates the power of the STREAMFINDER algorithm to detect even very nearby and ultra-faint structures. Due to its proximity and length we expect that Phlegethon will be a very useful probe of the Galactic acceleration field.","Phlegethon, a nearby $60°$-long retrograde stellar stream","Comment: 6 pages, 8 figures",Subject: Astrophysics of Galaxies [astro-ph.GA],"Published 5 days ago in Jun 04, 2018",2018-06-04T16:38:17Z,-
"Robin Manhaeve, Sebastijan Dumančić, Angelika Kimmig, Thomas Demeester, Luc De Raedt",Robin Manhaeve et al.,cs.AI,Artificial Intelligence,cs.AI,Submitted to NIPS 2018,A:1805.10872,-,13,https://arxiv.org/pdf/1805.10872.pdf,2018-05-28T11:33:00Z,,"We introduce DeepProbLog, a probabilistic logic programming language that incorporates deep learning by means of neural predicates. We show how existing inference and learning techniques can be adapted for the new language. Our experiments demonstrate that DeepProbLog supports both symbolic and subsymbolic representations and inference, 1) program induction, 2) probabilistic (logic) programming, and 3) (deep) learning from examples. To the best of our knowledge, this work is the first to propose a framework where general-purpose neural networks and expressive probabilistic-logical modeling and reasoning are integrated in a way that exploits the full expressiveness and strengths of both worlds and can be trained end-to-end based on examples.",DeepProbLog: Neural Probabilistic Logic Programming,Comment: Submitted to NIPS 2018,Subject: Artificial Intelligence [cs.AI],"Published 12 days ago in May 28, 2018",2018-05-28T11:33:00Z,-
Martin Celli,Martin Celli,math.HO,History and Overview,math.HO,-,A:1806.00207,-,3,https://arxiv.org/pdf/1806.00207.pdf,2018-06-01T06:18:51Z,,"Taking up the challenge McConnell laid down at the end of his proof of the law of cosines, we give a completely visual dissection proof of this theorem, which applies to any triangle. In order to avoid the trigonometric expressions of Cuoco-McConnell's proof, we replaced the equal-area rectangles with congruent triangles. As a matter of fact, trigonometric expressions are implicitly based on the similarity of two right triangles with a common non-right angle. So they are conceptually less simple than our congruent triangles which are, moreover, easy to visualize. This makes our proof the only dissection proof and the simplest proof of its family, and thus one of the best options for a course of geometry.","A dissection proof of the law of cosines, replacing Cuoco-McConnell's rectangles with congruent triangles",Comment: [ 3 pages. ],Subject: History and Overview [math.HO],"Published 9 days ago in Jun 01, 2018",2018-06-01T06:18:51Z,-
"Yasamin Jafarian, Yuan Yao, Hyun Soo Park",Yasamin Jafarian et al.,cs.CV,Computer Vision and Pattern Recognition,cs.CV,-,A:1806.00104,-,12,https://arxiv.org/pdf/1806.00104.pdf,2018-05-31T21:27:33Z,,"This paper presents MONET---an end-to-end semi-supervised learning framework for a pose detector using multiview image streams. What differentiates MONET from existing models is its capability of detecting general subjects including non-human species without a pre-trained model. A key challenge of such subjects lies in the limited availability of expert manual annotations, which often leads to a large bias in the detection model. We address this challenge by using the epipolar constraint embedded in the unlabeled data in two ways. First, given a set of the labeled data, the keypoint trajectories can be reliably reconstructed in 3D using multiview optical flows, resulting in considerable data augmentation in space and time from nearly exhaustive views. Second, the detection across views must geometrically agree with each other. We introduce a new measure of geometric consistency in keypoint distributions called epipolar divergence---a generalized distance from the epipolar lines to the corresponding keypoint distribution. Epipolar divergence characterizes when two view keypoint distributions produces zero reprojection error. We design a twin network that minimizes the epipolar divergence through stereo rectification that can significantly alleviate computational complexity and sampling aliasing in training. We demonstrate that our framework can localize customized keypoints of diverse species, e.g., humans, dogs, and monkeys.",MONET: Multiview Semi-supervised Keypoint via Epipolar Divergence,Comment: [ 12 pages. ],Subject: Computer Vision and Pattern Recognition [cs.CV],"Published 9 days ago in May 31, 2018",2018-05-31T21:27:33Z,-
"Matthew Welborn, Lixue Cheng, Thomas F. Miller III",Matthew Welborn et al.,physics.chem-ph,Chemical Physics,physics.chem-ph,"7 pages, 5 figures",A:1806.00133,-,7,https://arxiv.org/pdf/1806.00133.pdf,2018-05-31T23:28:04Z,,"We present a machine learning (ML) method for predicting electronic structure correlation energies using Hartree-Fock input.The total correlation energy is expressed in terms of individual and pair contributions from occupied molecular orbitals, and Gaussian process regression is used to predict these contributions from a feature set that is based on molecular orbital properties, such as Fock, Coulomb, and exchange matrix elements. With the aim of maximizing transferability across chemical systems and compactness of the feature set, we avoid the usual specification of ML features in terms of atom- or geometry-specific information, such atom/element-types, bond-types, or local molecular structure. ML predictions of MP2 and CCSD energies are presented for a range of systems, demonstrating that the method maintains accuracy while providing transferability both within and across chemical families; this includes predictions for molecules with atom-types and elements that are not included in the training set. The method holds promise both in its current form and as a proof-of-principle for the use of ML in the design of generalized density-matrix functionals.",Transferability in Machine Learning for Electronic Structure via the Molecular Orbital Basis,"Comment: 7 pages, 5 figures",Subject: Chemical Physics [physics.chem-ph],"Published 9 days ago in May 31, 2018",2018-05-31T23:28:04Z,-
"Mads T. Frandsen, Jonas Petersen",Mads T. Frandsen et al.,"astro-ph.GA, hep-ph",Astrophysics of Galaxies,astro-ph.GA,"24 pages, 4 figures",A:1805.10706,-,24,https://arxiv.org/pdf/1805.10706.pdf,2018-05-27T22:53:54Z,,"We study geometries of galactic rotation curves from Dark Matter (DM) and Modified Newtonian Dynamics (MOND) models in $(g_{\rm bar},g_{\rm tot})$-space ($g2$-space) where $g_{\rm tot}$ is the total centripetal acceleration of matter in the galaxies and $g_{\rm bar}$ is that due to the baryonic (visible) matter assuming Newtonian gravity. The $g2$-space geometries of the models and data from the SPARC database are classified and compared in a rescaled $\hat{g}2$-space that reduces systematic uncertainties on galaxy distance, inclination angle and variations in mass to light ratios. We find that MOND modified inertia models, frequently used to fit rotation curve data, are disfavoured at more than 5$\sigma$ independent of model details. The Bekenstein-Milgrom formulation of MOND modified gravity compares better with data in the analytic approximation we use. However a quantitative comparison with data is beyond the scope of the paper due to this approximation. NFW DM profiles only agree with a minority of galactic rotation curves. Improved measurements of rotation curves, in particular at radii below the maximum of the total and the baryonic accelerations of the curves are very important in discriminating models aiming to explain the missing mass problem on galactic scales.",Investigating Dark Matter and MOND Models with Galactic Rotation Curve Data,"Comment: 24 pages, 4 figures",Subject: Astrophysics of Galaxies [astro-ph.GA],"Published 13 days ago in May 27, 2018",2018-05-27T22:53:54Z,-
"Tze Yeung Mathew Yu, Ruth Murray-Clay, Kathryn Volk",Tze Yeung Mathew Yu et al.,astro-ph.EP,Earth and Planetary Astrophysics,astro-ph.EP,-,A:1805.08228,-,18,https://arxiv.org/pdf/1805.08228.pdf,2018-05-21T18:01:08Z,,"A substantial fraction of our solar system's trans-Neptunian objects (TNOs) are in mean motion resonance with Neptune. Many of these objects were likely caught into resonances by planetary migration---either smooth or stochastic---approximately 4 Gyr ago. Some, however, gravitationally scattered off of Neptune and became transiently stuck in more recent events. Here, we use numerical simulations to predict the number of transiently-stuck objects, captured from the current actively scattering population, that occupy 111 resonances at semimajor axes $a=$30--100 au. Our source population is an observationally constrained model of the currently-scattering TNOs. We predict that, integrated across all resonances at these distances, the current transient sticking population comprises 40\% of total transiently-stuck+scattering TNOs, suggesting that these objects should be treated as a single population. We compute the relative distribution of transiently-stuck objects across all $p$:$q$ resonances with $1/6 \le q/p < 1$, $p<40$, and $q<20$, providing predictions for the population of transient objects with $H_r < 8.66$ in each resonance. We find that the relative populations are approximately proportional to each resonance's libration period and confirm that the importance of transient sticking increases with semimajor axis in the studied range. We calculate the expected distribution of libration amplitudes for stuck objects and demonstrate that observational constraints indicate that both the total number and the amplitude-distribution of 5:2 resonant TNOs are inconsistent with a population dominated by transient sticking from the current scattering disk. The 5:2 resonance hence poses a challenge for leading theories of Kuiper belt sculpting.",Trans-Neptunian Objects Transiently Stuck in Neptune's Mean Motion Resonances: Numerical simulations of the current population,Comment: [ 18 pages. ],Subject: Earth and Planetary Astrophysics [astro-ph.EP],"Published 20 days ago in May 21, 2018",2018-05-21T18:01:08Z,-
"Florian Maire, Nial Friel, Pierre Alquier",Florian Maire et al.,"stat.ME, stat.CO, 65C40, 65C60, 62F15",Methodology,stat.ME,-,A:1706.08327,-,51,https://arxiv.org/pdf/1706.08327.pdf,2017-06-26T11:24:51Z,,"This paper introduces a framework for speeding up Bayesian inference conducted in presence of large datasets. We design a Markov chain whose transition kernel uses an (unknown) fraction of (fixed size) of the available data that is randomly refreshed throughout the algorithm. Inspired by the Approximate Bayesian Computation (ABC) literature, the subsampling process is guided by the fidelity to the observed data, as measured by summary statistics. The resulting algorithm, Informed Sub-Sampling MCMC (ISS-MCMC), is a generic and flexible approach which, contrary to existing scalable methodologies, preserves the simplicity of the Metropolis-Hastings algorithm. Even though exactness is lost, i.e. the chain distribution approximates the posterior, we study and quantify theoretically this bias and show on a diverse set of examples that it yields excellent performances when the computational budget is limited. If available and cheap to compute, we show that setting the summary statistics as the maximum likelihood estimator is supported by theoretical arguments.",Informed Sub-Sampling MCMC: Approximate Bayesian Inference for Large Datasets,Comment: [ 51 pages. ],Subject: Methodology [stat.ME],"Updated 10 days ago in May 31, 2018",2018-05-31T09:20:50Z,-
ATLAS Collaboration,ATLAS Collaboration,hep-ex,High Energy Physics - Experiment,hep-ex,"33 pages in total, author list starting page 17, 6 figures, 3 tables, submitted to PLB. All figures including auxiliary figures are available at https://atlas.web.cern.ch/Atlas/GROUPS/PHYSICS/PAPERS/HIGG-2018-13",A:1806.00425,-,33,https://arxiv.org/pdf/1806.00425.pdf,2018-06-01T16:30:08Z,,"The observation of Higgs boson production in association with a top quark pair ($t\bar{t}H$), based on the analysis of proton--proton collision data at a centre-of-mass energy of 13 TeV recorded with the ATLAS detector at the Large Hadron Collider, is presented. Using data corresponding to integrated luminosities of up to 79.8 fb$^{-1}$, and considering Higgs boson decays into $b\bar{b}$, $WW^*$, $\tau\tau$, $\gamma\gamma$, and $ZZ^*$, the observed significance is 5.8 standard deviations, compared to an expectation of 4.9 standard deviations. Combined with the $t\bar{t}H$ searches using a dataset corresponding to integrated luminosities of 4.5 fb$^{-1}$ at 7 TeV and 20.3 fb$^{-1}$ at 8 TeV, the observed (expected) significance is 6.3 (5.1) standard deviations. Assuming Standard Model branching fractions, the total $t\bar{t}H$ production cross section at 13 TeV is measured to be 670 $\pm$ 90 (stat.) $^{+110}_{-100}$ (syst.) fb, in agreement with the Standard Model prediction.",Observation of Higgs boson production in association with a top quark pair at the LHC with the ATLAS detector,"Comment: 33 pages in total, author list starting page 17, 6 figures, 3 tables, submitted to PLB. All figures including auxiliary figures are available at https://atlas.web.cern.ch/Atlas/GROUPS/PHYSICS/PAPERS/HIGG-2018-13",Subject: High Energy Physics - Experiment [hep-ex],"Published 10 days ago in Jun 01, 2018",2018-06-01T16:30:08Z,-
"P. Bianchini, R. P. van der Marel, A. del Pino, L. L. Watkins, A. Bellini, M. A. Fardal, M. Libralato, A. Sills",P. Bianchini et al.,astro-ph.GA,Astrophysics of Galaxies,astro-ph.GA,Submitted to MNRAS. Comments are welcome!,A:1806.02580,-,16,https://arxiv.org/pdf/1806.02580.pdf,2018-06-07T09:31:32Z,,"Line-of-sight kinematic studies indicate that many Galactic globular clusters have a significant degree of internal rotation. However, three-dimensional kinematics from a combination of proper motions and line-of-sight velocities are needed to unveil the role of angular momentum in the formation and evolution of these old stellar systems. Here we present the first quantitative study of internal rotation on the plane-of-the-sky for a large sample of globular clusters using proper motions from Gaia DR2. We detect signatures of rotation in the tangential component of proper motions for 11 out of 51 clusters at a $>$3-sigma confidence level, confirming the detection reported in Gaia Collaboration et al. 2018 for 8 clusters. Moreover, we construct the two-dimensional rotation maps and proper motion rotation curves, and we assess the relevance of rotation with respect to random motions ($V/\sigma\sim0.08-0.53$). We find evidence of a correlation between the degree of internal rotation and relaxation time, highlighting the importance of long-term dynamical evolution in shaping the clusters current properties. This is a strong indication that angular momentum must have played a fundamental role in the earliest phases of cluster formation. Finally, exploiting the spatial information of the rotation maps and a comparison with line-of-sight data, we provide an estimate of the inclination of the rotation axis for a subset of 8 clusters. Our work demonstrates the potential of Gaia data for internal kinematic studies of globular clusters and provides the first step to reconstruct their intrinsic three-dimensional structure.",The internal rotation of globular clusters revealed by Gaia DR2,Comment: Submitted to MNRAS. Comments are welcome!,Subject: Astrophysics of Galaxies [astro-ph.GA],"Published 4 days ago in Jun 07, 2018",2018-06-07T09:31:32Z,-
Chaomei Chen,Chaomei Chen,cs.DL,Digital Libraries,cs.DL,16 figures,A:1806.00089,-,22,https://arxiv.org/pdf/1806.00089.pdf,2018-05-31T20:33:29Z,,"Digital Science's Dimensions is envisaged as a next-generation research and discovery platform for a better and more efficient access to cross-referenced scholarly publications, grants, patents, and clinical trials. As a new addition to the growing open citation resources, it offers opportunities that may benefit a wide variety of stakeholders of scientific publications from researchers, policy makers, and the general public. In this article, we explore and demonstrate some of the practical potentials in terms of cascading citation expansions. Given a set of publications, the cascading citation expansion process can be successively applied to a set of articles so as to extend the coverage to more and more relevant articles through citation links. Although the conceptual origin can be traced back to Garfield's citation indexing, it has been largely limited, until recently, to the few who have unrestricted access to a citation database that is large enough to sustain such iterative expansions. Building on the open API of Dimensions, we integrate cascading citation expansion functions in CiteSpace and demonstrate how one may benefit from these new capabilities. In conclusion, cascading citation expansion has the potential to improve our understanding of the structure and dynamics of scientific knowledge.",Cascading Citation Expansion,Comment: 16 figures,Subject: Digital Libraries [cs.DL],"Published 10 days ago in May 31, 2018",2018-05-31T20:33:29Z,-
"Ward S. Howard, Matt A. Tilley, Hank Corbett, Allison Youngblood, R. O. Parke Loyd, Jeffrey K. Ratzloff, Nicholas M. Law, Octavi Fors, Daniel del Ser, Evgenya L. Shkolnik, Carl Ziegler, Erin E. Goeke, Aaron D. Pietraallo, Joshua Haislip",Ward S. Howard et al.,"astro-ph.EP, astro-ph.SR",Earth and Planetary Astrophysics,astro-ph.EP,"7 pages, 5 figures, accepted in ApJ Letters. Includes minor changes, extra habitability calculations",A:1804.02001,-,7,https://arxiv.org/pdf/1804.02001.pdf,2018-04-05T18:00:18Z,,"Proxima b is a terrestrial-mass planet in the habitable-zone of Proxima Centauri. Proxima Centauri's high stellar activity however casts doubt on the habitability of Proxima b: sufficiently bright and frequent flares and any associated proton events may destroy the planet's ozone layer, allowing lethal levels of UV flux to reach its surface. In March 2016, the Evryscope observed the first naked-eye-brightness superflare detected from Proxima Centauri. Proxima increased in optical flux by a factor of ~68 during the superflare and released a bolometric energy of 10^33.5 erg, ~10X larger than any previously-detected flare from Proxima. Over the last two years the Evryscope has recorded 23 other large Proxima flares ranging in bolometric energy from 10^30.6 erg to 10^32.4 erg; coupling those rates with the single superflare detection, we predict at least five superflares occur each year. Simultaneous high-resolution HARPS spectroscopy during the Evryscope superflare constrains the superflare's UV spectrum and any associated coronal mass ejections. We use these results and the Evryscope flare rates to model the photochemical effects of NOx atmospheric species generated by particle events from this extreme stellar activity, and show that the repeated flaring may be sufficient to reduce the ozone of an Earth-like atmosphere by 90% within five years; complete depletion may occur within several hundred kyr. The UV light produced by the Evryscope superflare would therefore have reached the surface with ~100X the intensity required to kill simple UV-hardy microorganisms, suggesting that life would have to undergo extreme adaptations to survive in the surface areas of Proxima b exposed to these flares.",The First Naked-Eye Superflare Detected from Proxima Centauri,"Comment: 7 pages, 5 figures, accepted in ApJ Letters. Includes minor changes, extra habitability calculations",Subject: Earth and Planetary Astrophysics [astro-ph.EP],"Updated 4 days ago in Jun 08, 2018",2018-06-08T02:47:49Z,-
"Trieu H. Trinh, Quoc V. Le",Trieu H. Trinh et al.,"cs.AI, cs.CL, cs.LG",Artificial Intelligence,cs.AI,-,A:1806.02847,-,12,https://arxiv.org/pdf/1806.02847.pdf,2018-06-07T18:13:08Z,,"Commonsense reasoning is a long-standing challenge for deep learning. For example, it is difficult to use neural networks to tackle the Winograd Schema dataset~\cite{levesque2011winograd}. In this paper, we present a simple method for commonsense reasoning with neural networks, using unsupervised learning. Key to our method is the use of language models, trained on a massive amount of unlabled data, to score multiple choice questions posed by commonsense reasoning tests. On both Pronoun Disambiguation and Winograd Schema challenges, our models outperform previous state-of-the-art methods by a large margin, without using expensive annotated knowledge bases or hand-engineered features. We train an array of large RNN language models that operate at word or character level on LM-1-Billion, CommonCrawl, SQuAD, Gutenberg Books, and a customized corpus for this task and show that diversity of training data plays an important role in test performance. Further analysis also shows that our system successfully discovers important features of the context that decide the correct answer, indicating a good grasp of commonsense knowledge.",A Simple Method for Commonsense Reasoning,Comment: [ 12 pages. ],Subject: Artificial Intelligence [cs.AI],"Published 4 days ago in Jun 07, 2018",2018-06-07T18:13:08Z,-
"Rex Ying, Ruining He, Kaifeng Chen, Pong Eksombatchai, William L. Hamilton, Jure Leskovec",Rex Ying et al.,"cs.IR, cs.LG, stat.ML",Information Retrieval,cs.IR,KDD 2018,A:1806.01973,-,10,https://arxiv.org/pdf/1806.01973.pdf,2018-06-06T01:26:33Z,,"Recent advancements in deep neural networks for graph-structured data have led to state-of-the-art performance on recommender system benchmarks. However, making these methods practical and scalable to web-scale recommendation tasks with billions of items and hundreds of millions of users remains a challenge. Here we describe a large-scale deep recommendation engine that we developed and deployed at Pinterest. We develop a data-efficient Graph Convolutional Network (GCN) algorithm PinSage, which combines efficient random walks and graph convolutions to generate embeddings of nodes (i.e., items) that incorporate both graph structure as well as node feature information. Compared to prior GCN approaches, we develop a novel method based on highly efficient random walks to structure the convolutions and design a novel training strategy that relies on harder-and-harder training examples to improve robustness and convergence of the model. We also develop an efficient MapReduce model inference algorithm to generate embeddings using a trained model. We deploy PinSage at Pinterest and train it on 7.5 billion examples on a graph with 3 billion nodes representing pins and boards, and 18 billion edges. According to offline metrics, user studies and A/B tests, PinSage generates higher-quality recommendations than comparable deep learning and graph-based alternatives. To our knowledge, this is the largest application of deep graph embeddings to date and paves the way for a new generation of web-scale recommender systems based on graph convolutional architectures.",Graph Convolutional Neural Networks for Web-Scale Recommender Systems,Comment: KDD 2018,Subject: Information Retrieval [cs.IR],"Published 6 days ago in Jun 06, 2018",2018-06-06T01:26:33Z,-
"Sebastian Ruder, Ivan Vulić, Anders Søgaard",Sebastian Ruder et al.,"cs.CL, cs.LG",Computation and Language,cs.CL,Very heavily improved and revised version,A:1706.04902,-,55,https://arxiv.org/pdf/1706.04902.pdf,2017-06-15T14:46:56Z,,"Cross-lingual representations of words enable us to reason about word meaning in multilingual contexts and are a key facilitator of cross-lingual transfer when developing natural language processing models for low-resource languages. In this survey, we provide a comprehensive typology of cross-lingual word embedding models. We compare their data requirements and objective functions. The recurring theme of the survey is that many of the models presented in the literature optimize for the same objectives, and that seemingly different models are often equivalent modulo optimization strategies, hyper-parameters, and such. We also discuss the different ways cross-lingual word embeddings are evaluated, as well as future challenges and research horizons.",A Survey Of Cross-lingual Word Embedding Models,Comment: Very heavily improved and revised version,Subject: Computation and Language [cs.CL],"Updated in Oct 18, 2017",2017-10-18T10:44:06Z,-
"Andreas Groll, Christophe Ley, Gunther Schauberger, Hans Van Eetvelde",Andreas Groll et al.,stat.AP,Applications,stat.AP,"First revised version, corrected typo in introduction when referring to the winning probabilities derived by Zeileis, Leitner, and Hornik (2018), which are for Germany 15.8% instead of 12.8%. Second revised version, slight changes in notation in Section 3.3",A:1806.03208,-,28,https://arxiv.org/pdf/1806.03208.pdf,2018-06-08T15:04:45Z,,"In this work, we compare three different modeling approaches for the scores of soccer matches with regard to their predictive performances based on all matches from the four previous FIFA World Cups 2002 - 2014: Poisson regression models, random forests and ranking methods. While the former two are based on the teams' covariate information, the latter method estimates adequate ability parameters that reflect the current strength of the teams best. Within this comparison the best-performing prediction methods on the training data turn out to be the ranking methods and the random forests. However, we show that by combining the random forest with the team ability parameters from the ranking methods as an additional covariate we can improve the predictive power substantially. Finally, this combination of methods is chosen as the final model and based on its estimates, the FIFA World Cup 2018 is simulated repeatedly and winning probabilities are obtained for all teams. The model slightly favors Spain before the defending champion Germany. Additionally, we provide survival probabilities for all teams and at all tournament stages as well as the most probable tournament outcome.",Prediction of the FIFA World Cup 2018 - A random forest approach with an emphasis on estimated team ability parameters,"Comment: First revised version, corrected typo in introduction when referring to the winning probabilities derived by Zeileis, Leitner, and Hornik (2018), which are for Germany 15.8% instead of 12.8%. Second revised version, slight changes in notation in Section 3.3",Subject: Applications [stat.AP],Updated yesterday,2018-06-13T15:16:22Z,-
"F. Marin, C. Beluffi",F. Marin et al.,"astro-ph.IM, physics.pop-ph, 85-04, 91C99, J.2; K.4",Instrumentation and Methods for Astrophysics,astro-ph.IM,"8 pages, 6 figures, 2 tables. Accepted for publication in JBIS",A:1806.03856,-,5,https://arxiv.org/pdf/1806.03856.pdf,2018-06-11T08:32:49Z,,"The survival of a genetically healthy multi-generational crew is of a prime concern when dealing with space travel. It has been shown that determining a realistic population size is tricky as many parameters (such as infertility, inbreeding, sudden deaths, accidents or random events) come into play. To evaluate the impact of those parameters, Monte Carlo simulations are among the best methods since they allow testing of all possible scenarios and determine, by numerous iterations, which are the most likely. This is why we use the Monte Carlo code HERITAGE to estimate the minimal crew for a multi-generational space travel towards Proxima Centauri b. By allowing the crew to evolve under a list of adaptive social engineering principles (namely yearly evaluations of the vessel population, offspring restrictions and breeding constraints), we show in this paper that it is possible to create and maintain a healthy population virtually indefinitely. A initial amount of 25 breeding pairs of settlers drives the mission towards extinction in 50 +/- 15% of cases if we completely forbid inbreeding. Under the set of parameters described in this publication, we find that a minimum crew of 98 people is necessary ensure a 100% success rate for a 6300-year space travel towards the closest telluric exoplanet known so far.",Computing the minimal crew for a multi-generational space travel towards Proxima Centauri b,"Comment: 8 pages, 6 figures, 2 tables. Accepted for publication in JBIS",Subject: Instrumentation and Methods for Astrophysics [astro-ph.IM],"Published 3 days ago in Jun 11, 2018",2018-06-11T08:32:49Z,-
"Victor Zhong, Caiming Xiong, Richard Socher",Victor Zhong et al.,"cs.CL, cs.AI",Computation and Language,cs.CL,"ACL 2018. 10 pages, 5 figures. Source code: https://github.com/salesforce/glad",A:1805.09655,-,10,https://arxiv.org/pdf/1805.09655.pdf,2018-05-19T19:23:38Z,,"Dialogue state tracking, which estimates user goals and requests given the dialogue context, is an essential part of task-oriented dialogue systems. In this paper, we propose the Global-Locally Self-Attentive Dialogue State Tracker (GLAD), which learns representations of the user utterance and previous system actions with global-local modules. Our model uses global modules to share parameters between estimators for different types (called slots) of dialogue states, and uses local modules to learn slot-specific features. We show that this significantly improves tracking of rare states and achieves state-of-the-art performance on the WoZ and DSTC2 state tracking tasks. GLAD obtains 88.1% joint goal accuracy and 97.1% request accuracy on WoZ, outperforming prior work by 3.7% and 5.5%. On DSTC2, our model obtains 74.5% joint goal accuracy and 97.5% request accuracy, outperforming prior work by 1.1% and 1.0%.",Global-Locally Self-Attentive Dialogue State Tracker,"Comment: ACL 2018. 10 pages, 5 figures. Source code: https://github.com/salesforce/glad",Subject: Computation and Language [cs.CL],Updated yesterday,2018-06-12T22:11:50Z,-
"Ben Athiwaratkun, Andrew Gordon Wilson, Anima Anandkumar",Ben Athiwaratkun et al.,"cs.CL, cs.AI, cs.LG, stat.ML",Computation and Language,cs.CL,Published at ACL 2018,A:1806.02901,-,11,https://arxiv.org/pdf/1806.02901.pdf,2018-06-07T20:57:22Z,,"We introduce Probabilistic FastText, a new model for word embeddings that can capture multiple word senses, sub-word structure, and uncertainty information. In particular, we represent each word with a Gaussian mixture density, where the mean of a mixture component is given by the sum of n-grams. This representation allows the model to share statistical strength across sub-word structures (e.g. Latin roots), producing accurate representations of rare, misspelt, or even unseen words. Moreover, each component of the mixture can capture a different word sense. Probabilistic FastText outperforms both FastText, which has no probabilistic model, and dictionary-level probabilistic embeddings, which do not incorporate subword structures, on several word-similarity benchmarks, including English RareWord and foreign language datasets. We also achieve state-of-art performance on benchmarks that measure ability to discern different meanings. Thus, the proposed model is the first to achieve multi-sense representations while having enriched semantics on rare words.",Probabilistic FastText for Multi-Sense Word Embeddings,Comment: Published at ACL 2018,Subject: Computation and Language [cs.CL],"Published 6 days ago in Jun 07, 2018",2018-06-07T20:57:22Z,-
"Antoine Allard, Laurent Hébert-Dufresne",Antoine Allard et al.,"physics.soc-ph, cond-mat.stat-mech",Physics and Society,physics.soc-ph,"11 pages, 4 figures",A:1804.09633,-,11,https://arxiv.org/pdf/1804.09633.pdf,2018-04-25T15:37:19Z,,"Analytical approaches to model the structure of complex networks can be distinguished into two groups according to whether they consider an intensive (e.g., fixed degree sequence and random otherwise) or an extensive (e.g., adjacency matrix) description of the network structure. While extensive approaches---such as the state-of-the-art Message Passing Approach---typically yield more accurate predictions, intensive approaches provide crucial insights on the role played by any given structural property in the outcome of dynamical processes. Here we introduce an intensive description that yields almost identical predictions to the ones obtained with MPA for bond percolation. Our approach distinguishes nodes according to two simple statistics: their degree and their position in the core-periphery organization of the network. Our near-exact predictions highlight how accurately capturing the long-range correlations in network structures allows to easily and effectively compress real complex network data.",Percolation and the effective structure of complex networks,"Comment: 11 pages, 4 figures",Subject: Physics and Society [physics.soc-ph],"Published in Apr 25, 2018",2018-04-25T15:37:19Z,-
"Dokyung Song, Julian Lettner, Prabhu Rajasekaran, Yeoul Na, Stijn Volckaert, Per Larsen, Michael Franz",Dokyung Song et al.,"cs.CR, cs.PL",Cryptography and Security,cs.CR,-,A:1806.04355,-,20,https://arxiv.org/pdf/1806.04355.pdf,2018-06-12T06:36:30Z,,"The C and C++ programming languages are notoriously insecure yet remain indispensable. Developers therefore resort to a multi-pronged approach to find security issues before adversaries. These include manual, static, and dynamic program analysis. Dynamic bug finding tools --- henceforth ""sanitizers"" --- can find bugs that elude other types of analysis because they observe the actual execution of a program, and can therefore directly observe incorrect program behavior as it happens. A vast number of sanitizers have been prototyped by academics and refined by practitioners. We provide a systematic overview of sanitizers with an emphasis on their role in finding security issues. Specifically, we taxonomize the available tools and the security vulnerabilities they cover, describe their performance and compatibility properties, and highlight various trade-offs.",SoK: Sanitizing for Security,Comment: [ 20 pages. ],Subject: Cryptography and Security [cs.CR],"Published 2 days ago in Jun 12, 2018",2018-06-12T06:36:30Z,-
"Abel L Peirson V, E Meltem Tolunay",Abel L Peirson V et al.,"cs.CL, cs.LG",Computation and Language,cs.CL,Stanford CS 224n Project,A:1806.04510,-,9,https://arxiv.org/pdf/1806.04510.pdf,2018-06-08T03:29:30Z,,"We introduce a novel meme generation system, which given any image can produce a humorous and relevant caption. Furthermore, the system can be conditioned on not only an image but also a user-defined label relating to the meme template, giving a handle to the user on meme content. The system uses a pretrained Inception-v3 network to return an image embedding which is passed to an attention-based deep-layer LSTM model producing the caption - inspired by the widely recognised Show and Tell Model. We implement a modified beam search to encourage diversity in the captions. We evaluate the quality of our model using perplexity and human assessment on both the quality of memes generated and whether they can be differentiated from real ones. Our model produces original memes that cannot on the whole be differentiated from real ones.",Dank Learning: Generating Memes Using Deep Neural Networks,Comment: Stanford CS 224n Project,Subject: Computation and Language [cs.CL],"Published 7 days ago in Jun 08, 2018",2018-06-08T03:29:30Z,-
"Shengyang Sun, Guodong Zhang, Chaoqi Wang, Wenyuan Zeng, Jiaman Li, Roger Grosse",Shengyang Sun et al.,"cs.LG, stat.ML",Learning,cs.LG,ICML 2018,A:1806.04326,"Machine Learning, ICML",21,https://arxiv.org/pdf/1806.04326.pdf,2018-06-12T04:21:53Z,,"The generalization properties of Gaussian processes depend heavily on the choice of kernel, and this choice remains a dark art. We present the Neural Kernel Network (NKN), a flexible family of kernels represented by a neural network. The NKN architecture is based on the composition rules for kernels, so that each unit of the network corresponds to a valid kernel. It can compactly approximate compositional kernel structures such as those used by the Automatic Statistician (Lloyd et al., 2014), but because the architecture is differentiable, it is end-to-end trainable with gradient-based optimization. We show that the NKN is universal for the class of stationary kernels. Empirically we demonstrate pattern discovery and extrapolation abilities of NKN on several tasks that depend crucially on identifying the underlying structure, including time series and texture extrapolation, as well as Bayesian optimization.",Differentiable Compositional Kernel Learning for Gaussian Processes,Comment: ICML 2018,Subject: Learning [cs.LG],"Published 3 days ago in Jun 12, 2018",2018-06-12T04:21:53Z,-
"Miles Brundage, Joanna Bryson",Miles Brundage et al.,cs.CY,Computers and Society,cs.CY,This is a draft of an article being revised - feedback is welcome,A:1608.08196,-,12,https://arxiv.org/pdf/1608.08196.pdf,2016-08-29T19:50:30Z,,"We argue that there already exists de facto artificial intelligence policy - a patchwork of policies impacting the field of AI's development in myriad ways. The key question related to AI policy, then, is not whether AI should be governed at all, but how it is currently being governed, and how that governance might become more informed, integrated, effective, and anticipatory. We describe the main components of de facto AI policy and make some recommendations for how AI policy can be improved, drawing on lessons from other scientific and technological domains.",Smart Policies for Artificial Intelligence,Comment: This is a draft of an article being revised - feedback is welcome,Subject: Computers and Society [cs.CY],"Published in Aug 29, 2016",2016-08-29T19:50:30Z,-
"Xing Lin, Yair Rivenson, Nezih T. Yardimci, Muhammed Veli, Mona Jarrahi, Aydogan Ozcan",Xing Lin et al.,"cs.NE, cs.LG, physics.comp-ph, physics.optics",Neural and Evolutionary Computing,cs.NE,-,A:1804.08711,-,20,https://arxiv.org/pdf/1804.08711.pdf,2018-04-14T05:27:34Z,,"We introduce an all-optical Diffractive Deep Neural Network (D2NN) architecture that can learn to implement various functions after deep learning-based design of passive diffractive layers that work collectively. We experimentally demonstrated the success of this framework by creating 3D-printed D2NNs that learned to implement handwritten digit classification and the function of an imaging lens at terahertz spectrum. With the existing plethora of 3D-printing and other lithographic fabrication methods as well as spatial-light-modulators, this all-optical deep learning framework can perform, at the speed of light, various complex functions that computer-based neural networks can implement, and will find applications in all-optical image analysis, feature detection and object classification, also enabling new camera designs and optical components that can learn to perform unique tasks using D2NNs.",All-Optical Machine Learning Using Diffractive Deep Neural Networks,Comment: [ 20 pages. ],Subject: Neural and Evolutionary Computing [cs.NE],"Published in Apr 14, 2018",2018-04-14T05:27:34Z,-
"Megan Mansfield, Edwin S. Kite, Michael A. Mischna",Megan Mansfield et al.,astro-ph.EP,Earth and Planetary Astrophysics,astro-ph.EP,"12 pages, 8 figures, accepted to JGR Planets",A:1802.10422,-,12,https://arxiv.org/pdf/1802.10422.pdf,2018-02-28T14:14:34Z,,"Post-Noachian Martian paleochannels indicate the existence of liquid water on the surface of Mars after about 3.5 Gya (Irwin et al., 2015; Palucis et al., 2016). In order to explore the effects of variations in CO$_{2}$ partial pressure and obliquity on the possibility of surface water, we created a zero-dimensional surface energy balance model. We combine this model with physically consistent orbital histories to track conditions over the last 3.5 Gyr of Martian history. We find that melting is allowed for atmospheric pressures corresponding to exponential loss rates of $dP/dt \propto t^{-3.73}$ or faster, but this rate is within $0.5 \sigma$ of the rate calculated from initial measurements made by the Mars Atmosphere and Volatile EvolutioN (MAVEN) mission, if we assume all the escaping oxygen measured by MAVEN comes from atmospheric CO$_{2}$ (Lillis et al., 2017; Tu et al., 2015). Melting at this loss rate matches selected key geologic constraints on the formation of Hesperian river networks, assuming optimal melt conditions during the warmest part of each Mars year (Irwin et al., 2015; Stopar et al., 2006; Kite et al., 2017a,b). The atmospheric pressure has a larger effect on the surface energy than changes in Mars's mean obliquity. These results show that initial measurements of atmosphere loss by MAVEN are consistent with atmospheric loss being the dominant process that switched Mars from a melt-permitting to a melt-absent climate (Jakosky et al., 2017), but non-CO$_{2}$ warming will be required if $<2$ Gya paleochannels are confirmed, or if most of the escaping oxygen measured by MAVEN comes from H$_{2}$O.",Effect of Mars Atmospheric Loss on Snow Melt Potential in a 3.5-Gyr Mars Climate Evolution Model,"Comment: 12 pages, 8 figures, accepted to JGR Planets",Subject: Earth and Planetary Astrophysics [astro-ph.EP],"Published in Feb 28, 2018",2018-02-28T14:14:34Z,-
"Chris Donahue, Huanru Henry Mao, Julian McAuley",Chris Donahue et al.,"cs.SD, cs.LG, cs.NE, eess.AS",Sound,cs.SD,Published as a conference paper at ISMIR 2018,A:1806.04278,-,8,https://arxiv.org/pdf/1806.04278.pdf,2018-06-12T00:28:50Z,,"Existing research on music generation focuses on composition, but often ignores the expressive performance characteristics required for plausible renditions of resultant pieces. In this paper, we introduce the Nintendo Entertainment System Music Database (NES-MDB), a large corpus allowing for separate examination of the tasks of composition and performance. NES-MDB contains thousands of multi-instrumental songs composed for playback by the compositionally-constrained NES audio synthesizer. For each song, the dataset contains a musical score for four instrument voices as well as expressive attributes for the dynamics and timbre of each voice. Unlike datasets comprised of General MIDI files, NES-MDB includes all of the information needed to render exact acoustic performances of the original compositions. Alongside the dataset, we provide a tool that renders generated compositions as NES-style audio by emulating the device's audio processor. Additionally, we establish baselines for the tasks of composition, which consists of learning the semantics of composing for the NES synthesizer, and performance, which involves finding a mapping between a composition and realistic expressive attributes.",The NES Music Database: A multi-instrumental dataset with expressive performance attributes,Comment: Published as a conference paper at ISMIR 2018,Subject: Sound [cs.SD],"Published 5 days ago in Jun 12, 2018",2018-06-12T00:28:50Z,-
"Aaron van den Oord, Oriol Vinyals, Koray Kavukcuoglu",Aaron van den Oord et al.,cs.LG,Learning,cs.LG,-,A:1711.00937,-,11,https://arxiv.org/pdf/1711.00937.pdf,2017-11-02T21:14:44Z,,"Learning useful representations without supervision remains a key challenge in machine learning. In this paper, we propose a simple yet powerful generative model that learns such discrete representations. Our model, the Vector Quantised-Variational AutoEncoder (VQ-VAE), differs from VAEs in two key ways: the encoder network outputs discrete, rather than continuous, codes; and the prior is learnt rather than static. In order to learn a discrete latent representation, we incorporate ideas from vector quantisation (VQ). Using the VQ method allows the model to circumvent issues of ""posterior collapse"" -- where the latents are ignored when they are paired with a powerful autoregressive decoder -- typically observed in the VAE framework. Pairing these representations with an autoregressive prior, the model can generate high quality images, videos, and speech as well as doing high quality speaker conversion and unsupervised learning of phonemes, providing further evidence of the utility of the learnt representations.",Neural Discrete Representation Learning,Comment: [ 11 pages. ],Subject: Learning [cs.LG],"Updated 18 days ago in May 30, 2018",2018-05-30T14:58:27Z,-
Bikash Chakraborty,Bikash Chakraborty,"math.HO, 00A05 (Primary), 00A66 (Secondary)",History and Overview,math.HO,"1 page, 1 figure, Accepted for publication on May 2018",A:1806.03163,-,1,https://arxiv.org/pdf/1806.03163.pdf,2018-06-03T15:12:38Z,,"In this article, we give another visual proof of $\pi^e < e^\pi$.",A Visual Proof that $π^e < e^π$,"Comment: 1 page, 1 figure, Accepted for publication on May 2018",Subject: History and Overview [math.HO],"Published 14 days ago in Jun 03, 2018",2018-06-03T15:12:38Z,-
"Mario Srouji, Jian Zhang, Ruslan Salakhutdinov",Mario Srouji et al.,"cs.LG, cs.AI, cs.RO",Learning,cs.LG,First two authors contributed equally,A:1802.08311,-,12,https://arxiv.org/pdf/1802.08311.pdf,2018-02-22T21:31:34Z,,"In recent years, Deep Reinforcement Learning has made impressive advances in solving several important benchmark problems for sequential decision making. Many control applications use a generic multilayer perceptron (MLP) for non-vision parts of the policy network. In this work, we propose a new neural network architecture for the policy network representation that is simple yet effective. The proposed Structured Control Net (SCN) splits the generic MLP into two separate sub-modules: a nonlinear control module and a linear control module. Intuitively, the nonlinear control is for forward-looking and global control, while the linear control stabilizes the local dynamics around the residual of global control. We hypothesize that this will bring together the benefits of both linear and nonlinear policies: improve training sample efficiency, final episodic reward, and generalization of learned policy, while requiring a smaller network and being generally applicable to different training methods. We validated our hypothesis with competitive results on simulations from OpenAI MuJoCo, Roboschool, Atari, and a custom 2D urban driving environment, with various ablation and generalization tests, trained with multiple black-box and policy gradient training methods. The proposed architecture has the potential to improve upon broader control tasks by incorporating problem specific priors into the architecture. As a case study, we demonstrate much improved performance for locomotion tasks by emulating the biological central pattern generators (CPGs) as the nonlinear part of the architecture.",Structured Control Nets for Deep Reinforcement Learning,Comment: First two authors contributed equally,Subject: Learning [cs.LG],"Published in Feb 22, 2018",2018-02-22T21:31:34Z,-
"Joao Carreira, Viorica Patraucean, Laurent Mazare, Andrew Zisserman, Simon Osindero",Joao Carreira et al.,cs.CV,Computer Vision and Pattern Recognition,cs.CV,-,A:1806.03863,-,27,https://arxiv.org/pdf/1806.03863.pdf,2018-06-11T08:46:51Z,,"We introduce a class of causal video understanding models that aims to improve efficiency of video processing by maximising throughput, minimising latency, and reducing the number of clock cycles. Leveraging operation pipelining and multi-rate clocks, these models perform a minimal amount of computation (e.g. as few as four convolutional layers) for each frame per timestep to produce an output. The models are still very deep, with dozens of such operations being performed but in a pipelined fashion that enables depth-parallel computation. We illustrate the proposed principles by applying them to existing image architectures and analyse their behaviour on two video tasks: action recognition and human keypoint localisation. The results show that a significant degree of parallelism, and implicitly speedup, can be achieved with little loss in performance.",Massively Parallel Video Networks,Comment: [ 27 pages. ],Subject: Computer Vision and Pattern Recognition [cs.CV],"Published 6 days ago in Jun 11, 2018",2018-06-11T08:46:51Z,-
"Rohan Chabukswar, Kushal Mukherjee",Rohan Chabukswar et al.,"math.HO, 65K10",History and Overview,math.HO,Added a section about Limitations and Future Work. Consolidated the accuracy of output. Corrected several typographical errors,A:1804.07389,-,11,https://arxiv.org/pdf/1804.07389.pdf,2018-04-09T20:01:44Z,,"There has been some interest recently in determining the longest distance one can sail for on the earth without hitting land, as well as in the converse problem of determining the longest distance one could drive for on the earth without encountering a major body of water. In its basic form, this is an optimisation problem, rendered chaotic by the presence of islands and lakes, and indeed the fractal nature of the coasts. In this paper we present a methodology for calculating the two paths using the branch-and-bound algorithm.",Longest Straight Line Paths on Water or Land on the Earth,Comment: Added a section about Limitations and Future Work. Consolidated the accuracy of output. Corrected several typographical errors,Subject: History and Overview [math.HO],"Updated in May 05, 2018",2018-05-05T09:21:35Z,-
"Dzmitry Bahdanau, Felix Hill, Jan Leike, Edward Hughes, Pushmeet Kohli, Edward Grefenstette",Dzmitry Bahdanau et al.,"cs.AI, cs.LG",Artificial Intelligence,cs.AI,"17 pages, 8 figures",A:1806.01946,-,17,https://arxiv.org/pdf/1806.01946.pdf,2018-06-05T22:01:51Z,,"Recent work has shown that deep reinforcement-learning agents can learn to follow language-like instructions from infrequent environment rewards. However, for many real-world natural language commands that involve a degree of underspecification or ambiguity, such as ""tidy the room"", it would be challenging or impossible to program an appropriate reward function. To overcome this, we present a method for learning to follow commands from a training set of instructions and corresponding example goal-states, rather than an explicit reward function. Importantly, the example goal-states are not seen at test time. The approach effectively separates the representation of what instructions require from how they can be executed. In a simple grid world, the method enables an agent to learn a range of commands requiring interaction with blocks and understanding of spatial relations and underspecified abstract arrangements. We further show the method allows our agent to adapt to changes in the environment without requiring new training examples.",Learning to Follow Language Instructions with Adversarial Reward Induction,"Comment: 17 pages, 8 figures",Subject: Artificial Intelligence [cs.AI],"Published 12 days ago in Jun 05, 2018",2018-06-05T22:01:51Z,-
"Kfir Aberman, Jing Liao, Mingyi Shi, Dani Lischinski, Baoquan Chen, Daniel Cohen-Or",Kfir Aberman et al.,cs.CV,Computer Vision and Pattern Recognition,cs.CV,SIGGRAPH 2018,A:1805.04140,"cross-domain correspondence, image hybrids, image morphing",14,https://arxiv.org/pdf/1805.04140.pdf,2018-05-10T19:11:04Z,,"Correspondence between images is a fundamental problem in computer vision, with a variety of graphics applications. This paper presents a novel method for sparse cross-domain correspondence. Our method is designed for pairs of images where the main objects of interest may belong to different semantic categories and differ drastically in shape and appearance, yet still contain semantically related or geometrically similar parts. Our approach operates on hierarchies of deep features, extracted from the input images by a pre-trained CNN. Specifically, starting from the coarsest layer in both hierarchies, we search for Neural Best Buddies (NBB): pairs of neurons that are mutual nearest neighbors. The key idea is then to percolate NBBs through the hierarchy, while narrowing down the search regions at each level and retaining only NBBs with significant activations. Furthermore, in order to overcome differences in appearance, each pair of search regions is transformed into a common appearance. We evaluate our method via a user study, in addition to comparisons with alternative correspondence approaches. The usefulness of our method is demonstrated using a variety of graphics applications, including cross-domain image alignment, creation of hybrid images, automatic image morphing, and more.",Neural Best-Buddies: Sparse Cross-Domain Correspondence,Comment: SIGGRAPH 2018,Subject: Computer Vision and Pattern Recognition [cs.CV],"Published in May 10, 2018",2018-05-10T19:11:04Z,-
"John Hale, Chris Dyer, Adhiguna Kuncoro, Jonathan R. Brennan",John Hale et al.,cs.CL,Computation and Language,cs.CL,ACL2018,A:1806.04127,-,10,https://arxiv.org/pdf/1806.04127.pdf,2018-06-11T17:51:23Z,,"Recurrent neural network grammars (RNNGs) are generative models of (tree,string) pairs that rely on neural networks to evaluate derivational choices. Parsing with them using beam search yields a variety of incremental complexity metrics such as word surprisal and parser action count. When used as regressors against human electrophysiological responses to naturalistic text, they derive two amplitude effects: an early peak and a P600-like later peak. By contrast, a non-syntactic neural language model yields no reliable effects. Model comparisons attribute the early peak to syntactic composition within the RNNG. This pattern of results recommends the RNNG+beam search combination as a mechanistic model of the syntactic processing that occurs during normal human language comprehension.",Finding Syntax in Human Encephalography with Beam Search,Comment: ACL2018,Subject: Computation and Language [cs.CL],"Published 7 days ago in Jun 11, 2018",2018-06-11T17:51:23Z,-
"Chun Fui Liew, Danielle DeLatte, Naoya Takeishi, Takehisa Yairi",Chun Fui Liew et al.,cs.RO,Robotics,cs.RO,"14 pages, 16 figures, typos corrected",A:1711.10085,-,14,https://arxiv.org/pdf/1711.10085.pdf,2017-11-28T01:53:58Z,,"In recent years, research and development in aerial robotics (i.e., unmanned aerial vehicles, UAVs) has been growing at an unprecedented speed, and there is a need to summarize the background, latest developments, and trends of UAV research. Along with a general overview on the definition, types, categories, and topics of UAV, this work describes a systematic way to identify 1,318 high-quality UAV papers from more than thirty thousand that have been appeared in the top journals and conferences. On top of that, we provide a bird's-eye view of UAV research since 2001 by summarizing various statistical information, such as the year, type, and topic distribution of the UAV papers. We make our survey list public and believe that the list can not only help researchers identify, study, and compare their work, but is also useful for understanding research trends in the field. From our survey results, we find there are many types of UAV, and to the best of our knowledge, no literature has attempted to summarize all types in one place. With our survey list, we explain the types within our survey and outline the recent progress of each. We believe this summary can enhance readers' understanding on the UAVs and inspire researchers to propose new methods and new applications.",Recent Developments in Aerial Robotics: A Survey and Prototypes Overview,"Comment: 14 pages, 16 figures, typos corrected",Subject: Robotics [cs.RO],"Updated in Nov 30, 2017",2017-11-30T00:11:50Z,-
"Anders Sandberg, Eric Drexler, Toby Ord",Anders Sandberg et al.,physics.pop-ph,Popular Physics,physics.pop-ph,Submitted to Proceedings of the Royal Society of London A; 4 supplements,A:1806.02404,-,19,https://arxiv.org/pdf/1806.02404.pdf,2018-06-06T19:51:21Z,,"The Fermi paradox is the conflict between an expectation of a high {\em ex ante} probability of intelligent life elsewhere in the universe and the apparently lifeless universe we in fact observe. The expectation that the universe should be teeming with intelligent life is linked to models like the Drake equation, which suggest that even if the probability of intelligent life developing at a given site is small, the sheer multitude of possible sites should nonetheless yield a large number of potentially observable civilizations. We show that this conflict arises from the use of Drake-like equations, which implicitly assume certainty regarding highly uncertain parameters. We examine these parameters, incorporating models of chemical and genetic transitions on paths to the origin of life, and show that extant scientific knowledge corresponds to uncertainties that span multiple orders of magnitude. This makes a stark difference. When the model is recast to represent realistic distributions of uncertainty, we find a substantial {\em ex ante} probability of there being no other intelligent life in our observable universe, and thus that there should be little surprise when we fail to detect any signs of it. This result dissolves the Fermi paradox, and in doing so removes any need to invoke speculative mechanisms by which civilizations would inevitably fail to have observable effects upon the universe.",Dissolving the Fermi Paradox,Comment: Submitted to Proceedings of the Royal Society of London A; 4 supplements,Subject: Popular Physics [physics.pop-ph],"Published 12 days ago in Jun 06, 2018",2018-06-06T19:51:21Z,-
"Amir Zamir, Alexander Sax, William Shen, Leonidas Guibas, Jitendra Malik, Silvio Savarese",Amir Zamir et al.,"cs.CV, cs.AI, cs.LG, cs.NE, cs.RO",Computer Vision and Pattern Recognition,cs.CV,CVPR 2018 (Oral). See project website and live demos at http://taskonomy.vision/,A:1804.08328,-,12,https://arxiv.org/pdf/1804.08328.pdf,2018-04-23T10:46:28Z,,"Do visual tasks have a relationship, or are they unrelated? For instance, could having surface normals simplify estimating the depth of an image? Intuition answers these questions positively, implying existence of a structure among visual tasks. Knowing this structure has notable values; it is the concept underlying transfer learning and provides a principled way for identifying redundancies across tasks, e.g., to seamlessly reuse supervision among related tasks or solve many tasks in one system without piling up the complexity. We proposes a fully computational approach for modeling the structure of space of visual tasks. This is done via finding (first and higher-order) transfer learning dependencies across a dictionary of twenty six 2D, 2.5D, 3D, and semantic tasks in a latent space. The product is a computational taxonomic map for task transfer learning. We study the consequences of this structure, e.g. nontrivial emerged relationships, and exploit them to reduce the demand for labeled data. For example, we show that the total number of labeled datapoints needed for solving a set of 10 tasks can be reduced by roughly 2/3 (compared to training independently) while keeping the performance nearly the same. We provide a set of tools for computing and probing this taxonomical structure including a solver that users can employ to devise efficient supervision policies for their use cases.",Taskonomy: Disentangling Task Transfer Learning,Comment: CVPR 2018 (Oral). See project website and live demos at http://taskonomy.vision/,Subject: Computer Vision and Pattern Recognition [cs.CV],"Published in Apr 23, 2018",2018-04-23T10:46:28Z,-
"Lisa Lee, Emilio Parisotto, Devendra Singh Chaplot, Eric Xing, Ruslan Salakhutdinov",Lisa Lee et al.,"cs.LG, cs.AI, cs.RO, stat.ML",Learning,cs.LG,ICML 2018,A:1806.06408,-,12,https://arxiv.org/pdf/1806.06408.pdf,2018-06-17T16:32:52Z,,"Value Iteration Networks (VINs) are effective differentiable path planning modules that can be used by agents to perform navigation while still maintaining end-to-end differentiability of the entire architecture. Despite their effectiveness, they suffer from several disadvantages including training instability, random seed sensitivity, and other optimization problems. In this work, we reframe VINs as recurrent-convolutional networks which demonstrates that VINs couple recurrent convolutions with an unconventional max-pooling activation. From this perspective, we argue that standard gated recurrent update equations could potentially alleviate the optimization issues plaguing VIN. The resulting architecture, which we call the Gated Path Planning Network, is shown to empirically outperform VIN on a variety of metrics such as learning speed, hyperparameter sensitivity, iteration count, and even generalization. Furthermore, we show that this performance gap is consistent across different maze transition types, maze sizes and even show success on a challenging 3D environment, where the planner is only provided with first-person RGB images.",Gated Path Planning Networks,Comment: ICML 2018,Subject: Learning [cs.LG],"Published 2 days ago in Jun 17, 2018",2018-06-17T16:32:52Z,-
"Rediet Abebe, Shawndra Hill, Jennifer Wortman Vaughan, Peter M. Small, H. Andrew Schwartz",Rediet Abebe et al.,"cs.CY, cs.AI, cs.CL",Computers and Society,cs.CY,-,A:1806.05740,-,13,https://arxiv.org/pdf/1806.05740.pdf,2018-06-14T20:48:41Z,,"The lack of comprehensive, high-quality health data in developing nations creates a roadblock for combating the impacts of disease. One key challenge is understanding the health information needs of people in these nations. Without understanding people's everyday needs, concerns, and misconceptions, health organizations and policymakers lack the ability to effectively target education and programming efforts. In this paper, we propose a bottom-up approach that uses search data from individuals to uncover and gain insight into health information needs in Africa. We analyze Bing searches related to HIV/AIDS, malaria, and tuberculosis from all 54 African nations. For each disease, we automatically derive a set of common search themes or topics, revealing a wide-spread interest in various types of information, including disease symptoms, drugs, concerns about breastfeeding, as well as stigma, beliefs in natural cures, and other topics that may be hard to uncover through traditional surveys. We expose the different patterns that emerge in health information needs by demographic groups (age and sex) and country. We also uncover discrepancies in the quality of content returned by search engines to users by topic. Combined, our results suggest that search data can help illuminate health information needs in Africa and inform discussions on health policy and targeted education efforts both on- and offline.",Using Search Queries to Understand Health Information Needs in Africa,Comment: [ 13 pages. ],Subject: Computers and Society [cs.CY],"Published 5 days ago in Jun 14, 2018",2018-06-14T20:48:41Z,-
Subhash Kak,Subhash Kak,physics.soc-ph,Physics and Society,physics.soc-ph,10 pages,A:1806.06695,-,10,https://arxiv.org/pdf/1806.06695.pdf,2018-06-14T18:09:50Z,,"The Newcomb-Benford Law, which is also called the first digit phenomenon, has applications in diverse phenomena ranging from social and computer networks, engineering systems, natural sciences, and accounting. In forensics, it has been used to determine intrusion in a computer server based on the measured expectations of first digits of time varying values of data, and to check whether the information in a data base has been tampered with. There are slight deviations from the law in certain natural data, as in fundamental physical constants, and here we propose a more general bin distribution of which the Newcomb-Benford Law is a special case so that it can be used to provide a better fit to such data, and also open the door to a mathematical examination of the origins of such deviations.",Variations on the Newcomb-Benford Law,Comment: 10 pages,Subject: Physics and Society [physics.soc-ph],"Published 6 days ago in Jun 14, 2018",2018-06-14T18:09:50Z,-
"Jin-Hwa Kim, Jaehyun Jun, Byoung-Tak Zhang",Jin-Hwa Kim et al.,"cs.CV, cs.AI, cs.CL, cs.LG",Computer Vision and Pattern Recognition,cs.CV,"12 pages including 2 page appendix, 4 figures",A:1805.07932,-,12,https://arxiv.org/pdf/1805.07932.pdf,2018-05-21T07:58:31Z,,"Attention networks in multimodal learning provide an efficient way to utilize given visual information selectively. However, the computational cost to learn attention distributions for every pair of multimodal input channels is prohibitively expensive. To solve this problem, co-attention builds two separate attention distributions for each modality neglecting the interaction between multimodal inputs. In this paper, we propose bilinear attention networks (BAN) that find bilinear attention distributions to utilize given vision-language information seamlessly. BAN considers bilinear interactions among two groups of input channels, while low-rank bilinear pooling extracts the joint representations for each pair of channels. Furthermore, we propose a variant of multimodal residual networks to exploit eight-attention maps of the BAN efficiently. We quantitatively and qualitatively evaluate our model on visual question answering (VQA 2.0) and Flickr30k Entities datasets, showing that BAN significantly outperforms previous methods and achieves new state-of-the-arts on both datasets.",Bilinear Attention Networks,"Comment: 12 pages including 2 page appendix, 4 figures",Subject: Computer Vision and Pattern Recognition [cs.CV],"Published in May 21, 2018",2018-05-21T07:58:31Z,-
"Junhyuk Oh, Yijie Guo, Satinder Singh, Honglak Lee",Junhyuk Oh et al.,"cs.LG, cs.AI, stat.ML",Learning,cs.LG,-,A:1806.05635,Reinforcement Learning,13,https://arxiv.org/pdf/1806.05635.pdf,2018-06-14T16:25:55Z,,"This paper proposes Self-Imitation Learning (SIL), a simple off-policy actor-critic algorithm that learns to reproduce the agent's past good decisions. This algorithm is designed to verify our hypothesis that exploiting past good experiences can indirectly drive deep exploration. Our empirical results show that SIL significantly improves advantage actor-critic (A2C) on several hard exploration Atari games and is competitive to the state-of-the-art count-based exploration methods. We also show that SIL improves proximal policy optimization (PPO) on MuJoCo tasks.",Self-Imitation Learning,Comment: [ 13 pages. ],Subject: Learning [cs.LG],"Published 6 days ago in Jun 14, 2018",2018-06-14T16:25:55Z,-
"Ildefons Magrans de Abril, Ryota Kanai","Ildefons Magrans de Abril, Ryota Kanai",cs.AI,Artificial Intelligence,cs.AI,"13 pages, 8 figures",A:1806.06505,-,13,https://arxiv.org/pdf/1806.06505.pdf,2018-06-18T05:58:04Z,,"Although there are many approaches to implement intrinsically motivated artificial agents, the combined usage of multiple intrinsic drives remains still a relatively unexplored research area. Specifically, we hypothesize that a mechanism capable of quantifying and controlling the evolution of the information flow between the agent and the environment could be the fundamental component for implementing a higher degree of autonomy into artificial intelligent agents. This paper propose a unified strategy for implementing two semantically orthogonal intrinsic motivations: curiosity and empowerment. Curiosity reward informs the agent about the relevance of a recent agent action, whereas empowerment is implemented as the opposite information flow from the agent to the environment that quantifies the agent's potential of controlling its own future. We show that an additional homeostatic drive is derived from the curiosity reward, which generalizes and enhances the information gain of a classical curious/heterostatic reinforcement learning agent. We show how a shared internal model by curiosity and empowerment facilitates a more efficient training of the empowerment function. Finally, we discuss future directions for further leveraging the interplay between these two intrinsic rewards.",A unified strategy for implementing curiosity and empowerment driven reinforcement learning,"Comment: 13 pages, 8 figures",Subject: Artificial Intelligence [cs.AI],"Published 4 days ago in Jun 18, 2018",2018-06-18T05:58:04Z,-
"Simon A. A. Kohl, Bernardino Romera-Paredes, Clemens Meyer, Jeffrey De Fauw, Joseph R. Ledsam, Klaus H. Maier-Hein, S. M. Ali Eslami, Danilo Jimenez Rezende, Olaf Ronneberger",Simon A. A. Kohl et al.,"cs.CV, cs.LG, cs.NE, stat.ML",Computer Vision and Pattern Recognition,cs.CV,"10 pages for the main paper, 24 pages including appendix. 5 figures in the main paper, 17 figures in total",A:1806.05034,-,24,https://arxiv.org/pdf/1806.05034.pdf,2018-06-13T13:47:04Z,,"Many real-world vision problems suffer from inherent ambiguities. In clinical applications for example, it might not be clear from a CT scan alone which particular region is cancer tissue. Therefore a group of graders typically produces a set of diverse but plausible segmentations. We consider the task of learning a distribution over segmentations given an input. To this end we propose a generative segmentation model based on a combination of a U-Net with a conditional variational autoencoder that is capable of efficiently producing an unlimited number of plausible hypotheses. We show on a lung abnormalities segmentation task and on a Cityscapes segmentation task that our model reproduces the possible segmentation variants as well as the frequencies with which they occur, doing so significantly better than published approaches. These models could have a high impact in real-world applications, such as being used as clinical decision-making algorithms accounting for multiple plausible semantic segmentation hypotheses to provide possible diagnoses and recommend further actions to resolve the present ambiguities.",A Probabilistic U-Net for Segmentation of Ambiguous Images,"Comment: 10 pages for the main paper, 24 pages including appendix. 5 figures in the main paper, 17 figures in total",Subject: Computer Vision and Pattern Recognition [cs.CV],"Published 9 days ago in Jun 13, 2018",2018-06-13T13:47:04Z,-
"Georg Ostrovski, Will Dabney, Rémi Munos",Georg Ostrovski et al.,"cs.LG, stat.ML",Learning,cs.LG,ICML 2018,A:1806.05575,"autoregressive, generative model, machine learning, quantile regression",16,https://arxiv.org/pdf/1806.05575.pdf,2018-06-14T14:29:18Z,,"We introduce autoregressive implicit quantile networks (AIQN), a fundamentally different approach to generative modeling than those commonly used, that implicitly captures the distribution using quantile regression. AIQN is able to achieve superior perceptual quality and improvements in evaluation metrics, without incurring a loss of sample diversity. The method can be applied to many existing models and architectures. In this work we extend the PixelCNN model with AIQN and demonstrate results on CIFAR-10 and ImageNet using Inception score, FID, non-cherry-picked samples, and inpainting results. We consistently observe that AIQN yields a highly stable algorithm that improves perceptual quality while maintaining a highly diverse distribution.",Autoregressive Quantile Networks for Generative Modeling,Comment: ICML 2018,Subject: Learning [cs.LG],"Published 8 days ago in Jun 14, 2018",2018-06-14T14:29:18Z,-
Dan Hooper,Dan Hooper,"astro-ph.CO, astro-ph.GA, physics.pop-ph",Cosmology and Nongalactic Astrophysics,astro-ph.CO,"11 pages, 4 figures",A:1806.05203,-,11,https://arxiv.org/pdf/1806.05203.pdf,2018-06-13T18:10:51Z,,"The presence of dark energy in our universe is causing space to expand at an accelerating rate. As a result, over the next approximately 100 billion years, all stars residing beyond the Local Group will fall beyond the cosmic horizon and become not only unobservable, but entirely inaccessible, thus limiting how much energy could one day be extracted from them. Here, we consider the likely response of a highly advanced civilization to this situation. In particular, we argue that in order to maximize its access to useable energy, a sufficiently advanced civilization would chose to expand rapidly outward, build Dyson Spheres or similar structures around encountered stars, and use the energy that is harnessed to accelerate those stars away from the approaching horizon and toward the center of the civilization. We find that such efforts will be most effective for stars with masses in the range of $M\sim (0.2-1) M_{\odot}$, and could lead to the harvesting of stars within a region extending out to several tens of Mpc in radius, potentially increasing the total amount of energy that is available to a future civilization by a factor of several thousand. We also discuss the observable signatures of a civilization elsewhere in the universe that is currently in this state of stellar harvesting.",Life Versus Dark Energy: How An Advanced Civilization Could Resist the Accelerating Expansion of the Universe,"Comment: 11 pages, 4 figures",Subject: Cosmology and Nongalactic Astrophysics [astro-ph.CO],"Published 9 days ago in Jun 13, 2018",2018-06-13T18:10:51Z,-
"Lechao Xiao, Yasaman Bahri, Jascha Sohl-Dickstein, Samuel S. Schoenholz, Jeffrey Pennington",Lechao Xiao et al.,"stat.ML, cs.LG",Machine Learning,stat.ML,ICML 2018 Conference Proceedings,A:1806.05393,-,16,https://arxiv.org/pdf/1806.05393.pdf,2018-06-14T07:04:15Z,,"In recent years, state-of-the-art methods in computer vision have utilized increasingly deep convolutional neural network architectures (CNNs), with some of the most successful models employing hundreds or even thousands of layers. A variety of pathologies such as vanishing/exploding gradients make training such deep networks challenging. While residual connections and batch normalization do enable training at these depths, it has remained unclear whether such specialized architecture designs are truly necessary to train deep CNNs. In this work, we demonstrate that it is possible to train vanilla CNNs with ten thousand layers or more simply by using an appropriate initialization scheme. We derive this initialization scheme theoretically by developing a mean field theory for signal propagation and by characterizing the conditions for dynamical isometry, the equilibration of singular values of the input-output Jacobian matrix. These conditions require that the convolution operator be an orthogonal transformation in the sense that it is norm-preserving. We present an algorithm for generating such random initial orthogonal convolution kernels and demonstrate empirically that they enable efficient training of extremely deep architectures.","Dynamical Isometry and a Mean Field Theory of CNNs: How to Train 10,000-Layer Vanilla Convolutional Neural Networks",Comment: ICML 2018 Conference Proceedings,Subject: Machine Learning [stat.ML],"Published 9 days ago in Jun 14, 2018",2018-06-14T07:04:15Z,-
"Ye Jia, Yu Zhang, Ron J. Weiss, Quan Wang, Jonathan Shen, Fei Ren, Zhifeng Chen, Patrick Nguyen, Ruoming Pang, Ignacio Lopez Moreno, Yonghui Wu",Ye Jia et al.,"cs.CL, cs.LG, cs.SD, eess.AS",Computation and Language,cs.CL,-,A:1806.04558,-,15,https://arxiv.org/pdf/1806.04558.pdf,2018-06-12T14:29:22Z,,"We describe a neural network-based system for text-to-speech (TTS) synthesis that is able to generate speech audio in the voice of many different speakers, including those unseen during training. Our system consists of three independently trained components: (1) a speaker encoder network, trained on a speaker verification task using an independent dataset of noisy speech from thousands of speakers without transcripts, to generate a fixed-dimensional embedding vector from seconds of reference speech from a target speaker; (2) a sequence-to-sequence synthesis network based on Tacotron 2, which generates a mel spectrogram from text, conditioned on the speaker embedding; (3) an auto-regressive WaveNet-based vocoder that converts the mel spectrogram into a sequence of time domain waveform samples. We demonstrate that the proposed model is able to transfer the knowledge of speaker variability learned by the discriminatively-trained speaker encoder to the new task, and is able to synthesize natural speech from speakers that were not seen during training. We quantify the importance of training the speaker encoder on a large and diverse speaker set in order to obtain the best generalization performance. Finally, we show that randomly sampled speaker embeddings can be used to synthesize speech in the voice of novel speakers dissimilar from those used in training, indicating that the model has learned a high quality speaker representation.",Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis,Comment: [ 15 pages. ],Subject: Computation and Language [cs.CL],"Published 11 days ago in Jun 12, 2018",2018-06-12T14:29:22Z,-
"Kurtland Chua, Roberto Calandra, Rowan McAllister, Sergey Levine",Kurtland Chua et al.,"cs.LG, cs.AI, cs.RO, stat.ML",Learning,cs.LG,-,A:1805.12114,-,16,https://arxiv.org/pdf/1805.12114.pdf,2018-05-30T17:55:21Z,,"Model-based reinforcement learning (RL) algorithms can attain excellent sample efficiency, but often lag behind the best model-free algorithms in terms of asymptotic performance, especially those with high-capacity parametric function approximators, such as deep networks. In this paper, we study how to bridge this gap, by employing uncertainty-aware dynamics models. We propose a new algorithm called probabilistic ensembles with trajectory sampling (PETS) that combines uncertainty-aware deep network dynamics models with sampling-based uncertainty propagation. Our comparison to state-of-the-art model-based and model-free deep RL algorithms shows that our approach matches the asymptotic performance of model-free algorithms on several challenging benchmark tasks, while requiring significantly fewer samples (e.g. 25 and 125 times fewer samples than Soft Actor Critic and Proximal Policy Optimization respectively on the half-cheetah task).",Deep Reinforcement Learning in a Handful of Trials using Probabilistic Dynamics Models,Comment: [ 16 pages. ],Subject: Learning [cs.LG],"Published 24 days ago in May 30, 2018",2018-05-30T17:55:21Z,-
Raghuraman Krishnamoorthi,Raghuraman Krishnamoorthi,"cs.LG, cs.CV, stat.ML",Learning,cs.LG,37 pages,A:1806.08342,-,36,https://arxiv.org/pdf/1806.08342.pdf,2018-06-21T17:32:46Z,,"We present an overview of techniques for quantizing convolutional neural networks for inference with integer weights and activations. Per-channel quantization of weights and per-layer quantization of activations to 8-bits of precision post-training produces classification accuracies within 2% of floating point networks for a wide variety of CNN architectures. Model sizes can be reduced by a factor of 4 by quantizing weights to 8-bits, even when 8-bit arithmetic is not supported. This can be achieved with simple, post training quantization of weights.We benchmark latencies of quantized networks on CPUs and DSPs and observe a speedup of 2x-3x for quantized implementations compared to floating point on CPUs. Speedups of up to 10x are observed on specialized processors with fixed point SIMD capabilities, like the Qualcomm QDSPs with HVX. Quantization-aware training can provide further improvements, reducing the gap to floating point to 1% at 8-bit precision. Quantization-aware training also allows for reducing the precision of weights to four bits with accuracy losses ranging from 2% to 10%, with higher accuracy drop for smaller networks.We introduce tools in TensorFlow and TensorFlowLite for quantizing convolutional networks and review best practices for quantization-aware training to obtain high accuracy with quantized weights and activations. We recommend that per-channel quantization of weights and per-layer quantization of activations be the preferred quantization scheme for hardware acceleration and kernel optimization. We also propose that future processors and hardware accelerators for optimized inference support precisions of 4, 8 and 16 bits.",Quantizing deep convolutional networks for efficient inference: A whitepaper,Comment: 37 pages,Subject: Learning [cs.LG],"Published 2 days ago in Jun 21, 2018",2018-06-21T17:32:46Z,-
"Zhilin Yang, Jake Zhao, Bhuwan Dhingra, Kaiming He, William W. Cohen, Ruslan Salakhutdinov, Yann LeCun",Zhilin Yang et al.,"cs.LG, cs.CL, cs.CV, stat.ML",Learning,cs.LG,-,A:1806.05662,-,12,https://arxiv.org/pdf/1806.05662.pdf,2018-06-14T17:41:19Z,,"Modern deep transfer learning approaches have mainly focused on learning generic feature vectors from one task that are transferable to other tasks, such as word embeddings in language and pretrained convolutional features in vision. However, these approaches usually transfer unary features and largely ignore more structured graphical representations. This work explores the possibility of learning generic latent relational graphs that capture dependencies between pairs of data units (e.g., words or pixels) from large-scale unlabeled data and transferring the graphs to downstream tasks. Our proposed transfer learning framework improves performance on various tasks including question answering, natural language inference, sentiment analysis, and image classification. We also show that the learned graphs are generic enough to be transferred to different embeddings on which the graphs have not been trained (including GloVe embeddings, ELMo embeddings, and task-specific RNN hidden unit), or embedding-free units such as image pixels.",GLoMo: Unsupervisedly Learned Relational Graphs as Transferable Representations,Comment: [ 12 pages. ],Subject: Learning [cs.LG],"Updated 7 days ago in Jun 17, 2018",2018-06-17T04:36:08Z,-
"Naman Agarwal, Brian Bullins, Xinyi Chen, Elad Hazan, Karan Singh, Cyril Zhang, Yi Zhang",Naman Agarwal et al.,"cs.LG, math.OC, stat.ML",Learning,cs.LG,-,A:1806.02958,-,16,https://arxiv.org/pdf/1806.02958.pdf,2018-06-08T03:31:05Z,,"Adaptive regularization methods come in diagonal and full-matrix variants. However, only the former have enjoyed widespread adoption in training large-scale deep models. This is due to the computational overhead of manipulating a full matrix in high dimension. In this paper, we show how to make full-matrix adaptive regularization practical and useful. We present GGT, a truly scalable full-matrix adaptive optimizer. At the heart of our algorithm is an efficient method for computing the inverse square root of a low-rank matrix. We show that GGT converges to first-order local minima, providing the first rigorous theoretical analysis of adaptive regularization in non-convex optimization. In preliminary experiments, GGT trains faster across a variety of synthetic tasks and standard deep learning benchmarks.",The Case for Full-Matrix Adaptive Regularization,Comment: [ 16 pages. ],Subject: Learning [cs.LG],"Published 17 days ago in Jun 08, 2018",2018-06-08T03:31:05Z,-
"Alex Sanchez-Stern, Pavel Panchekha, Sorin Lerner, Zachary Tatlock",Alex Sanchez-Stern et al.,cs.PL,Programming Languages,cs.PL,15 pages Conditionally accepted at PLDI 18,A:1705.10416,-,15,https://arxiv.org/pdf/1705.10416.pdf,2017-05-29T23:43:04Z,,"Floating-point arithmetic plays a central role in science, engineering, and finance by enabling developers to approximate real arithmetic. To address numerical issues in large floating-point applications, developers must identify root causes, which is difficult because floating-point errors are generally non-local, non-compositional, and non-uniform. This paper presents Herbgrind, a tool to help developers identify and address root causes in numerical code written in low-level C/C++ and Fortran. Herbgrind dynamically tracks dependencies between operations and program outputs to avoid false positives and abstracts erroneous computations to a simplified program fragment whose improvement can reduce output error. We perform several case studies applying Herbgrind to large, expert-crafted numerical programs and show that it scales to applications spanning hundreds of thousands of lines, correctly handling the low-level details of modern floating point hardware and mathematical libraries, and tracking error across function boundaries and through the heap.",Finding Root Causes of Floating Point Error with Herbgrind,Comment: 15 pages Conditionally accepted at PLDI 18,Subject: Programming Languages [cs.PL],"Updated in Mar 08, 2018",2018-03-08T18:04:56Z,-
"Neal Wadhwa, Rahul Garg, David E. Jacobs, Bryan E. Feldman, Nori Kanazawa, Robert Carroll, Yair Movshovitz-Attias, Jonathan T. Barron, Yael Pritch, Marc Levoy",Neal Wadhwa et al.,"cs.CV, cs.GR",Computer Vision and Pattern Recognition,cs.CV,Accepted to SIGGRAPH 2018. Basis for Portrait Mode on Google Pixel 2 and Pixel 2 XL,A:1806.04171,-,18,https://arxiv.org/pdf/1806.04171.pdf,2018-06-11T18:29:12Z,,"Shallow depth-of-field is commonly used by photographers to isolate a subject from a distracting background. However, standard cell phone cameras cannot produce such images optically, as their short focal lengths and small apertures capture nearly all-in-focus images. We present a system to computationally synthesize shallow depth-of-field images with a single mobile camera and a single button press. If the image is of a person, we use a person segmentation network to separate the person and their accessories from the background. If available, we also use dense dual-pixel auto-focus hardware, effectively a 2-sample light field with an approximately 1 millimeter baseline, to compute a dense depth map. These two signals are combined and used to render a defocused image. Our system can process a 5.4 megapixel image in 4 seconds on a mobile phone, is fully automatic, and is robust enough to be used by non-experts. The modular nature of our system allows it to degrade naturally in the absence of a dual-pixel sensor or a human subject.",Synthetic Depth-of-Field with a Single-Camera Mobile Phone,Comment: Accepted to SIGGRAPH 2018. Basis for Portrait Mode on Google Pixel 2 and Pixel 2 XL,Subject: Computer Vision and Pattern Recognition [cs.CV],"Published 13 days ago in Jun 11, 2018",2018-06-11T18:29:12Z,-
"Chrisantha Thomas Fernando, Jakub Sygnowski, Simon Osindero, Jane Wang, Tom Schaul, Denis Teplyashin, Pablo Sprechmann, Alexander Pritzel, Andrei A. Rusu",Chrisantha Thomas Fernando et al.,"cs.NE, cs.AI, cs.LG",Neural and Evolutionary Computing,cs.NE,-,A:1806.07917,-,12,https://arxiv.org/pdf/1806.07917.pdf,2018-06-06T08:39:03Z,,"The scope of the Baldwin effect was recently called into question by two papers that closely examined the seminal work of Hinton and Nowlan. To this date there has been no demonstration of its necessity in empirically challenging tasks. Here we show that the Baldwin effect is capable of evolving few-shot supervised and reinforcement learning mechanisms, by shaping the hyperparameters and the initial parameters of deep learning algorithms. Furthermore it can genetically accommodate strong learning biases on the same set of problems as a recent machine learning algorithm called MAML ""Model Agnostic Meta-Learning"" which uses second-order gradients instead of evolution to learn a set of reference parameters (initial weights) that can allow rapid adaptation to tasks sampled from a distribution. Whilst in simple cases MAML is more data efficient than the Baldwin effect, the Baldwin effect is more general in that it does not require gradients to be backpropagated to the reference parameters or hyperparameters, and permits effectively any number of gradient updates in the inner loop. The Baldwin effect learns strong learning dependent biases, rather than purely genetically accommodating fixed behaviours in a learning independent manner.",Meta-Learning by the Baldwin Effect,Comment: [ 12 pages. ],Subject: Neural and Evolutionary Computing [cs.NE],"Updated 5 days ago in Jun 22, 2018",2018-06-22T09:55:17Z,-
"Bastiaan S. Veeling, Jasper Linmans, Jim Winkens, Taco Cohen, Max Welling",Bastiaan S. Veeling et al.,"cs.CV, cs.LG, stat.ML",Computer Vision and Pattern Recognition,cs.CV,To be presented at MICCAI 2018. Implementations of equivariant layers available at https://github.com/basveeling/keras_gcnn . PCam details and data at https://github.com/basveeling/pcam,A:1806.03962,-,8,https://arxiv.org/pdf/1806.03962.pdf,2018-06-08T12:13:37Z,,"We propose a new model for digital pathology segmentation, based on the observation that histopathology images are inherently symmetric under rotation and reflection. Utilizing recent findings on rotation equivariant CNNs, the proposed model leverages these symmetries in a principled manner. We present a visual analysis showing improved stability on predictions, and demonstrate that exploiting rotation equivariance significantly improves tumor detection performance on a challenging lymph node metastases dataset. We further present a novel derived dataset to enable principled comparison of machine learning models, in combination with an initial benchmark. Through this dataset, the task of histopathology diagnosis becomes accessible as a challenging benchmark for fundamental machine learning research.",Rotation Equivariant CNNs for Digital Pathology,Comment: To be presented at MICCAI 2018. Implementations of equivariant layers available at https://github.com/basveeling/keras_gcnn . PCam details and data at https://github.com/basveeling/pcam,Subject: Computer Vision and Pattern Recognition [cs.CV],"Published 19 days ago in Jun 08, 2018",2018-06-08T12:13:37Z,-
"John C. Baez, Tobias Fritz, Tom Leinster",John C. Baez et al.,"cs.IT, math-ph, math.IT, math.MP, quant-ph, 94A17, 62B10",Information Theory,cs.IT,"11 pages LaTeX, minor revision",A:1106.1791,-,12,https://arxiv.org/pdf/1106.1791.pdf,2011-06-09T12:47:00Z,,"There are numerous characterizations of Shannon entropy and Tsallis entropy as measures of information obeying certain properties. Using work by Faddeev and Furuichi, we derive a very simple characterization. Instead of focusing on the entropy of a probability measure on a finite set, this characterization focuses on the `information loss', or change in entropy, associated with a measure-preserving function. Information loss is a special case of conditional entropy: namely, it is the entropy of a random variable conditioned on some function of that variable. We show that Shannon entropy gives the only concept of information loss that is functorial, convex-linear and continuous. This characterization naturally generalizes to Tsallis entropy as well.",A Characterization of Entropy in Terms of Information Loss,"Comment: 11 pages LaTeX, minor revision",Subject: Information Theory [cs.IT],"Updated in Nov 18, 2011",2011-11-18T14:46:17Z,-
"Xi Cheng, Bohdan Khomtchouk, Norman Matloff, Pete Mohanty",Xi Cheng et al.,"cs.LG, stat.ML",Learning,cs.LG,"23 pages, 1 figure, 13 tables",A:1806.06850,-,23,https://arxiv.org/pdf/1806.06850.pdf,2018-06-13T05:06:43Z,,"Despite the success of neural networks (NNs), there is still a concern among many over their ""black box"" nature. Why do they work? Here we present a simple analytic argument that NNs are in fact essentially polynomial regression models. This view will have various implications for NNs, e.g. providing an explanation for why convergence problems arise in NNs, and it gives rough guidance on avoiding overfitting. In addition, we use this phenomenon to predict and confirm a multicollinearity property of NNs not previously reported in the literature. Most importantly, given this loose correspondence, one may choose to routinely use polynomial models instead of NNs, thus avoiding some major problems of the latter, such as having to set many tuning parameters and dealing with convergence issues. We present a number of empirical results; in each case, the accuracy of the polynomial approach matches or exceeds that of NN approaches. A many-featured, open-source software package, polyreg, is available.",Polynomial Regression As an Alternative to Neural Nets,"Comment: 23 pages, 1 figure, 13 tables",Subject: Learning [cs.LG],"Published 15 days ago in Jun 13, 2018",2018-06-13T05:06:43Z,-
Brian K. Vogel,Brian K. Vogel,cs.LG,Learning,cs.LG,"Minor editing of the abstract, introduction, and concluding sections to improve readability and remove redundant wording, based on feedback from a reviewer. No changes were made to the material presented nor to the results. Added an acknowledgment section to thank the reviewer. Corrected minor typos",A:0807.4198,-,83,https://arxiv.org/pdf/0807.4198.pdf,2008-07-25T22:50:46Z,,"We present a novel graphical framework for modeling non-negative sequential data with hierarchical structure. Our model corresponds to a network of coupled non-negative matrix factorization (NMF) modules, which we refer to as a positive factor network (PFN). The data model is linear, subject to non-negativity constraints, so that observation data consisting of an additive combination of individually representable observations is also representable by the network. This is a desirable property for modeling problems in computational auditory scene analysis, since distinct sound sources in the environment are often well-modeled as combining additively in the corresponding magnitude spectrogram. We propose inference and learning algorithms that leverage existing NMF algorithms and that are straightforward to implement. We present a target tracking example and provide results for synthetic observation data which serve to illustrate the interesting properties of PFNs and motivate their potential usefulness in applications such as music transcription, source separation, and speech recognition. We show how a target process characterized by a hierarchical state transition model can be represented as a PFN. Our results illustrate that a PFN which is defined in terms of a single target observation can then be used to effectively track the states of multiple simultaneous targets. Our results show that the quality of the inferred target states degrades gradually as the observation noise is increased. We also present results for an example in which meaningful hierarchical features are extracted from a spectrogram. Such a hierarchical representation could be useful for music transcription and source separation applications. We also propose a network for language modeling.",Positive factor networks: A graphical framework for modeling non-negative sequential data,"Comment: Minor editing of the abstract, introduction, and concluding sections to improve readability and remove redundant wording, based on feedback from a reviewer. No changes were made to the material presented nor to the results. Added an acknowledgment section to thank the reviewer. Corrected minor typos",Subject: Learning [cs.LG],"Updated in Jul 16, 2009",2009-07-16T00:30:26Z,-
"Taro Kimura, Sho Ozaki","Taro Kimura, Sho Ozaki","hep-ph, cond-mat.str-el, hep-th",High Energy Physics - Phenomenology,hep-ph,"1+20 pages, 1 figure",A:1806.06486,-,21,https://arxiv.org/pdf/1806.06486.pdf,2018-06-18T03:11:09Z,,"We study non-perturbative aspects of QCD Kondo effect, which has been recently proposed for the finite density and strong magnetic field systems, using conformal field theory describing the low energy physics near the IR fixed point. We clarify the symmetry class of QCD Kondo effect both for the finite density and magnetic field systems, and show how the IR fixed point is non-perturbatively characterized by the boundary condition, which incorporates the impurity effect in Kondo problem. We also obtain the low temperature behavior of several quantities of QCD Kondo effect in the vicinity of the IR fixed point based on the conformal field theory analysis.",Conformal field theory analysis for QCD Kondo effect,"Comment: 1+20 pages, 1 figure",Subject: High Energy Physics - Phenomenology [hep-ph],"Published 11 days ago in Jun 18, 2018",2018-06-18T03:11:09Z,-
"Sander Dieleman, Aäron van den Oord, Karen Simonyan",Sander Dieleman et al.,"cs.SD, cs.LG, eess.AS, stat.ML",Sound,cs.SD,"13 pages, 2 figures, submitted to NIPS 2018",A:1806.10474,-,13,https://arxiv.org/pdf/1806.10474.pdf,2018-06-26T16:48:59Z,,"Realistic music generation is a challenging task. When building generative models of music that are learnt from data, typically high-level representations such as scores or MIDI are used that abstract away the idiosyncrasies of a particular performance. But these nuances are very important for our perception of musicality and realism, so in this work we embark on modelling music in the raw audio domain. It has been shown that autoregressive models excel at generating raw audio waveforms of speech, but when applied to music, we find them biased towards capturing local signal structure at the expense of modelling long-range correlations. This is problematic because music exhibits structure at many different timescales. In this work, we explore autoregressive discrete autoencoders (ADAs) as a means to enable autoregressive models to capture long-range correlations in waveforms. We find that they allow us to unconditionally generate piano music directly in the raw audio domain, which shows stylistic consistency across tens of seconds.",The challenge of realistic music generation: modelling raw audio at scale,"Comment: 13 pages, 2 figures, submitted to NIPS 2018",Subject: Sound [cs.SD],"Published 3 days ago in Jun 26, 2018",2018-06-26T16:48:59Z,-
"Hanxiao Liu, Karen Simonyan, Yiming Yang",Hanxiao Liu et al.,"cs.LG, cs.CL, cs.CV, stat.ML",Learning,cs.LG,-,A:1806.09055,-,12,https://arxiv.org/pdf/1806.09055.pdf,2018-06-24T00:06:13Z,,"This paper addresses the scalability challenge of architecture search by formulating the task in a differentiable manner. Unlike conventional approaches of applying evolution or reinforcement learning over a discrete and non-differentiable search space, our method is based on the continuous relaxation of the architecture representation, allowing efficient search of the architecture using gradient descent. Extensive experiments on CIFAR-10, ImageNet, Penn Treebank and WikiText-2 show that our algorithm excels in discovering high-performance convolutional architectures for image classification and recurrent architectures for language modeling, while being orders of magnitude faster than state-of-the-art non-differentiable techniques.",DARTS: Differentiable Architecture Search,Comment: [ 12 pages. ],Subject: Learning [cs.LG],"Published 6 days ago in Jun 24, 2018",2018-06-24T00:06:13Z,-
"Saurabh Arora, Prashant Doshi","Saurabh Arora, Prashant Doshi","cs.LG, stat.ML",Learning,cs.LG,-,A:1806.06877,-,47,https://arxiv.org/pdf/1806.06877.pdf,2018-06-18T18:26:29Z,,"Inverse reinforcement learning is the problem of inferring the reward function of an observed agent, given its policy or behavior. Researchers perceive IRL both as a problem and as a class of methods. By categorically surveying the current literature in IRL, this article serves as a reference for researchers and practitioners in machine learning to understand the challenges of IRL and select the approaches best suited for the problem on hand. The survey formally introduces the IRL problem along with its central challenges which include accurate inference, generalizability, correctness of prior knowledge, and growth in solution complexity with problem size. The article elaborates how the current methods mitigate these challenges. We further discuss the extensions of traditional IRL methods: (i) inaccurate and incomplete perception, (ii) incomplete model, (iii) multiple rewards, and (iv) non-linear reward functions. This discussion concludes with some broad advances in the research area and currently open research questions.","A Survey of Inverse Reinforcement Learning: Challenges, Methods and Progress",Comment: [ 47 pages. ],Subject: Learning [cs.LG],"Published 12 days ago in Jun 18, 2018",2018-06-18T18:26:29Z,-
Sergey Levine,Sergey Levine,"cs.LG, cs.AI, cs.RO, stat.ML",Learning,cs.LG,-,A:1805.00909,-,22,https://arxiv.org/pdf/1805.00909.pdf,2018-05-02T17:11:20Z,,"The framework of reinforcement learning or optimal control provides a mathematical formalization of intelligent decision making that is powerful and broadly applicable. While the general form of the reinforcement learning problem enables effective reasoning about uncertainty, the connection between reinforcement learning and inference in probabilistic models is not immediately obvious. However, such a connection has considerable value when it comes to algorithm design: formalizing a problem as probabilistic inference in principle allows us to bring to bear a wide array of approximate inference tools, extend the model in flexible and powerful ways, and reason about compositionality and partial observability. In this article, we will discuss how a generalization of the reinforcement learning or optimal control problem, which is sometimes termed maximum entropy reinforcement learning, is equivalent to exact probabilistic inference in the case of deterministic dynamics, and variational inference in the case of stochastic dynamics. We will present a detailed derivation of this framework, overview prior work that has drawn on this and related ideas to propose new reinforcement learning and control algorithms, and describe perspectives on future research.",Reinforcement Learning and Control as Probabilistic Inference: Tutorial and Review,Comment: [ 22 pages. ],Subject: Learning [cs.LG],"Updated in May 20, 2018",2018-05-20T20:03:59Z,-
"Tian Qi Chen, Yulia Rubanova, Jesse Bettencourt, David Duvenaud",Tian Qi Chen et al.,"cs.LG, cs.AI, stat.ML",Learning,cs.LG,-,A:1806.07366,-,19,https://arxiv.org/pdf/1806.07366.pdf,2018-06-19T17:50:12Z,,"We introduce a new family of deep neural network models. Instead of specifying a discrete sequence of hidden layers, we parameterize the derivative of the hidden state using a neural network. The output of the network is computed using a blackbox differential equation solver. These continuous-depth models have constant memory cost, adapt their evaluation strategy to each input, and can explicitly trade numerical precision for speed. We demonstrate these properties in continuous-depth residual networks and continuous-time latent variable models. We also construct continuous normalizing flows, a generative model that can train by maximum likelihood, without partitioning or ordering the data dimensions. For training, we show how to scalably backpropagate through any ODE solver, without access to its internal operations. This allows end-to-end training of ODEs within larger models.",Neural Ordinary Differential Equations,Comment: [ 19 pages. ],Subject: Learning [cs.LG],"Published 11 days ago in Jun 19, 2018",2018-06-19T17:50:12Z,-
"Gamaleldin F. Elsayed, Ian Goodfellow, Jascha Sohl-Dickstein",Gamaleldin F. Elsayed et al.,"cs.LG, cs.CR, cs.CV, stat.ML",Learning,cs.LG,-,A:1806.11146,-,12,https://arxiv.org/pdf/1806.11146.pdf,2018-06-28T19:06:26Z,,"Deep neural networks are susceptible to adversarial attacks. In computer vision, well-crafted perturbations to images can cause neural networks to make mistakes such as identifying a panda as a gibbon or confusing a cat with a computer. Previous adversarial examples have been designed to degrade performance of models or cause machine learning models to produce specific outputs chosen ahead of time by the attacker. We introduce adversarial attacks that instead reprogram the target model to perform a task chosen by the attacker---without the attacker needing to specify or compute the desired output for each test-time input. This attack is accomplished by optimizing for a single adversarial perturbation, of unrestricted magnitude, that can be added to all test-time inputs to a machine learning model in order to cause the model to perform a task chosen by the adversary when processing these inputs---even if the model was not trained to do this task. These perturbations can be thus considered a program for the new task. We demonstrate adversarial reprogramming on six ImageNet classification models, repurposing these models to perform a counting task, as well as two classification tasks: classification of MNIST and CIFAR-10 examples presented within the input to the ImageNet model.",Adversarial Reprogramming of Neural Networks,Comment: [ 12 pages. ],Subject: Learning [cs.LG],"Published 4 days ago in Jun 28, 2018",2018-06-28T19:06:26Z,-
Brian Skinner,Brian Skinner,cond-mat.supr-con,Superconductivity,cond-mat.supr-con,"2 pages, 1 figure",A:1808.02929,-,2,https://arxiv.org/pdf/1808.02929.pdf,2018-08-08T20:24:13Z,,"A recent preprint [arxiv:1807.08572] has reported the observation of room temperature supercondutivity in a nanostructured solid composed of gold and silver nanocrystals. Given the extraordinary and exciting nature of this claim, it is worth examining the reported data closely. In this short comment I point out a very surprising feature in the data: an identical pattern of noise for two presumably independent measurements of the magnetic susceptibility as a function of temperature.","Repeated noise pattern in the data of arXiv:1807.08572, ""Evidence for Superconductivity at Ambient Temperature and Pressure in Nanostructures""","Comment: 2 pages, 1 figure",Subject: Superconductivity [cond-mat.supr-con],"Published 9 days ago in Aug 08, 2018",2018-08-08T20:24:13Z,-
